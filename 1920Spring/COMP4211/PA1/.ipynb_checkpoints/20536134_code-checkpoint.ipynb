{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Task 1](#Task-1:-Calculating-the-Win-Rate)\n",
    "    * [Q1](#[Q1]-When-calculating-the-win-rates-of-the-Pokemons,-you-may-notice-that-some-of-them-have-not-participated-in-any-battle.-Explain-how-you-deal-with-them.)\n",
    "* [Task 2](#Task-2:-Finding-the-Most-Correlated-Feature-using-Linear-Regression)\n",
    "    * [Q2](#[Q2]-Report-the-validation-R2-score-of-each-model-to-evaluate-its-prediction-performance.)\n",
    "    * [Q3](#[Q3]-After-training-the-models-with-the-training-set,-use-them-to-make-prediction-on-the-validation-set.-Then,-plot-the-regression-line-and-the-data-points-of-the-validation-set-for-each-of-the-six-models.-For-illustration,-Figure-1-shows-a-plot-of-the-win-rate-versus-the-feature-‘HP’-and-the-regression-line.)\n",
    "    * [Q4](#[Q4]-By-looking-at-the-regression-lines-of-the-six-plots,-find-the-feature-that-is-most-correlated-to-the-win-rate.-Explain-how-you-find-it.)\n",
    "* [Task 3](#Task-3:-Legendary-Pokemon-Classification-using-Logistic-Regression-and-Single-hidden-layer-Neural-Networks)\n",
    "    * [Q5](#[Q5]-Report-the-model-setting,-training-time,-and-performance-of-the-logistic-regression-model.-Since-the-solution-found-may-depend-on-the-initial-weight-values,-you-are-expected-to-repeat-each-setting-multiple-times-(e.g.,-three-times\\)-for-the-same-hyperparameter-setting-and-report-the-mean-and-standard-deviation-of-the-training-time,-accuracy,-and-F1-score-for-each-setting.)\n",
    "    * [Q6](#[Q6]-Report-the-model-setting,-training-time,-and-performance-of-the-neural-networks-for-each-value-of-H.-You-are-also-expected-to-repeat-each-setting-multiple-times-for-the-same-hyperpa--rameter-setting-and-report-the-mean-and-standard-deviation-of-the-training-time,-accuracy,-and-F1-score-for-each-setting.)\n",
    "    * [Q7](#[Q7]-Compare-the-training-time,-accuracy-and-F1-score-of-the-logistic-regression-model-and-the-best-neural-network-model.)\n",
    "    * [Q8](#[Q8]-Plot-the-accuracy-and-the-F1-score-for-different-values-of-H.)\n",
    "    * [Q9](#[Q9]-Do-you-notice-any-trend-when-you-increase-the-hidden-layer-size-from-1-to-64?-If-so,-please-describe-what-the-trend-is.)\n",
    "    * [Q10](#[Q10]-Referring-to-your-experiment-results,-comment-on-the-gap-between-accuracy-and-the-F1-score?-Suggest-a-reason-for-this-observation.)\n",
    "* [Task 4](#Task-4:-Predicting-the-Winners-in-the-Pokemon-Battles)\n",
    "    * [Q11](#[Q11]-Report-10-combinations-of-the-hyperparameter-setting.)\n",
    "    * [Q12](#[Q12]-Report-the-three-best-hyperparameter-settings-as-well-as-the-mean-and-standard-deviation-of-the-validation-accuracy-of-the-five-random-data-splits-for-each-hyperparameter-setting.)\n",
    "    * [Q13](#[Q13]-Use-the-best-model-to-predict-the-instances-in-the-test-set-(q4-test.csv\\).-Report-the-accuracy.)\n",
    "    * [Q14](#[Q14]-Print-the-confusion-matrix-of-the-predictions-on-the-test-set.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Calculating the Win Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemons = pd.read_csv('./data/pokemon.csv', sep=',')\n",
    "battles = pd.read_csv('./data/battles.csv', sep=',')\n",
    "\n",
    "pokemons = pd.DataFrame(pokemons)\n",
    "battles = pd.DataFrame(battles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Has Gender</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>796</td>\n",
       "      <td>Diancie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>797</td>\n",
       "      <td>Mega Diancie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>50</td>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>798</td>\n",
       "      <td>Hoopa Confined</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>799</td>\n",
       "      <td>Hoopa Unbound</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Dark</td>\n",
       "      <td>80</td>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>170</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>800</td>\n",
       "      <td>Volcanion</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Water</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>120</td>\n",
       "      <td>130</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #            Name   Type 1  Type 2  HP  Attack  Defense  Sp. Atk  \\\n",
       "0      1       Bulbasaur    Grass  Poison  45      49       49       65   \n",
       "1      2         Ivysaur    Grass  Poison  60      62       63       80   \n",
       "2      3        Venusaur    Grass  Poison  80      82       83      100   \n",
       "3      4   Mega Venusaur    Grass  Poison  80     100      123      122   \n",
       "4      5      Charmander     Fire     NaN  39      52       43       60   \n",
       "..   ...             ...      ...     ...  ..     ...      ...      ...   \n",
       "795  796         Diancie     Rock   Fairy  50     100      150      100   \n",
       "796  797    Mega Diancie     Rock   Fairy  50     160      110      160   \n",
       "797  798  Hoopa Confined  Psychic   Ghost  80     110       60      150   \n",
       "798  799   Hoopa Unbound  Psychic    Dark  80     160       60      170   \n",
       "799  800       Volcanion     Fire   Water  80     110      120      130   \n",
       "\n",
       "     Sp. Def  Speed  Generation  Has Gender  Legendary  \n",
       "0         65     45           1        True      False  \n",
       "1         80     60           1        True      False  \n",
       "2        100     80           1        True      False  \n",
       "3        120     80           1        True      False  \n",
       "4         50     65           1        True      False  \n",
       "..       ...    ...         ...         ...        ...  \n",
       "795      150     50           6       False       True  \n",
       "796      110    110           6       False       True  \n",
       "797      130     70           6       False       True  \n",
       "798      130     80           6       False       True  \n",
       "799       90     70           6       False       True  \n",
       "\n",
       "[800 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pokemons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First_pokemon</th>\n",
       "      <th>Second_pokemon</th>\n",
       "      <th>Winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173</td>\n",
       "      <td>463</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>174</td>\n",
       "      <td>307</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>772</td>\n",
       "      <td>181</td>\n",
       "      <td>772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>430</td>\n",
       "      <td>356</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>519</td>\n",
       "      <td>695</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>416</td>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>221</td>\n",
       "      <td>265</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>35</td>\n",
       "      <td>448</td>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>791</td>\n",
       "      <td>713</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>312</td>\n",
       "      <td>486</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       First_pokemon  Second_pokemon  Winner\n",
       "0                173             463     463\n",
       "1                174             307     307\n",
       "2                772             181     772\n",
       "3                430             356     430\n",
       "4                519             695     519\n",
       "...              ...             ...     ...\n",
       "39995            416             778     778\n",
       "39996            221             265     265\n",
       "39997             35             448     448\n",
       "39998            791             713     713\n",
       "39999            312             486     486\n",
       "\n",
       "[40000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "battles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Has Gender</th>\n",
       "      <th>Legendary</th>\n",
       "      <th>WinRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.254902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.395833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.631068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.445652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #           Name Type 1  Type 2  HP  Attack  Defense  Sp. Atk  Sp. Def  \\\n",
       "0  1      Bulbasaur  Grass  Poison  45      49       49       65       65   \n",
       "1  2        Ivysaur  Grass  Poison  60      62       63       80       80   \n",
       "2  3       Venusaur  Grass  Poison  80      82       83      100      100   \n",
       "3  4  Mega Venusaur  Grass  Poison  80     100      123      122      120   \n",
       "4  5     Charmander   Fire     NaN  39      52       43       60       50   \n",
       "\n",
       "   Speed  Generation  Has Gender  Legendary   WinRate  \n",
       "0     45           1        True      False  0.254902  \n",
       "1     60           1        True      False  0.395833  \n",
       "2     80           1        True      False  0.631068  \n",
       "3     80           1        True      False  0.578947  \n",
       "4     65           1        True      False  0.445652  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winRate = []\n",
    "first_pokemon = battles['First_pokemon']\n",
    "second_pokemon = battles['Second_pokemon']\n",
    "winner = battles['Winner']\n",
    "\n",
    "for index, row in pokemons.iterrows():\n",
    "    wins = np.sum(winner == row['#'])\n",
    "    total = np.sum(first_pokemon == row['#']) + np.sum(second_pokemon == row['#'])\n",
    "    winRate.append(0 if total == 0 else wins / total) # 0% win rate if no battle record\n",
    "\n",
    "# This is the result for [Q1]\n",
    "pokemons['WinRate'] = winRate \n",
    "pokemons.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Q1] When calculating the win rates of the Pokemons, you may notice that some of them have not participated in any battle. Explain how you deal with them.\n",
    "\n",
    "**Your Answer:** I simply treat their win rate as 0%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Finding the Most Correlated Feature using Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 socre of HP:  \t0.093010\n",
      "R2 socre of Attack:  \t0.215038\n",
      "R2 socre of Defense:  \t-0.015525\n",
      "R2 socre of Sp. Atk:  \t0.204860\n",
      "R2 socre of Sp. Def:  \t-0.015475\n",
      "R2 socre of Speed:  \t0.805541\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train, val = train_test_split(pokemons, test_size=0.2, random_state=4211)\n",
    "\n",
    "models = []\n",
    "features = ['HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed']\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "def reshape_feature(x):\n",
    "    return x.values.reshape(-1, 1)\n",
    "\n",
    "for idx, feature in enumerate(features):\n",
    "    X_train = reshape_feature(train[feature])\n",
    "    X_val = reshape_feature(val[feature])\n",
    "    \n",
    "    clf = LinearRegression()\n",
    "    clf.fit(X_train, train['WinRate'])\n",
    "    y_pred = clf.predict(X_val)\n",
    "    # This is the result for [Q2]\n",
    "    print('R2 socre of %s:  \\t%f' % (feature, r2_score(val['WinRate'], y_pred)))\n",
    "    \n",
    "    # These are the result for [Q3]\n",
    "    plt.subplot(2, 3, idx + 1)\n",
    "    plt.scatter(X_val, reshape_feature(val['WinRate']))\n",
    "    plt.plot(X_val, y_pred, color='red')\n",
    "    plt.title('WinRate vs %s' % feature)\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('WinRate')\n",
    "    \n",
    "    models.append(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Q2] Report the validation R2 score of each model to evaluate its prediction performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- R2 socre of HP:  \t    0.093010\n",
    "- R2 socre of Attack:  \t0.215038\n",
    "- R2 socre of Defense:  \t-0.015525\n",
    "- R2 socre of Sp. Atk:  \t0.204860\n",
    "- R2 socre of Sp. Def:  \t-0.015475\n",
    "- R2 socre of Speed:  \t0.805541"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Q3] After training the models with the training set, use them to make prediction on the validation set. Then, plot the regression line and the data points of the validation set for each of the six models. For illustration, Figure 1 shows a plot of the win rate versus the feature ‘HP’ and the regression line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![!alt text](./task3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Q4] By looking at the regression lines of the six plots, find the feature that is most correlated to the win rate. Explain how you find it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most correlated feature is Speed. According to the graph above, we can observe that Speed are positively proportional to WinRate, and the regression line perform same as the scatter points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Legendary Pokemon Classification using Logistic Regression and Single-hidden-layer Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pokemons' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-18636658f8cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mto_keep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpokemons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4211\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pokemons' is not defined"
     ]
    }
   ],
   "source": [
    "# These are the variable and functions that will use in the whole Task 3 and Task 4\n",
    "\n",
    "model_sample_size = 3 # train a model with same setting N times\n",
    "\n",
    "def cat_to_ont_hot(dataSet, cat_vars=['Type 1', 'Type 2']):\n",
    "    train = dataSet.copy()\n",
    "    for var in cat_vars:\n",
    "        cat_list = pd.get_dummies(train[var], prefix=var)\n",
    "        data=train.join(cat_list)\n",
    "        train=data\n",
    "\n",
    "    data_vars=train.columns.values.tolist()\n",
    "    to_keep=[i for i in data_vars if i not in cat_vars]\n",
    "\n",
    "    return train[to_keep]\n",
    "\n",
    "def preprocess_data(data=pokemons):\n",
    "    train, val = train_test_split(data, test_size=0.2, random_state=4211)\n",
    "\n",
    "    train = cat_to_ont_hot(train)\n",
    "    val = cat_to_ont_hot(val)\n",
    "\n",
    "    val.insert(30, 'Type 2_Bug', np.zeros_like(val['Name']))\n",
    "    val.insert(33, 'Type 2_Electric', np.zeros_like(val['Name']))\n",
    "    \n",
    "    return (train, val)\n",
    "\n",
    "def report(models, size=model_sample_size, needGraph=False, xaxis=[1, 2, 4, 8, 16, 32, 64]):\n",
    "    accuracies = []\n",
    "    f1_scores = []\n",
    "    for i in range(0, len(models), size):\n",
    "        \n",
    "        time_model, acc_model, f1_model = None, None, None\n",
    "        best_time, best_acc, best_f1 = 0.0, 0.0, 0.0\n",
    "        scope = np.arange(size)\n",
    "\n",
    "        # arrays containing each statistics\n",
    "        training_time = [models[i + j]['time'] for j in scope]\n",
    "        accuracy = [(accuracy_score(y_val, models[i + j]['clf'].predict(X_val))) for j in scope]\n",
    "        f1 =       [(      f1_score(y_val, models[i + j]['clf'].predict(X_val))) for j in scope]\n",
    "        \n",
    "        accuracies.append(np.mean(accuracy))\n",
    "        f1_scores.append(np.mean(f1))\n",
    "\n",
    "        if np.mean(training_time) > best_time:\n",
    "            best_time = np.mean(training_time)\n",
    "            time_model = models[i]\n",
    "        if np.mean(accuracy) > best_acc:\n",
    "            best_acc = np.mean(accuracy)\n",
    "            acc_model = models[i]\n",
    "        if np.mean(f1) > best_f1:\n",
    "            best_f1 = np.mean(f1)\n",
    "            f1_model = models[i]\n",
    "\n",
    "        print('\\n%d / %d' % (i, len(models)))\n",
    "        print('Model Settings: ', models[i]['clf'])\n",
    "        print('Mean Training Time: ', np.mean(training_time))\n",
    "        print('SD of Training Time: ', np.std(training_time))\n",
    "        print('Mean Accuracy: ', np.mean(accuracy))\n",
    "        print('SD of Accuracy: ', np.std(accuracy))\n",
    "        print('Mean F1 score: ', np.mean(f1))\n",
    "        print('SD of F1 score: ', np.std(f1))\n",
    "        \n",
    "    if needGraph:\n",
    "        plt.plot(xaxis, accuracies, label='accuracy')\n",
    "        plt.plot(xaxis, f1_scores, label='f1 score')\n",
    "        plt.xlabel('Hidden Units')\n",
    "        plt.ylabel('Score')\n",
    "        plt.legend()\n",
    "        plt.savefig('tmp.png')\n",
    "        \n",
    "    print('\\nBest Training Time; ', best_time)\n",
    "    print(time_model)\n",
    "\n",
    "    print('\\nBest accuracy: ', best_acc)\n",
    "    print(acc_model)\n",
    "\n",
    "    print('\\nBest f1 score: ', best_f1)\n",
    "    print(f1_model)\n",
    "    \n",
    "def report_table(models, size=model_sample_size):\n",
    "    table = {}\n",
    "    table['Hidden Unit'] = [1, 2, 4, 8, 16, 32, 64]\n",
    "    table['Mean Time'] = []\n",
    "    table['Std. Time'] = []\n",
    "    table['Mean Accuracy'] = []\n",
    "    table['Std. Accuracy'] = []\n",
    "    table['Mean F1 Score'] = []\n",
    "    table['Std. F1 Score'] = []\n",
    "    \n",
    "    for i in range(0, len(models), size):\n",
    "        scope = np.arange(size)\n",
    "        \n",
    "        # arrays containing each statistics\n",
    "        training_time = [models[i + j]['time'] for j in scope]\n",
    "        accuracy = [(accuracy_score(y_val, models[i + j]['clf'].predict(X_val))) for j in scope]\n",
    "        f1 =       [(f1_score(y_val, models[i + j]['clf'].predict(X_val))) for j in scope]\n",
    "        \n",
    "        table['Mean Time'].append(np.mean(training_time))\n",
    "        table['Std. Time'].append(np.std(training_time))\n",
    "        table['Mean Accuracy'].append(np.mean(accuracy))\n",
    "        table['Std. Accuracy'].append(np.std(accuracy))\n",
    "        table['Mean F1 Score'].append(np.mean(f1))\n",
    "        table['Std. F1 Score'].append(np.std(f1))\n",
    "        \n",
    "    return pd.DataFrame(table)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.002804, T: 640, Avg. loss: 0.530745\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.004999, T: 1280, Avg. loss: 0.473073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.007353, T: 1920, Avg. loss: 0.477698\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.009563, T: 2560, Avg. loss: 0.526879\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.012097, T: 3200, Avg. loss: 0.492399\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.014273, T: 3840, Avg. loss: 0.483501\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.016534, T: 4480, Avg. loss: 0.501115\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.010616064071655273 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.002804, T: 640, Avg. loss: 0.530745\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.004999, T: 1280, Avg. loss: 0.473073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.007353, T: 1920, Avg. loss: 0.477698\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.009563, T: 2560, Avg. loss: 0.526879\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.012097, T: 3200, Avg. loss: 0.492399\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.014273, T: 3840, Avg. loss: 0.483501\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.016534, T: 4480, Avg. loss: 0.501115\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.009141921997070312 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.002804, T: 640, Avg. loss: 0.530745\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.004999, T: 1280, Avg. loss: 0.473073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.007353, T: 1920, Avg. loss: 0.477698\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.009563, T: 2560, Avg. loss: 0.526879\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.012097, T: 3200, Avg. loss: 0.492399\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.014273, T: 3840, Avg. loss: 0.483501\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.016534, T: 4480, Avg. loss: 0.501115\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.005387067794799805 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 2495.55, NNZs: 40, Bias: -173.243886, T: 640, Avg. loss: 30801.248757\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2050.57, NNZs: 43, Bias: -287.332502, T: 1280, Avg. loss: 18969.702448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1652.84, NNZs: 43, Bias: -367.519263, T: 1920, Avg. loss: 14798.941977\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1456.19, NNZs: 43, Bias: -429.450141, T: 2560, Avg. loss: 13148.500053\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1381.34, NNZs: 43, Bias: -483.250401, T: 3200, Avg. loss: 10270.942512\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1567.17, NNZs: 43, Bias: -522.966221, T: 3840, Avg. loss: 8722.036104\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1079.76, NNZs: 43, Bias: -553.762673, T: 4480, Avg. loss: 7476.517176\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1214.10, NNZs: 43, Bias: -595.186474, T: 5120, Avg. loss: 6678.600067\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1278.12, NNZs: 44, Bias: -624.695637, T: 5760, Avg. loss: 5915.409154\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1285.32, NNZs: 44, Bias: -651.612881, T: 6400, Avg. loss: 5752.807953\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1139.73, NNZs: 44, Bias: -675.035744, T: 7040, Avg. loss: 4983.009927\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1112.20, NNZs: 44, Bias: -692.915017, T: 7680, Avg. loss: 4710.982586\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1033.57, NNZs: 44, Bias: -716.356350, T: 8320, Avg. loss: 4034.006958\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 949.86, NNZs: 44, Bias: -735.998619, T: 8960, Avg. loss: 4552.730168\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1030.75, NNZs: 44, Bias: -758.365883, T: 9600, Avg. loss: 4016.078415\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 988.92, NNZs: 44, Bias: -775.763258, T: 10240, Avg. loss: 3432.888311\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1039.65, NNZs: 44, Bias: -792.294392, T: 10880, Avg. loss: 2936.404461\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1010.74, NNZs: 44, Bias: -806.220773, T: 11520, Avg. loss: 2984.979803\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 974.24, NNZs: 44, Bias: -821.803321, T: 12160, Avg. loss: 3316.948645\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 963.70, NNZs: 44, Bias: -835.139095, T: 12800, Avg. loss: 2951.386082\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 970.55, NNZs: 44, Bias: -849.324160, T: 13440, Avg. loss: 2989.667011\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 988.25, NNZs: 44, Bias: -861.529135, T: 14080, Avg. loss: 2281.903736\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 987.73, NNZs: 44, Bias: -871.963436, T: 14720, Avg. loss: 2682.600205\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 976.90, NNZs: 44, Bias: -884.481374, T: 15360, Avg. loss: 2330.265429\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 974.74, NNZs: 44, Bias: -895.322019, T: 16000, Avg. loss: 2155.861475\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 950.52, NNZs: 44, Bias: -905.148129, T: 16640, Avg. loss: 2048.901443\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 961.11, NNZs: 44, Bias: -914.615551, T: 17280, Avg. loss: 2048.271031\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 957.22, NNZs: 44, Bias: -926.464267, T: 17920, Avg. loss: 1869.561717\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 950.08, NNZs: 44, Bias: -936.829761, T: 18560, Avg. loss: 1802.534811\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 980.53, NNZs: 44, Bias: -947.912722, T: 19200, Avg. loss: 1866.771309\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 957.39, NNZs: 44, Bias: -954.247734, T: 19840, Avg. loss: 1798.679859\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 950.76, NNZs: 44, Bias: -963.227196, T: 20480, Avg. loss: 1781.657030\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 945.74, NNZs: 44, Bias: -968.739841, T: 21120, Avg. loss: 1624.041529\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 945.61, NNZs: 44, Bias: -977.686627, T: 21760, Avg. loss: 1596.320191\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 954.60, NNZs: 44, Bias: -985.911547, T: 22400, Avg. loss: 1568.622498\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 945.79, NNZs: 44, Bias: -993.914015, T: 23040, Avg. loss: 1572.932396\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 942.78, NNZs: 44, Bias: -1001.726833, T: 23680, Avg. loss: 1601.846946\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 938.02, NNZs: 44, Bias: -1009.316532, T: 24320, Avg. loss: 1452.959411\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 934.07, NNZs: 44, Bias: -1016.737288, T: 24960, Avg. loss: 1278.891445\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 935.74, NNZs: 44, Bias: -1023.199696, T: 25600, Avg. loss: 1403.652975\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 922.73, NNZs: 44, Bias: -1028.397080, T: 26240, Avg. loss: 1359.303331\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 915.36, NNZs: 44, Bias: -1033.470784, T: 26880, Avg. loss: 1196.712144\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 916.26, NNZs: 44, Bias: -1038.435008, T: 27520, Avg. loss: 1333.135925\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 914.79, NNZs: 44, Bias: -1044.330947, T: 28160, Avg. loss: 1226.511264\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 918.79, NNZs: 44, Bias: -1051.136086, T: 28800, Avg. loss: 1205.729002\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 910.75, NNZs: 44, Bias: -1056.290764, T: 29440, Avg. loss: 1067.009941\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 926.65, NNZs: 44, Bias: -1063.128725, T: 30080, Avg. loss: 1190.628791\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 924.57, NNZs: 44, Bias: -1068.861692, T: 30720, Avg. loss: 1049.310080\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 925.09, NNZs: 44, Bias: -1074.160225, T: 31360, Avg. loss: 1110.357461\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 919.66, NNZs: 44, Bias: -1079.057770, T: 32000, Avg. loss: 1148.884431\n",
      "Total training time: 0.01 seconds.\n",
      "--- training time 0.02319788932800293 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 2495.55, NNZs: 40, Bias: -173.243886, T: 640, Avg. loss: 30801.248757\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2050.57, NNZs: 43, Bias: -287.332502, T: 1280, Avg. loss: 18969.702448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1652.84, NNZs: 43, Bias: -367.519263, T: 1920, Avg. loss: 14798.941977\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1456.19, NNZs: 43, Bias: -429.450141, T: 2560, Avg. loss: 13148.500053\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1381.34, NNZs: 43, Bias: -483.250401, T: 3200, Avg. loss: 10270.942512\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1567.17, NNZs: 43, Bias: -522.966221, T: 3840, Avg. loss: 8722.036104\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1079.76, NNZs: 43, Bias: -553.762673, T: 4480, Avg. loss: 7476.517176\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1214.10, NNZs: 43, Bias: -595.186474, T: 5120, Avg. loss: 6678.600067\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1278.12, NNZs: 44, Bias: -624.695637, T: 5760, Avg. loss: 5915.409154\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1285.32, NNZs: 44, Bias: -651.612881, T: 6400, Avg. loss: 5752.807953\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1139.73, NNZs: 44, Bias: -675.035744, T: 7040, Avg. loss: 4983.009927\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1112.20, NNZs: 44, Bias: -692.915017, T: 7680, Avg. loss: 4710.982586\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1033.57, NNZs: 44, Bias: -716.356350, T: 8320, Avg. loss: 4034.006958\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 949.86, NNZs: 44, Bias: -735.998619, T: 8960, Avg. loss: 4552.730168\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1030.75, NNZs: 44, Bias: -758.365883, T: 9600, Avg. loss: 4016.078415\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 988.92, NNZs: 44, Bias: -775.763258, T: 10240, Avg. loss: 3432.888311\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1039.65, NNZs: 44, Bias: -792.294392, T: 10880, Avg. loss: 2936.404461\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1010.74, NNZs: 44, Bias: -806.220773, T: 11520, Avg. loss: 2984.979803\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 974.24, NNZs: 44, Bias: -821.803321, T: 12160, Avg. loss: 3316.948645\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 963.70, NNZs: 44, Bias: -835.139095, T: 12800, Avg. loss: 2951.386082\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 970.55, NNZs: 44, Bias: -849.324160, T: 13440, Avg. loss: 2989.667011\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 988.25, NNZs: 44, Bias: -861.529135, T: 14080, Avg. loss: 2281.903736\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 987.73, NNZs: 44, Bias: -871.963436, T: 14720, Avg. loss: 2682.600205\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 976.90, NNZs: 44, Bias: -884.481374, T: 15360, Avg. loss: 2330.265429\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 974.74, NNZs: 44, Bias: -895.322019, T: 16000, Avg. loss: 2155.861475\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 950.52, NNZs: 44, Bias: -905.148129, T: 16640, Avg. loss: 2048.901443\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 961.11, NNZs: 44, Bias: -914.615551, T: 17280, Avg. loss: 2048.271031\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 957.22, NNZs: 44, Bias: -926.464267, T: 17920, Avg. loss: 1869.561717\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 950.08, NNZs: 44, Bias: -936.829761, T: 18560, Avg. loss: 1802.534811\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 980.53, NNZs: 44, Bias: -947.912722, T: 19200, Avg. loss: 1866.771309\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 957.39, NNZs: 44, Bias: -954.247734, T: 19840, Avg. loss: 1798.679859\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 950.76, NNZs: 44, Bias: -963.227196, T: 20480, Avg. loss: 1781.657030\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 945.74, NNZs: 44, Bias: -968.739841, T: 21120, Avg. loss: 1624.041529\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 945.61, NNZs: 44, Bias: -977.686627, T: 21760, Avg. loss: 1596.320191\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 954.60, NNZs: 44, Bias: -985.911547, T: 22400, Avg. loss: 1568.622498\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 945.79, NNZs: 44, Bias: -993.914015, T: 23040, Avg. loss: 1572.932396\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 942.78, NNZs: 44, Bias: -1001.726833, T: 23680, Avg. loss: 1601.846946\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 938.02, NNZs: 44, Bias: -1009.316532, T: 24320, Avg. loss: 1452.959411\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 934.07, NNZs: 44, Bias: -1016.737288, T: 24960, Avg. loss: 1278.891445\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 935.74, NNZs: 44, Bias: -1023.199696, T: 25600, Avg. loss: 1403.652975\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 922.73, NNZs: 44, Bias: -1028.397080, T: 26240, Avg. loss: 1359.303331\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 915.36, NNZs: 44, Bias: -1033.470784, T: 26880, Avg. loss: 1196.712144\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 916.26, NNZs: 44, Bias: -1038.435008, T: 27520, Avg. loss: 1333.135925\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 914.79, NNZs: 44, Bias: -1044.330947, T: 28160, Avg. loss: 1226.511264\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 918.79, NNZs: 44, Bias: -1051.136086, T: 28800, Avg. loss: 1205.729002\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 910.75, NNZs: 44, Bias: -1056.290764, T: 29440, Avg. loss: 1067.009941\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 926.65, NNZs: 44, Bias: -1063.128725, T: 30080, Avg. loss: 1190.628791\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 924.57, NNZs: 44, Bias: -1068.861692, T: 30720, Avg. loss: 1049.310080\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 925.09, NNZs: 44, Bias: -1074.160225, T: 31360, Avg. loss: 1110.357461\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 919.66, NNZs: 44, Bias: -1079.057770, T: 32000, Avg. loss: 1148.884431\n",
      "Total training time: 0.01 seconds.\n",
      "--- training time 0.01385498046875 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 2495.55, NNZs: 40, Bias: -173.243886, T: 640, Avg. loss: 30801.248757\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2050.57, NNZs: 43, Bias: -287.332502, T: 1280, Avg. loss: 18969.702448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1652.84, NNZs: 43, Bias: -367.519263, T: 1920, Avg. loss: 14798.941977\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1456.19, NNZs: 43, Bias: -429.450141, T: 2560, Avg. loss: 13148.500053\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1381.34, NNZs: 43, Bias: -483.250401, T: 3200, Avg. loss: 10270.942512\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1567.17, NNZs: 43, Bias: -522.966221, T: 3840, Avg. loss: 8722.036104\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1079.76, NNZs: 43, Bias: -553.762673, T: 4480, Avg. loss: 7476.517176\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1214.10, NNZs: 43, Bias: -595.186474, T: 5120, Avg. loss: 6678.600067\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1278.12, NNZs: 44, Bias: -624.695637, T: 5760, Avg. loss: 5915.409154\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1285.32, NNZs: 44, Bias: -651.612881, T: 6400, Avg. loss: 5752.807953\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1139.73, NNZs: 44, Bias: -675.035744, T: 7040, Avg. loss: 4983.009927\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1112.20, NNZs: 44, Bias: -692.915017, T: 7680, Avg. loss: 4710.982586\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1033.57, NNZs: 44, Bias: -716.356350, T: 8320, Avg. loss: 4034.006958\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 949.86, NNZs: 44, Bias: -735.998619, T: 8960, Avg. loss: 4552.730168\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1030.75, NNZs: 44, Bias: -758.365883, T: 9600, Avg. loss: 4016.078415\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 988.92, NNZs: 44, Bias: -775.763258, T: 10240, Avg. loss: 3432.888311\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1039.65, NNZs: 44, Bias: -792.294392, T: 10880, Avg. loss: 2936.404461\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1010.74, NNZs: 44, Bias: -806.220773, T: 11520, Avg. loss: 2984.979803\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 974.24, NNZs: 44, Bias: -821.803321, T: 12160, Avg. loss: 3316.948645\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 963.70, NNZs: 44, Bias: -835.139095, T: 12800, Avg. loss: 2951.386082\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 970.55, NNZs: 44, Bias: -849.324160, T: 13440, Avg. loss: 2989.667011\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 988.25, NNZs: 44, Bias: -861.529135, T: 14080, Avg. loss: 2281.903736\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 987.73, NNZs: 44, Bias: -871.963436, T: 14720, Avg. loss: 2682.600205\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 976.90, NNZs: 44, Bias: -884.481374, T: 15360, Avg. loss: 2330.265429\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 974.74, NNZs: 44, Bias: -895.322019, T: 16000, Avg. loss: 2155.861475\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 950.52, NNZs: 44, Bias: -905.148129, T: 16640, Avg. loss: 2048.901443\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 961.11, NNZs: 44, Bias: -914.615551, T: 17280, Avg. loss: 2048.271031\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 957.22, NNZs: 44, Bias: -926.464267, T: 17920, Avg. loss: 1869.561717\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 950.08, NNZs: 44, Bias: -936.829761, T: 18560, Avg. loss: 1802.534811\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 980.53, NNZs: 44, Bias: -947.912722, T: 19200, Avg. loss: 1866.771309\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 957.39, NNZs: 44, Bias: -954.247734, T: 19840, Avg. loss: 1798.679859\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 950.76, NNZs: 44, Bias: -963.227196, T: 20480, Avg. loss: 1781.657030\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 945.74, NNZs: 44, Bias: -968.739841, T: 21120, Avg. loss: 1624.041529\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 945.61, NNZs: 44, Bias: -977.686627, T: 21760, Avg. loss: 1596.320191\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 954.60, NNZs: 44, Bias: -985.911547, T: 22400, Avg. loss: 1568.622498\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 945.79, NNZs: 44, Bias: -993.914015, T: 23040, Avg. loss: 1572.932396\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 942.78, NNZs: 44, Bias: -1001.726833, T: 23680, Avg. loss: 1601.846946\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 938.02, NNZs: 44, Bias: -1009.316532, T: 24320, Avg. loss: 1452.959411\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 934.07, NNZs: 44, Bias: -1016.737288, T: 24960, Avg. loss: 1278.891445\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 935.74, NNZs: 44, Bias: -1023.199696, T: 25600, Avg. loss: 1403.652975\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 922.73, NNZs: 44, Bias: -1028.397080, T: 26240, Avg. loss: 1359.303331\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 915.36, NNZs: 44, Bias: -1033.470784, T: 26880, Avg. loss: 1196.712144\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 916.26, NNZs: 44, Bias: -1038.435008, T: 27520, Avg. loss: 1333.135925\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 914.79, NNZs: 44, Bias: -1044.330947, T: 28160, Avg. loss: 1226.511264\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 918.79, NNZs: 44, Bias: -1051.136086, T: 28800, Avg. loss: 1205.729002\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 910.75, NNZs: 44, Bias: -1056.290764, T: 29440, Avg. loss: 1067.009941\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 926.65, NNZs: 44, Bias: -1063.128725, T: 30080, Avg. loss: 1190.628791\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 924.57, NNZs: 44, Bias: -1068.861692, T: 30720, Avg. loss: 1049.310080\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 925.09, NNZs: 44, Bias: -1074.160225, T: 31360, Avg. loss: 1110.357461\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 919.66, NNZs: 44, Bias: -1079.057770, T: 32000, Avg. loss: 1148.884431\n",
      "Total training time: 0.01 seconds.\n",
      "--- training time 0.012463808059692383 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000268, T: 640, Avg. loss: 0.365764\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000371, T: 1280, Avg. loss: 0.356616\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000440, T: 1920, Avg. loss: 0.351156\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000512, T: 2560, Avg. loss: 0.349170\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000571, T: 3200, Avg. loss: 0.344668\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000626, T: 3840, Avg. loss: 0.344730\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000670, T: 4480, Avg. loss: 0.341486\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000723, T: 5120, Avg. loss: 0.340767\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000765, T: 5760, Avg. loss: 0.340707\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000802, T: 6400, Avg. loss: 0.339845\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000839, T: 7040, Avg. loss: 0.338683\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000873, T: 7680, Avg. loss: 0.337827\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000916, T: 8320, Avg. loss: 0.336225\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000941, T: 8960, Avg. loss: 0.336617\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000975, T: 9600, Avg. loss: 0.336643\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001005, T: 10240, Avg. loss: 0.336029\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001040, T: 10880, Avg. loss: 0.334355\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001068, T: 11520, Avg. loss: 0.335234\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001097, T: 12160, Avg. loss: 0.334441\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001120, T: 12800, Avg. loss: 0.334514\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001147, T: 13440, Avg. loss: 0.334017\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001171, T: 14080, Avg. loss: 0.333580\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 22 epochs took 0.01 seconds\n",
      "--- training time 0.010775089263916016 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000268, T: 640, Avg. loss: 0.365764\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000371, T: 1280, Avg. loss: 0.356616\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000440, T: 1920, Avg. loss: 0.351156\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000512, T: 2560, Avg. loss: 0.349170\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000571, T: 3200, Avg. loss: 0.344668\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000626, T: 3840, Avg. loss: 0.344730\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000670, T: 4480, Avg. loss: 0.341486\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000723, T: 5120, Avg. loss: 0.340767\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000765, T: 5760, Avg. loss: 0.340707\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000802, T: 6400, Avg. loss: 0.339845\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000839, T: 7040, Avg. loss: 0.338683\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000873, T: 7680, Avg. loss: 0.337827\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000916, T: 8320, Avg. loss: 0.336225\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000941, T: 8960, Avg. loss: 0.336617\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000975, T: 9600, Avg. loss: 0.336643\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001005, T: 10240, Avg. loss: 0.336029\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001040, T: 10880, Avg. loss: 0.334355\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001068, T: 11520, Avg. loss: 0.335234\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001097, T: 12160, Avg. loss: 0.334441\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001120, T: 12800, Avg. loss: 0.334514\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001147, T: 13440, Avg. loss: 0.334017\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001171, T: 14080, Avg. loss: 0.333580\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 22 epochs took 0.01 seconds\n",
      "--- training time 0.011884927749633789 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000268, T: 640, Avg. loss: 0.365764\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000371, T: 1280, Avg. loss: 0.356616\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000440, T: 1920, Avg. loss: 0.351156\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000512, T: 2560, Avg. loss: 0.349170\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000571, T: 3200, Avg. loss: 0.344668\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000626, T: 3840, Avg. loss: 0.344730\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000670, T: 4480, Avg. loss: 0.341486\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000723, T: 5120, Avg. loss: 0.340767\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000765, T: 5760, Avg. loss: 0.340707\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000802, T: 6400, Avg. loss: 0.339845\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000839, T: 7040, Avg. loss: 0.338683\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000873, T: 7680, Avg. loss: 0.337827\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000916, T: 8320, Avg. loss: 0.336225\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000941, T: 8960, Avg. loss: 0.336617\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000975, T: 9600, Avg. loss: 0.336643\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001005, T: 10240, Avg. loss: 0.336029\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001040, T: 10880, Avg. loss: 0.334355\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001068, T: 11520, Avg. loss: 0.335234\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001097, T: 12160, Avg. loss: 0.334441\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001120, T: 12800, Avg. loss: 0.334514\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001147, T: 13440, Avg. loss: 0.334017\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001171, T: 14080, Avg. loss: 0.333580\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 22 epochs took 0.01 seconds\n",
      "--- training time 0.011651039123535156 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.002804, T: 640, Avg. loss: 0.530745\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.004999, T: 1280, Avg. loss: 0.473073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.007353, T: 1920, Avg. loss: 0.477698\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.009563, T: 2560, Avg. loss: 0.526879\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.012097, T: 3200, Avg. loss: 0.492399\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.014273, T: 3840, Avg. loss: 0.483501\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.016534, T: 4480, Avg. loss: 0.501115\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.016942, T: 5120, Avg. loss: 0.367130\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.017476, T: 5760, Avg. loss: 0.352643\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.017962, T: 6400, Avg. loss: 0.350942\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.018492, T: 7040, Avg. loss: 0.344682\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.018956, T: 7680, Avg. loss: 0.348603\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.019531, T: 8320, Avg. loss: 0.343703\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.019971, T: 8960, Avg. loss: 0.350367\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.020559, T: 9600, Avg. loss: 0.348111\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021010, T: 10240, Avg. loss: 0.348495\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021158, T: 10880, Avg. loss: 0.317506\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021251, T: 11520, Avg. loss: 0.324189\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021362, T: 12160, Avg. loss: 0.320888\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021453, T: 12800, Avg. loss: 0.324178\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021557, T: 13440, Avg. loss: 0.322479\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021656, T: 14080, Avg. loss: 0.321282\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021682, T: 14720, Avg. loss: 0.318814\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021707, T: 15360, Avg. loss: 0.317611\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021731, T: 16000, Avg. loss: 0.317027\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021748, T: 16640, Avg. loss: 0.318004\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021771, T: 17280, Avg. loss: 0.317610\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 27 epochs took 0.01 seconds\n",
      "--- training time 0.012527227401733398 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.002804, T: 640, Avg. loss: 0.530745\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.004999, T: 1280, Avg. loss: 0.473073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.007353, T: 1920, Avg. loss: 0.477698\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.009563, T: 2560, Avg. loss: 0.526879\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.012097, T: 3200, Avg. loss: 0.492399\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.014273, T: 3840, Avg. loss: 0.483501\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.016534, T: 4480, Avg. loss: 0.501115\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.016942, T: 5120, Avg. loss: 0.367130\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.017476, T: 5760, Avg. loss: 0.352643\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.017962, T: 6400, Avg. loss: 0.350942\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.018492, T: 7040, Avg. loss: 0.344682\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.018956, T: 7680, Avg. loss: 0.348603\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.019531, T: 8320, Avg. loss: 0.343703\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.019971, T: 8960, Avg. loss: 0.350367\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.020559, T: 9600, Avg. loss: 0.348111\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021010, T: 10240, Avg. loss: 0.348495\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021158, T: 10880, Avg. loss: 0.317506\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021251, T: 11520, Avg. loss: 0.324189\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021362, T: 12160, Avg. loss: 0.320888\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021453, T: 12800, Avg. loss: 0.324178\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021557, T: 13440, Avg. loss: 0.322479\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021656, T: 14080, Avg. loss: 0.321282\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021682, T: 14720, Avg. loss: 0.318814\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021707, T: 15360, Avg. loss: 0.317611\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021731, T: 16000, Avg. loss: 0.317027\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021748, T: 16640, Avg. loss: 0.318004\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021771, T: 17280, Avg. loss: 0.317610\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 27 epochs took 0.01 seconds\n",
      "--- training time 0.010582923889160156 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.002804, T: 640, Avg. loss: 0.530745\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.004999, T: 1280, Avg. loss: 0.473073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.007353, T: 1920, Avg. loss: 0.477698\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.009563, T: 2560, Avg. loss: 0.526879\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.012097, T: 3200, Avg. loss: 0.492399\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.014273, T: 3840, Avg. loss: 0.483501\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.016534, T: 4480, Avg. loss: 0.501115\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.016942, T: 5120, Avg. loss: 0.367130\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.017476, T: 5760, Avg. loss: 0.352643\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.017962, T: 6400, Avg. loss: 0.350942\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.018492, T: 7040, Avg. loss: 0.344682\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.018956, T: 7680, Avg. loss: 0.348603\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.019531, T: 8320, Avg. loss: 0.343703\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.019971, T: 8960, Avg. loss: 0.350367\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.020559, T: 9600, Avg. loss: 0.348111\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021010, T: 10240, Avg. loss: 0.348495\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021158, T: 10880, Avg. loss: 0.317506\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021251, T: 11520, Avg. loss: 0.324189\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021362, T: 12160, Avg. loss: 0.320888\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021453, T: 12800, Avg. loss: 0.324178\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021557, T: 13440, Avg. loss: 0.322479\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021656, T: 14080, Avg. loss: 0.321282\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021682, T: 14720, Avg. loss: 0.318814\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021707, T: 15360, Avg. loss: 0.317611\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021731, T: 16000, Avg. loss: 0.317027\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021748, T: 16640, Avg. loss: 0.318004\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021771, T: 17280, Avg. loss: 0.317610\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 27 epochs took 0.02 seconds\n",
      "--- training time 0.02485799789428711 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.021067, T: 640, Avg. loss: 3.984145\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.48, NNZs: 44, Bias: -0.040317, T: 1280, Avg. loss: 3.222851\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.059537, T: 1920, Avg. loss: 3.644051\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.50, NNZs: 44, Bias: -0.078804, T: 2560, Avg. loss: 4.137911\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.45, NNZs: 44, Bias: -0.098773, T: 3200, Avg. loss: 3.813206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.74, NNZs: 44, Bias: -0.116994, T: 3840, Avg. loss: 3.862541\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.70, NNZs: 44, Bias: -0.135162, T: 4480, Avg. loss: 3.740942\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.004497051239013672 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.021067, T: 640, Avg. loss: 3.984145\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.48, NNZs: 44, Bias: -0.040317, T: 1280, Avg. loss: 3.222851\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.059537, T: 1920, Avg. loss: 3.644051\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.50, NNZs: 44, Bias: -0.078804, T: 2560, Avg. loss: 4.137911\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.45, NNZs: 44, Bias: -0.098773, T: 3200, Avg. loss: 3.813206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.74, NNZs: 44, Bias: -0.116994, T: 3840, Avg. loss: 3.862541\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.70, NNZs: 44, Bias: -0.135162, T: 4480, Avg. loss: 3.740942\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.00464630126953125 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.021067, T: 640, Avg. loss: 3.984145\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.48, NNZs: 44, Bias: -0.040317, T: 1280, Avg. loss: 3.222851\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.059537, T: 1920, Avg. loss: 3.644051\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.50, NNZs: 44, Bias: -0.078804, T: 2560, Avg. loss: 4.137911\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.45, NNZs: 44, Bias: -0.098773, T: 3200, Avg. loss: 3.813206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.74, NNZs: 44, Bias: -0.116994, T: 3840, Avg. loss: 3.862541\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.70, NNZs: 44, Bias: -0.135162, T: 4480, Avg. loss: 3.740942\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.004644155502319336 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 500.74, NNZs: 40, Bias: -52.512065, T: 640, Avg. loss: 8966.903966\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 320.78, NNZs: 43, Bias: -72.608925, T: 1280, Avg. loss: 3357.209314\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 230.09, NNZs: 43, Bias: -84.340473, T: 1920, Avg. loss: 2166.524856\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 189.36, NNZs: 43, Bias: -92.661941, T: 2560, Avg. loss: 1764.310331\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 168.40, NNZs: 44, Bias: -99.779847, T: 3200, Avg. loss: 1306.004672\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 202.15, NNZs: 44, Bias: -104.232835, T: 3840, Avg. loss: 995.721480\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 137.92, NNZs: 44, Bias: -108.116835, T: 4480, Avg. loss: 926.979040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 151.23, NNZs: 44, Bias: -112.749757, T: 5120, Avg. loss: 746.909156\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 148.27, NNZs: 44, Bias: -116.665804, T: 5760, Avg. loss: 699.113288\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 153.32, NNZs: 44, Bias: -119.708379, T: 6400, Avg. loss: 599.858419\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 133.29, NNZs: 44, Bias: -122.480550, T: 7040, Avg. loss: 555.386621\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 126.49, NNZs: 44, Bias: -124.739493, T: 7680, Avg. loss: 528.065646\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 117.66, NNZs: 44, Bias: -127.544830, T: 8320, Avg. loss: 475.009744\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 109.57, NNZs: 44, Bias: -129.587971, T: 8960, Avg. loss: 491.862829\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 106.81, NNZs: 44, Bias: -131.703656, T: 9600, Avg. loss: 446.339582\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 112.49, NNZs: 44, Bias: -133.685142, T: 10240, Avg. loss: 363.660773\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 115.80, NNZs: 44, Bias: -135.462435, T: 10880, Avg. loss: 317.797125\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 114.90, NNZs: 44, Bias: -137.127378, T: 11520, Avg. loss: 313.789935\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 105.54, NNZs: 44, Bias: -138.791050, T: 12160, Avg. loss: 348.313547\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 104.84, NNZs: 44, Bias: -140.210565, T: 12800, Avg. loss: 334.727113\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 107.89, NNZs: 44, Bias: -141.560703, T: 13440, Avg. loss: 298.511347\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 100.53, NNZs: 44, Bias: -142.568970, T: 14080, Avg. loss: 257.251948\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 104.61, NNZs: 44, Bias: -143.586413, T: 14720, Avg. loss: 250.219567\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 105.06, NNZs: 44, Bias: -144.970692, T: 15360, Avg. loss: 247.542619\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 100.92, NNZs: 44, Bias: -146.237201, T: 16000, Avg. loss: 248.501058\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 100.15, NNZs: 44, Bias: -147.451414, T: 16640, Avg. loss: 225.751338\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 103.35, NNZs: 44, Bias: -148.561394, T: 17280, Avg. loss: 212.981286\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 100.88, NNZs: 44, Bias: -149.463165, T: 17920, Avg. loss: 191.596918\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 101.96, NNZs: 44, Bias: -150.548571, T: 18560, Avg. loss: 189.725798\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 103.52, NNZs: 44, Bias: -151.611007, T: 19200, Avg. loss: 183.233201\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 102.28, NNZs: 44, Bias: -152.380246, T: 19840, Avg. loss: 201.349287\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 101.43, NNZs: 44, Bias: -153.315040, T: 20480, Avg. loss: 194.863840\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 98.98, NNZs: 44, Bias: -153.983702, T: 21120, Avg. loss: 169.953737\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 98.06, NNZs: 44, Bias: -154.831632, T: 21760, Avg. loss: 173.155293\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 99.43, NNZs: 44, Bias: -155.729074, T: 22400, Avg. loss: 155.416821\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 100.79, NNZs: 44, Bias: -156.597047, T: 23040, Avg. loss: 153.429602\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 97.84, NNZs: 44, Bias: -157.191383, T: 23680, Avg. loss: 159.924902\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 97.13, NNZs: 44, Bias: -157.891737, T: 24320, Avg. loss: 148.308670\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 97.03, NNZs: 44, Bias: -158.613327, T: 24960, Avg. loss: 133.659802\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 96.85, NNZs: 44, Bias: -159.227607, T: 25600, Avg. loss: 145.577644\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 95.71, NNZs: 44, Bias: -159.751561, T: 26240, Avg. loss: 132.080117\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 95.59, NNZs: 44, Bias: -160.375331, T: 26880, Avg. loss: 117.890443\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 96.42, NNZs: 44, Bias: -160.953157, T: 27520, Avg. loss: 134.577507\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 95.09, NNZs: 44, Bias: -161.520962, T: 28160, Avg. loss: 136.019925\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 94.90, NNZs: 44, Bias: -162.150253, T: 28800, Avg. loss: 127.672971\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 94.33, NNZs: 44, Bias: -162.662278, T: 29440, Avg. loss: 127.475931\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 95.54, NNZs: 44, Bias: -163.365363, T: 30080, Avg. loss: 123.089532\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 47 epochs took 0.01 seconds\n",
      "--- training time 0.01205301284790039 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 500.74, NNZs: 40, Bias: -52.512065, T: 640, Avg. loss: 8966.903966\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 320.78, NNZs: 43, Bias: -72.608925, T: 1280, Avg. loss: 3357.209314\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 230.09, NNZs: 43, Bias: -84.340473, T: 1920, Avg. loss: 2166.524856\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 189.36, NNZs: 43, Bias: -92.661941, T: 2560, Avg. loss: 1764.310331\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 168.40, NNZs: 44, Bias: -99.779847, T: 3200, Avg. loss: 1306.004672\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 202.15, NNZs: 44, Bias: -104.232835, T: 3840, Avg. loss: 995.721480\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 137.92, NNZs: 44, Bias: -108.116835, T: 4480, Avg. loss: 926.979040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 151.23, NNZs: 44, Bias: -112.749757, T: 5120, Avg. loss: 746.909156\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 148.27, NNZs: 44, Bias: -116.665804, T: 5760, Avg. loss: 699.113288\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 153.32, NNZs: 44, Bias: -119.708379, T: 6400, Avg. loss: 599.858419\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 133.29, NNZs: 44, Bias: -122.480550, T: 7040, Avg. loss: 555.386621\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 126.49, NNZs: 44, Bias: -124.739493, T: 7680, Avg. loss: 528.065646\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 117.66, NNZs: 44, Bias: -127.544830, T: 8320, Avg. loss: 475.009744\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 109.57, NNZs: 44, Bias: -129.587971, T: 8960, Avg. loss: 491.862829\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 106.81, NNZs: 44, Bias: -131.703656, T: 9600, Avg. loss: 446.339582\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 112.49, NNZs: 44, Bias: -133.685142, T: 10240, Avg. loss: 363.660773\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 115.80, NNZs: 44, Bias: -135.462435, T: 10880, Avg. loss: 317.797125\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 114.90, NNZs: 44, Bias: -137.127378, T: 11520, Avg. loss: 313.789935\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 105.54, NNZs: 44, Bias: -138.791050, T: 12160, Avg. loss: 348.313547\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 104.84, NNZs: 44, Bias: -140.210565, T: 12800, Avg. loss: 334.727113\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 107.89, NNZs: 44, Bias: -141.560703, T: 13440, Avg. loss: 298.511347\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 100.53, NNZs: 44, Bias: -142.568970, T: 14080, Avg. loss: 257.251948\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 104.61, NNZs: 44, Bias: -143.586413, T: 14720, Avg. loss: 250.219567\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 105.06, NNZs: 44, Bias: -144.970692, T: 15360, Avg. loss: 247.542619\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 100.92, NNZs: 44, Bias: -146.237201, T: 16000, Avg. loss: 248.501058\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 100.15, NNZs: 44, Bias: -147.451414, T: 16640, Avg. loss: 225.751338\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 103.35, NNZs: 44, Bias: -148.561394, T: 17280, Avg. loss: 212.981286\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 100.88, NNZs: 44, Bias: -149.463165, T: 17920, Avg. loss: 191.596918\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 101.96, NNZs: 44, Bias: -150.548571, T: 18560, Avg. loss: 189.725798\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 103.52, NNZs: 44, Bias: -151.611007, T: 19200, Avg. loss: 183.233201\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 102.28, NNZs: 44, Bias: -152.380246, T: 19840, Avg. loss: 201.349287\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 101.43, NNZs: 44, Bias: -153.315040, T: 20480, Avg. loss: 194.863840\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 98.98, NNZs: 44, Bias: -153.983702, T: 21120, Avg. loss: 169.953737\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 98.06, NNZs: 44, Bias: -154.831632, T: 21760, Avg. loss: 173.155293\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 99.43, NNZs: 44, Bias: -155.729074, T: 22400, Avg. loss: 155.416821\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 100.79, NNZs: 44, Bias: -156.597047, T: 23040, Avg. loss: 153.429602\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 97.84, NNZs: 44, Bias: -157.191383, T: 23680, Avg. loss: 159.924902\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 97.13, NNZs: 44, Bias: -157.891737, T: 24320, Avg. loss: 148.308670\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 97.03, NNZs: 44, Bias: -158.613327, T: 24960, Avg. loss: 133.659802\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 96.85, NNZs: 44, Bias: -159.227607, T: 25600, Avg. loss: 145.577644\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 95.71, NNZs: 44, Bias: -159.751561, T: 26240, Avg. loss: 132.080117\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 95.59, NNZs: 44, Bias: -160.375331, T: 26880, Avg. loss: 117.890443\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 96.42, NNZs: 44, Bias: -160.953157, T: 27520, Avg. loss: 134.577507\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 95.09, NNZs: 44, Bias: -161.520962, T: 28160, Avg. loss: 136.019925\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 94.90, NNZs: 44, Bias: -162.150253, T: 28800, Avg. loss: 127.672971\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 94.33, NNZs: 44, Bias: -162.662278, T: 29440, Avg. loss: 127.475931\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 95.54, NNZs: 44, Bias: -163.365363, T: 30080, Avg. loss: 123.089532\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 47 epochs took 0.01 seconds\n",
      "--- training time 0.01224207878112793 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 500.74, NNZs: 40, Bias: -52.512065, T: 640, Avg. loss: 8966.903966\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 320.78, NNZs: 43, Bias: -72.608925, T: 1280, Avg. loss: 3357.209314\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 230.09, NNZs: 43, Bias: -84.340473, T: 1920, Avg. loss: 2166.524856\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 189.36, NNZs: 43, Bias: -92.661941, T: 2560, Avg. loss: 1764.310331\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 168.40, NNZs: 44, Bias: -99.779847, T: 3200, Avg. loss: 1306.004672\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 202.15, NNZs: 44, Bias: -104.232835, T: 3840, Avg. loss: 995.721480\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 137.92, NNZs: 44, Bias: -108.116835, T: 4480, Avg. loss: 926.979040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 151.23, NNZs: 44, Bias: -112.749757, T: 5120, Avg. loss: 746.909156\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 148.27, NNZs: 44, Bias: -116.665804, T: 5760, Avg. loss: 699.113288\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 153.32, NNZs: 44, Bias: -119.708379, T: 6400, Avg. loss: 599.858419\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 133.29, NNZs: 44, Bias: -122.480550, T: 7040, Avg. loss: 555.386621\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 126.49, NNZs: 44, Bias: -124.739493, T: 7680, Avg. loss: 528.065646\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 117.66, NNZs: 44, Bias: -127.544830, T: 8320, Avg. loss: 475.009744\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 109.57, NNZs: 44, Bias: -129.587971, T: 8960, Avg. loss: 491.862829\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 106.81, NNZs: 44, Bias: -131.703656, T: 9600, Avg. loss: 446.339582\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 112.49, NNZs: 44, Bias: -133.685142, T: 10240, Avg. loss: 363.660773\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 115.80, NNZs: 44, Bias: -135.462435, T: 10880, Avg. loss: 317.797125\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 114.90, NNZs: 44, Bias: -137.127378, T: 11520, Avg. loss: 313.789935\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 105.54, NNZs: 44, Bias: -138.791050, T: 12160, Avg. loss: 348.313547\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 104.84, NNZs: 44, Bias: -140.210565, T: 12800, Avg. loss: 334.727113\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 107.89, NNZs: 44, Bias: -141.560703, T: 13440, Avg. loss: 298.511347\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 100.53, NNZs: 44, Bias: -142.568970, T: 14080, Avg. loss: 257.251948\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 104.61, NNZs: 44, Bias: -143.586413, T: 14720, Avg. loss: 250.219567\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 105.06, NNZs: 44, Bias: -144.970692, T: 15360, Avg. loss: 247.542619\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 100.92, NNZs: 44, Bias: -146.237201, T: 16000, Avg. loss: 248.501058"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 100.15, NNZs: 44, Bias: -147.451414, T: 16640, Avg. loss: 225.751338\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 103.35, NNZs: 44, Bias: -148.561394, T: 17280, Avg. loss: 212.981286\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 100.88, NNZs: 44, Bias: -149.463165, T: 17920, Avg. loss: 191.596918\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 101.96, NNZs: 44, Bias: -150.548571, T: 18560, Avg. loss: 189.725798\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 103.52, NNZs: 44, Bias: -151.611007, T: 19200, Avg. loss: 183.233201\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 102.28, NNZs: 44, Bias: -152.380246, T: 19840, Avg. loss: 201.349287\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 101.43, NNZs: 44, Bias: -153.315040, T: 20480, Avg. loss: 194.863840\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 98.98, NNZs: 44, Bias: -153.983702, T: 21120, Avg. loss: 169.953737\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 98.06, NNZs: 44, Bias: -154.831632, T: 21760, Avg. loss: 173.155293\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 99.43, NNZs: 44, Bias: -155.729074, T: 22400, Avg. loss: 155.416821\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 100.79, NNZs: 44, Bias: -156.597047, T: 23040, Avg. loss: 153.429602\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 97.84, NNZs: 44, Bias: -157.191383, T: 23680, Avg. loss: 159.924902\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 97.13, NNZs: 44, Bias: -157.891737, T: 24320, Avg. loss: 148.308670\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 97.03, NNZs: 44, Bias: -158.613327, T: 24960, Avg. loss: 133.659802\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 96.85, NNZs: 44, Bias: -159.227607, T: 25600, Avg. loss: 145.577644\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 95.71, NNZs: 44, Bias: -159.751561, T: 26240, Avg. loss: 132.080117\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 95.59, NNZs: 44, Bias: -160.375331, T: 26880, Avg. loss: 117.890443\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 96.42, NNZs: 44, Bias: -160.953157, T: 27520, Avg. loss: 134.577507\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 95.09, NNZs: 44, Bias: -161.520962, T: 28160, Avg. loss: 136.019925\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 94.90, NNZs: 44, Bias: -162.150253, T: 28800, Avg. loss: 127.672971\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 94.33, NNZs: 44, Bias: -162.662278, T: 29440, Avg. loss: 127.475931\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 95.54, NNZs: 44, Bias: -163.365363, T: 30080, Avg. loss: 123.089532\n",
      "Total training time: 0.06 seconds.\n",
      "Convergence after 47 epochs took 0.06 seconds\n",
      "--- training time 0.059654951095581055 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.04, NNZs: 44, Bias: -0.001716, T: 640, Avg. loss: 0.494289\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.04, NNZs: 44, Bias: -0.002572, T: 1280, Avg. loss: 0.364677\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.003237, T: 1920, Avg. loss: 0.349521\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.003750, T: 2560, Avg. loss: 0.365191\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.004277, T: 3200, Avg. loss: 0.343723\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.004730, T: 3840, Avg. loss: 0.350922\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005132, T: 4480, Avg. loss: 0.338571\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005522, T: 5120, Avg. loss: 0.343426\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005915, T: 5760, Avg. loss: 0.344485\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006246, T: 6400, Avg. loss: 0.344850\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006582, T: 7040, Avg. loss: 0.339307\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006865, T: 7680, Avg. loss: 0.340507\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 12 epochs took 0.00 seconds\n",
      "--- training time 0.007585763931274414 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.04, NNZs: 44, Bias: -0.001716, T: 640, Avg. loss: 0.494289\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.04, NNZs: 44, Bias: -0.002572, T: 1280, Avg. loss: 0.364677\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.003237, T: 1920, Avg. loss: 0.349521\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.003750, T: 2560, Avg. loss: 0.365191\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.004277, T: 3200, Avg. loss: 0.343723\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.004730, T: 3840, Avg. loss: 0.350922\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005132, T: 4480, Avg. loss: 0.338571\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005522, T: 5120, Avg. loss: 0.343426\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005915, T: 5760, Avg. loss: 0.344485\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006246, T: 6400, Avg. loss: 0.344850\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006582, T: 7040, Avg. loss: 0.339307\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006865, T: 7680, Avg. loss: 0.340507\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 12 epochs took 0.00 seconds\n",
      "--- training time 0.007024049758911133 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.04, NNZs: 44, Bias: -0.001716, T: 640, Avg. loss: 0.494289\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.04, NNZs: 44, Bias: -0.002572, T: 1280, Avg. loss: 0.364677\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.003237, T: 1920, Avg. loss: 0.349521\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.003750, T: 2560, Avg. loss: 0.365191\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.004277, T: 3200, Avg. loss: 0.343723\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.004730, T: 3840, Avg. loss: 0.350922\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005132, T: 4480, Avg. loss: 0.338571\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005522, T: 5120, Avg. loss: 0.343426\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005915, T: 5760, Avg. loss: 0.344485\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006246, T: 6400, Avg. loss: 0.344850\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006582, T: 7040, Avg. loss: 0.339307\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006865, T: 7680, Avg. loss: 0.340507\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 12 epochs took 0.00 seconds\n",
      "--- training time 0.0064923763275146484 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.021067, T: 640, Avg. loss: 3.984145\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.48, NNZs: 44, Bias: -0.040317, T: 1280, Avg. loss: 3.222851\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.059537, T: 1920, Avg. loss: 3.644051\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.50, NNZs: 44, Bias: -0.078804, T: 2560, Avg. loss: 4.137911\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.45, NNZs: 44, Bias: -0.098773, T: 3200, Avg. loss: 3.813206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.74, NNZs: 44, Bias: -0.116994, T: 3840, Avg. loss: 3.862541\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.70, NNZs: 44, Bias: -0.135162, T: 4480, Avg. loss: 3.740942\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.138026, T: 5120, Avg. loss: 1.398175\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.51, NNZs: 44, Bias: -0.141678, T: 5760, Avg. loss: 0.953206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.52, NNZs: 44, Bias: -0.145249, T: 6400, Avg. loss: 0.784679\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.52, NNZs: 44, Bias: -0.149089, T: 7040, Avg. loss: 0.727688\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.53, NNZs: 44, Bias: -0.152845, T: 7680, Avg. loss: 0.727317\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.54, NNZs: 44, Bias: -0.156963, T: 8320, Avg. loss: 0.685719\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.55, NNZs: 44, Bias: -0.160600, T: 8960, Avg. loss: 0.805217\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.165141, T: 9600, Avg. loss: 0.780246\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.57, NNZs: 44, Bias: -0.168779, T: 10240, Avg. loss: 0.745140\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.59, NNZs: 44, Bias: -0.173353, T: 10880, Avg. loss: 0.668678\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.60, NNZs: 44, Bias: -0.177487, T: 11520, Avg. loss: 0.741204\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.61, NNZs: 44, Bias: -0.181503, T: 12160, Avg. loss: 0.770187\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.62, NNZs: 44, Bias: -0.185364, T: 12800, Avg. loss: 0.800654\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.63, NNZs: 44, Bias: -0.189288, T: 13440, Avg. loss: 0.788337\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.193096, T: 14080, Avg. loss: 0.677807\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.193678, T: 14720, Avg. loss: 0.353993\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.194425, T: 15360, Avg. loss: 0.313918\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.195239, T: 16000, Avg. loss: 0.305386\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.195940, T: 16640, Avg. loss: 0.306292\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.196674, T: 17280, Avg. loss: 0.298847\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.197423, T: 17920, Avg. loss: 0.304501\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.198198, T: 18560, Avg. loss: 0.304672\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.199014, T: 19200, Avg. loss: 0.298193\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.199779, T: 19840, Avg. loss: 0.313134\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200556, T: 20480, Avg. loss: 0.311360\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200677, T: 21120, Avg. loss: 0.266225\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200840, T: 21760, Avg. loss: 0.258514\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200990, T: 22400, Avg. loss: 0.262786\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.201148, T: 23040, Avg. loss: 0.263645\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.201312, T: 23680, Avg. loss: 0.266481\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201486, T: 24320, Avg. loss: 0.261895\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201651, T: 24960, Avg. loss: 0.259777\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201667, T: 25600, Avg. loss: 0.260109\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201695, T: 26240, Avg. loss: 0.254555\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201730, T: 26880, Avg. loss: 0.254708\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201758, T: 27520, Avg. loss: 0.254875\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201796, T: 28160, Avg. loss: 0.254540\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201830, T: 28800, Avg. loss: 0.254008\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201855, T: 29440, Avg. loss: 0.255364\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201862, T: 30080, Avg. loss: 0.252925\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201869, T: 30720, Avg. loss: 0.252909\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201875, T: 31360, Avg. loss: 0.252805\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201882, T: 32000, Avg. loss: 0.252968\n",
      "Total training time: 0.01 seconds.\n",
      "--- training time 0.018023014068603516 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.021067, T: 640, Avg. loss: 3.984145\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.48, NNZs: 44, Bias: -0.040317, T: 1280, Avg. loss: 3.222851\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.059537, T: 1920, Avg. loss: 3.644051\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.50, NNZs: 44, Bias: -0.078804, T: 2560, Avg. loss: 4.137911\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.45, NNZs: 44, Bias: -0.098773, T: 3200, Avg. loss: 3.813206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.74, NNZs: 44, Bias: -0.116994, T: 3840, Avg. loss: 3.862541\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.70, NNZs: 44, Bias: -0.135162, T: 4480, Avg. loss: 3.740942\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.138026, T: 5120, Avg. loss: 1.398175\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.51, NNZs: 44, Bias: -0.141678, T: 5760, Avg. loss: 0.953206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.52, NNZs: 44, Bias: -0.145249, T: 6400, Avg. loss: 0.784679\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.52, NNZs: 44, Bias: -0.149089, T: 7040, Avg. loss: 0.727688\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.53, NNZs: 44, Bias: -0.152845, T: 7680, Avg. loss: 0.727317\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.54, NNZs: 44, Bias: -0.156963, T: 8320, Avg. loss: 0.685719\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.55, NNZs: 44, Bias: -0.160600, T: 8960, Avg. loss: 0.805217\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.165141, T: 9600, Avg. loss: 0.780246\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.57, NNZs: 44, Bias: -0.168779, T: 10240, Avg. loss: 0.745140\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.59, NNZs: 44, Bias: -0.173353, T: 10880, Avg. loss: 0.668678\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.60, NNZs: 44, Bias: -0.177487, T: 11520, Avg. loss: 0.741204\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.61, NNZs: 44, Bias: -0.181503, T: 12160, Avg. loss: 0.770187\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.62, NNZs: 44, Bias: -0.185364, T: 12800, Avg. loss: 0.800654\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.63, NNZs: 44, Bias: -0.189288, T: 13440, Avg. loss: 0.788337\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.193096, T: 14080, Avg. loss: 0.677807\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.193678, T: 14720, Avg. loss: 0.353993\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.194425, T: 15360, Avg. loss: 0.313918\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.195239, T: 16000, Avg. loss: 0.305386\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.195940, T: 16640, Avg. loss: 0.306292\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.196674, T: 17280, Avg. loss: 0.298847\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.197423, T: 17920, Avg. loss: 0.304501\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.198198, T: 18560, Avg. loss: 0.304672\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.199014, T: 19200, Avg. loss: 0.298193\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.199779, T: 19840, Avg. loss: 0.313134\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200556, T: 20480, Avg. loss: 0.311360\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200677, T: 21120, Avg. loss: 0.266225\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200840, T: 21760, Avg. loss: 0.258514\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200990, T: 22400, Avg. loss: 0.262786\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.201148, T: 23040, Avg. loss: 0.263645\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.201312, T: 23680, Avg. loss: 0.266481\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201486, T: 24320, Avg. loss: 0.261895\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201651, T: 24960, Avg. loss: 0.259777\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201667, T: 25600, Avg. loss: 0.260109\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201695, T: 26240, Avg. loss: 0.254555\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201730, T: 26880, Avg. loss: 0.254708\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201758, T: 27520, Avg. loss: 0.254875\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201796, T: 28160, Avg. loss: 0.254540\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201830, T: 28800, Avg. loss: 0.254008\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201855, T: 29440, Avg. loss: 0.255364\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201862, T: 30080, Avg. loss: 0.252925\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201869, T: 30720, Avg. loss: 0.252909\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201875, T: 31360, Avg. loss: 0.252805\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201882, T: 32000, Avg. loss: 0.252968\n",
      "Total training time: 0.01 seconds.\n",
      "--- training time 0.018049001693725586 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.021067, T: 640, Avg. loss: 3.984145\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.48, NNZs: 44, Bias: -0.040317, T: 1280, Avg. loss: 3.222851\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.059537, T: 1920, Avg. loss: 3.644051\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.50, NNZs: 44, Bias: -0.078804, T: 2560, Avg. loss: 4.137911\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.45, NNZs: 44, Bias: -0.098773, T: 3200, Avg. loss: 3.813206\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.74, NNZs: 44, Bias: -0.116994, T: 3840, Avg. loss: 3.862541\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.70, NNZs: 44, Bias: -0.135162, T: 4480, Avg. loss: 3.740942\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.138026, T: 5120, Avg. loss: 1.398175\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.51, NNZs: 44, Bias: -0.141678, T: 5760, Avg. loss: 0.953206\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.52, NNZs: 44, Bias: -0.145249, T: 6400, Avg. loss: 0.784679\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.52, NNZs: 44, Bias: -0.149089, T: 7040, Avg. loss: 0.727688\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.53, NNZs: 44, Bias: -0.152845, T: 7680, Avg. loss: 0.727317\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.54, NNZs: 44, Bias: -0.156963, T: 8320, Avg. loss: 0.685719\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.55, NNZs: 44, Bias: -0.160600, T: 8960, Avg. loss: 0.805217\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.165141, T: 9600, Avg. loss: 0.780246\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.57, NNZs: 44, Bias: -0.168779, T: 10240, Avg. loss: 0.745140\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.59, NNZs: 44, Bias: -0.173353, T: 10880, Avg. loss: 0.668678\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.60, NNZs: 44, Bias: -0.177487, T: 11520, Avg. loss: 0.741204\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.61, NNZs: 44, Bias: -0.181503, T: 12160, Avg. loss: 0.770187\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.62, NNZs: 44, Bias: -0.185364, T: 12800, Avg. loss: 0.800654\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.63, NNZs: 44, Bias: -0.189288, T: 13440, Avg. loss: 0.788337\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.193096, T: 14080, Avg. loss: 0.677807\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.193678, T: 14720, Avg. loss: 0.353993\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.194425, T: 15360, Avg. loss: 0.313918\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.195239, T: 16000, Avg. loss: 0.305386\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.195940, T: 16640, Avg. loss: 0.306292\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.196674, T: 17280, Avg. loss: 0.298847\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.197423, T: 17920, Avg. loss: 0.304501\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.198198, T: 18560, Avg. loss: 0.304672\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.199014, T: 19200, Avg. loss: 0.298193\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.199779, T: 19840, Avg. loss: 0.313134\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200556, T: 20480, Avg. loss: 0.311360\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200677, T: 21120, Avg. loss: 0.266225\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200840, T: 21760, Avg. loss: 0.258514\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200990, T: 22400, Avg. loss: 0.262786\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.201148, T: 23040, Avg. loss: 0.263645\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.201312, T: 23680, Avg. loss: 0.266481\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201486, T: 24320, Avg. loss: 0.261895\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201651, T: 24960, Avg. loss: 0.259777\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201667, T: 25600, Avg. loss: 0.260109\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201695, T: 26240, Avg. loss: 0.254555\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201730, T: 26880, Avg. loss: 0.254708\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201758, T: 27520, Avg. loss: 0.254875\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201796, T: 28160, Avg. loss: 0.254540\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201830, T: 28800, Avg. loss: 0.254008\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201855, T: 29440, Avg. loss: 0.255364\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201862, T: 30080, Avg. loss: 0.252925\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201869, T: 30720, Avg. loss: 0.252909\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201875, T: 31360, Avg. loss: 0.252805\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201882, T: 32000, Avg. loss: 0.252968\n",
      "Total training time: 0.03 seconds.\n",
      "--- training time 0.038826942443847656 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 3.92, NNZs: 44, Bias: -0.229017, T: 640, Avg. loss: 39.588520\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.22, NNZs: 44, Bias: -0.412678, T: 1280, Avg. loss: 36.358448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.77, NNZs: 44, Bias: -0.608724, T: 1920, Avg. loss: 37.326056\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.16, NNZs: 44, Bias: -0.820996, T: 2560, Avg. loss: 41.772040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.046754, T: 3200, Avg. loss: 40.525607\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.70, NNZs: 44, Bias: -1.233228, T: 3840, Avg. loss: 39.758304\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 6.79, NNZs: 44, Bias: -1.422213, T: 4480, Avg. loss: 39.742680\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.006770133972167969 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 3.92, NNZs: 44, Bias: -0.229017, T: 640, Avg. loss: 39.588520\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.22, NNZs: 44, Bias: -0.412678, T: 1280, Avg. loss: 36.358448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.77, NNZs: 44, Bias: -0.608724, T: 1920, Avg. loss: 37.326056\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.16, NNZs: 44, Bias: -0.820996, T: 2560, Avg. loss: 41.772040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.046754, T: 3200, Avg. loss: 40.525607\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.70, NNZs: 44, Bias: -1.233228, T: 3840, Avg. loss: 39.758304\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 6.79, NNZs: 44, Bias: -1.422213, T: 4480, Avg. loss: 39.742680\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.006309986114501953 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 3.92, NNZs: 44, Bias: -0.229017, T: 640, Avg. loss: 39.588520\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.22, NNZs: 44, Bias: -0.412678, T: 1280, Avg. loss: 36.358448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.77, NNZs: 44, Bias: -0.608724, T: 1920, Avg. loss: 37.326056\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.16, NNZs: 44, Bias: -0.820996, T: 2560, Avg. loss: 41.772040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.046754, T: 3200, Avg. loss: 40.525607\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.70, NNZs: 44, Bias: -1.233228, T: 3840, Avg. loss: 39.758304\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 6.79, NNZs: 44, Bias: -1.422213, T: 4480, Avg. loss: 39.742680\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.006455898284912109 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 60.99, NNZs: 42, Bias: -10.453885, T: 640, Avg. loss: 1552.509515\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 35.66, NNZs: 43, Bias: -12.783554, T: 1280, Avg. loss: 389.856725\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24.73, NNZs: 43, Bias: -14.062543, T: 1920, Avg. loss: 236.101649\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 20.01, NNZs: 44, Bias: -14.948544, T: 2560, Avg. loss: 187.732636\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 18.39, NNZs: 44, Bias: -15.671130, T: 3200, Avg. loss: 136.399263\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.70, NNZs: 44, Bias: -16.116936, T: 3840, Avg. loss: 111.364907\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 15.98, NNZs: 44, Bias: -16.589929, T: 4480, Avg. loss: 97.613050\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 14.31, NNZs: 44, Bias: -16.987956, T: 5120, Avg. loss: 74.871437\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 15.61, NNZs: 44, Bias: -17.388014, T: 5760, Avg. loss: 67.966306\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 13.92, NNZs: 44, Bias: -17.682240, T: 6400, Avg. loss: 61.636073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 11.86, NNZs: 44, Bias: -17.950590, T: 7040, Avg. loss: 55.904815\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 12.77, NNZs: 44, Bias: -18.208976, T: 7680, Avg. loss: 46.708359\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 11.33, NNZs: 44, Bias: -18.482606, T: 8320, Avg. loss: 45.033947\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 11.24, NNZs: 44, Bias: -18.677592, T: 8960, Avg. loss: 44.011195\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 11.42, NNZs: 44, Bias: -18.902786, T: 9600, Avg. loss: 43.701096\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 11.15, NNZs: 44, Bias: -19.059339, T: 10240, Avg. loss: 36.234746\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 11.28, NNZs: 44, Bias: -19.274144, T: 10880, Avg. loss: 33.412584\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 11.10, NNZs: 44, Bias: -19.442793, T: 11520, Avg. loss: 33.555258\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 10.71, NNZs: 44, Bias: -19.610984, T: 12160, Avg. loss: 34.817090\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 10.65, NNZs: 44, Bias: -19.756785, T: 12800, Avg. loss: 33.258951\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 11.12, NNZs: 44, Bias: -19.904638, T: 13440, Avg. loss: 30.816617\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 10.41, NNZs: 44, Bias: -20.032428, T: 14080, Avg. loss: 25.012433\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 10.57, NNZs: 44, Bias: -20.137965, T: 14720, Avg. loss: 28.452017\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 10.37, NNZs: 44, Bias: -20.251578, T: 15360, Avg. loss: 21.674290\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 10.47, NNZs: 44, Bias: -20.372988, T: 16000, Avg. loss: 22.736932\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 10.00, NNZs: 44, Bias: -20.472535, T: 16640, Avg. loss: 22.318439\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 10.02, NNZs: 44, Bias: -20.558950, T: 17280, Avg. loss: 20.445041\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 9.96, NNZs: 44, Bias: -20.664347, T: 17920, Avg. loss: 19.539886\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 9.83, NNZs: 44, Bias: -20.762185, T: 18560, Avg. loss: 19.285078\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 10.04, NNZs: 44, Bias: -20.861298, T: 19200, Avg. loss: 18.476698\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 10.05, NNZs: 44, Bias: -20.937798, T: 19840, Avg. loss: 19.100710\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 9.78, NNZs: 44, Bias: -21.031560, T: 20480, Avg. loss: 19.932161\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 9.73, NNZs: 44, Bias: -21.091787, T: 21120, Avg. loss: 16.569235\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 9.61, NNZs: 44, Bias: -21.180585, T: 21760, Avg. loss: 17.286220\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 9.71, NNZs: 44, Bias: -21.269395, T: 22400, Avg. loss: 16.595709\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 9.69, NNZs: 44, Bias: -21.341714, T: 23040, Avg. loss: 15.801840\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 9.62, NNZs: 44, Bias: -21.409972, T: 23680, Avg. loss: 15.241195\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 9.56, NNZs: 44, Bias: -21.492169, T: 24320, Avg. loss: 14.953152\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 9.59, NNZs: 44, Bias: -21.566195, T: 24960, Avg. loss: 13.076712\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 9.55, NNZs: 44, Bias: -21.629678, T: 25600, Avg. loss: 14.345237\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 9.57, NNZs: 44, Bias: -21.692393, T: 26240, Avg. loss: 13.411980\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 9.47, NNZs: 44, Bias: -21.744887, T: 26880, Avg. loss: 12.224874\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 9.46, NNZs: 44, Bias: -21.804454, T: 27520, Avg. loss: 12.965197\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 9.36, NNZs: 44, Bias: -21.862684, T: 28160, Avg. loss: 13.809267\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 9.37, NNZs: 44, Bias: -21.925840, T: 28800, Avg. loss: 11.215663\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 9.29, NNZs: 44, Bias: -21.977134, T: 29440, Avg. loss: 10.919410\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 9.44, NNZs: 44, Bias: -22.046628, T: 30080, Avg. loss: 11.670287\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 9.33, NNZs: 44, Bias: -22.098766, T: 30720, Avg. loss: 10.678681\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 9.37, NNZs: 44, Bias: -22.149601, T: 31360, Avg. loss: 11.416260\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 9.30, NNZs: 44, Bias: -22.196523, T: 32000, Avg. loss: 11.358393\n",
      "Total training time: 0.01 seconds.\n",
      "--- training time 0.01836681365966797 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 60.99, NNZs: 42, Bias: -10.453885, T: 640, Avg. loss: 1552.509515\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 35.66, NNZs: 43, Bias: -12.783554, T: 1280, Avg. loss: 389.856725\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24.73, NNZs: 43, Bias: -14.062543, T: 1920, Avg. loss: 236.101649\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 20.01, NNZs: 44, Bias: -14.948544, T: 2560, Avg. loss: 187.732636\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 18.39, NNZs: 44, Bias: -15.671130, T: 3200, Avg. loss: 136.399263\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.70, NNZs: 44, Bias: -16.116936, T: 3840, Avg. loss: 111.364907\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 15.98, NNZs: 44, Bias: -16.589929, T: 4480, Avg. loss: 97.613050\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 14.31, NNZs: 44, Bias: -16.987956, T: 5120, Avg. loss: 74.871437\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 15.61, NNZs: 44, Bias: -17.388014, T: 5760, Avg. loss: 67.966306\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 13.92, NNZs: 44, Bias: -17.682240, T: 6400, Avg. loss: 61.636073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 11.86, NNZs: 44, Bias: -17.950590, T: 7040, Avg. loss: 55.904815\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 12.77, NNZs: 44, Bias: -18.208976, T: 7680, Avg. loss: 46.708359\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 11.33, NNZs: 44, Bias: -18.482606, T: 8320, Avg. loss: 45.033947\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 11.24, NNZs: 44, Bias: -18.677592, T: 8960, Avg. loss: 44.011195\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 11.42, NNZs: 44, Bias: -18.902786, T: 9600, Avg. loss: 43.701096\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 11.15, NNZs: 44, Bias: -19.059339, T: 10240, Avg. loss: 36.234746\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 11.28, NNZs: 44, Bias: -19.274144, T: 10880, Avg. loss: 33.412584\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 11.10, NNZs: 44, Bias: -19.442793, T: 11520, Avg. loss: 33.555258\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 10.71, NNZs: 44, Bias: -19.610984, T: 12160, Avg. loss: 34.817090\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 10.65, NNZs: 44, Bias: -19.756785, T: 12800, Avg. loss: 33.258951\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 11.12, NNZs: 44, Bias: -19.904638, T: 13440, Avg. loss: 30.816617\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 10.41, NNZs: 44, Bias: -20.032428, T: 14080, Avg. loss: 25.012433\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 10.57, NNZs: 44, Bias: -20.137965, T: 14720, Avg. loss: 28.452017\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 10.37, NNZs: 44, Bias: -20.251578, T: 15360, Avg. loss: 21.674290\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 10.47, NNZs: 44, Bias: -20.372988, T: 16000, Avg. loss: 22.736932\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 10.00, NNZs: 44, Bias: -20.472535, T: 16640, Avg. loss: 22.318439\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 10.02, NNZs: 44, Bias: -20.558950, T: 17280, Avg. loss: 20.445041\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 9.96, NNZs: 44, Bias: -20.664347, T: 17920, Avg. loss: 19.539886\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 9.83, NNZs: 44, Bias: -20.762185, T: 18560, Avg. loss: 19.285078\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 10.04, NNZs: 44, Bias: -20.861298, T: 19200, Avg. loss: 18.476698\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 10.05, NNZs: 44, Bias: -20.937798, T: 19840, Avg. loss: 19.100710\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 9.78, NNZs: 44, Bias: -21.031560, T: 20480, Avg. loss: 19.932161\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 9.73, NNZs: 44, Bias: -21.091787, T: 21120, Avg. loss: 16.569235\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 9.61, NNZs: 44, Bias: -21.180585, T: 21760, Avg. loss: 17.286220\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 9.71, NNZs: 44, Bias: -21.269395, T: 22400, Avg. loss: 16.595709\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 9.69, NNZs: 44, Bias: -21.341714, T: 23040, Avg. loss: 15.801840\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 9.62, NNZs: 44, Bias: -21.409972, T: 23680, Avg. loss: 15.241195\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 9.56, NNZs: 44, Bias: -21.492169, T: 24320, Avg. loss: 14.953152\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 9.59, NNZs: 44, Bias: -21.566195, T: 24960, Avg. loss: 13.076712\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 9.55, NNZs: 44, Bias: -21.629678, T: 25600, Avg. loss: 14.345237\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 9.57, NNZs: 44, Bias: -21.692393, T: 26240, Avg. loss: 13.411980\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 9.47, NNZs: 44, Bias: -21.744887, T: 26880, Avg. loss: 12.224874\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 9.46, NNZs: 44, Bias: -21.804454, T: 27520, Avg. loss: 12.965197\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 9.36, NNZs: 44, Bias: -21.862684, T: 28160, Avg. loss: 13.809267\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 9.37, NNZs: 44, Bias: -21.925840, T: 28800, Avg. loss: 11.215663\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 9.29, NNZs: 44, Bias: -21.977134, T: 29440, Avg. loss: 10.919410\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 9.44, NNZs: 44, Bias: -22.046628, T: 30080, Avg. loss: 11.670287\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 9.33, NNZs: 44, Bias: -22.098766, T: 30720, Avg. loss: 10.678681\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 9.37, NNZs: 44, Bias: -22.149601, T: 31360, Avg. loss: 11.416260\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 9.30, NNZs: 44, Bias: -22.196523, T: 32000, Avg. loss: 11.358393\n",
      "Total training time: 0.03 seconds.\n",
      "--- training time 0.03425312042236328 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 60.99, NNZs: 42, Bias: -10.453885, T: 640, Avg. loss: 1552.509515\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 35.66, NNZs: 43, Bias: -12.783554, T: 1280, Avg. loss: 389.856725\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24.73, NNZs: 43, Bias: -14.062543, T: 1920, Avg. loss: 236.101649\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 20.01, NNZs: 44, Bias: -14.948544, T: 2560, Avg. loss: 187.732636\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 18.39, NNZs: 44, Bias: -15.671130, T: 3200, Avg. loss: 136.399263\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.70, NNZs: 44, Bias: -16.116936, T: 3840, Avg. loss: 111.364907\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 15.98, NNZs: 44, Bias: -16.589929, T: 4480, Avg. loss: 97.613050\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 14.31, NNZs: 44, Bias: -16.987956, T: 5120, Avg. loss: 74.871437\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 15.61, NNZs: 44, Bias: -17.388014, T: 5760, Avg. loss: 67.966306\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 13.92, NNZs: 44, Bias: -17.682240, T: 6400, Avg. loss: 61.636073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 11.86, NNZs: 44, Bias: -17.950590, T: 7040, Avg. loss: 55.904815\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 12.77, NNZs: 44, Bias: -18.208976, T: 7680, Avg. loss: 46.708359\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 11.33, NNZs: 44, Bias: -18.482606, T: 8320, Avg. loss: 45.033947\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 11.24, NNZs: 44, Bias: -18.677592, T: 8960, Avg. loss: 44.011195\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 11.42, NNZs: 44, Bias: -18.902786, T: 9600, Avg. loss: 43.701096\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 11.15, NNZs: 44, Bias: -19.059339, T: 10240, Avg. loss: 36.234746\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 11.28, NNZs: 44, Bias: -19.274144, T: 10880, Avg. loss: 33.412584\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 11.10, NNZs: 44, Bias: -19.442793, T: 11520, Avg. loss: 33.555258\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 10.71, NNZs: 44, Bias: -19.610984, T: 12160, Avg. loss: 34.817090\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 10.65, NNZs: 44, Bias: -19.756785, T: 12800, Avg. loss: 33.258951\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 11.12, NNZs: 44, Bias: -19.904638, T: 13440, Avg. loss: 30.816617\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 10.41, NNZs: 44, Bias: -20.032428, T: 14080, Avg. loss: 25.012433\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 10.57, NNZs: 44, Bias: -20.137965, T: 14720, Avg. loss: 28.452017\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 10.37, NNZs: 44, Bias: -20.251578, T: 15360, Avg. loss: 21.674290\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 10.47, NNZs: 44, Bias: -20.372988, T: 16000, Avg. loss: 22.736932\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 10.00, NNZs: 44, Bias: -20.472535, T: 16640, Avg. loss: 22.318439\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 10.02, NNZs: 44, Bias: -20.558950, T: 17280, Avg. loss: 20.445041\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 9.96, NNZs: 44, Bias: -20.664347, T: 17920, Avg. loss: 19.539886\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 9.83, NNZs: 44, Bias: -20.762185, T: 18560, Avg. loss: 19.285078\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 10.04, NNZs: 44, Bias: -20.861298, T: 19200, Avg. loss: 18.476698\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 10.05, NNZs: 44, Bias: -20.937798, T: 19840, Avg. loss: 19.100710\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 9.78, NNZs: 44, Bias: -21.031560, T: 20480, Avg. loss: 19.932161\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 9.73, NNZs: 44, Bias: -21.091787, T: 21120, Avg. loss: 16.569235\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 9.61, NNZs: 44, Bias: -21.180585, T: 21760, Avg. loss: 17.286220\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 9.71, NNZs: 44, Bias: -21.269395, T: 22400, Avg. loss: 16.595709\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 9.69, NNZs: 44, Bias: -21.341714, T: 23040, Avg. loss: 15.801840\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 9.62, NNZs: 44, Bias: -21.409972, T: 23680, Avg. loss: 15.241195\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 9.56, NNZs: 44, Bias: -21.492169, T: 24320, Avg. loss: 14.953152\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 9.59, NNZs: 44, Bias: -21.566195, T: 24960, Avg. loss: 13.076712\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 9.55, NNZs: 44, Bias: -21.629678, T: 25600, Avg. loss: 14.345237\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 9.57, NNZs: 44, Bias: -21.692393, T: 26240, Avg. loss: 13.411980\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 9.47, NNZs: 44, Bias: -21.744887, T: 26880, Avg. loss: 12.224874\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 9.46, NNZs: 44, Bias: -21.804454, T: 27520, Avg. loss: 12.965197\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 9.36, NNZs: 44, Bias: -21.862684, T: 28160, Avg. loss: 13.809267\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 9.37, NNZs: 44, Bias: -21.925840, T: 28800, Avg. loss: 11.215663\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 9.29, NNZs: 44, Bias: -21.977134, T: 29440, Avg. loss: 10.919410\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 9.44, NNZs: 44, Bias: -22.046628, T: 30080, Avg. loss: 11.670287\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 9.33, NNZs: 44, Bias: -22.098766, T: 30720, Avg. loss: 10.678681\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 9.37, NNZs: 44, Bias: -22.149601, T: 31360, Avg. loss: 11.416260\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 9.30, NNZs: 44, Bias: -22.196523, T: 32000, Avg. loss: 11.358393\n",
      "Total training time: 0.02 seconds.\n",
      "--- training time 0.018438100814819336 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.28, NNZs: 44, Bias: -0.013512, T: 640, Avg. loss: 3.020409\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.018760, T: 1280, Avg. loss: 1.296850\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.023565, T: 1920, Avg. loss: 0.963469\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.15, NNZs: 44, Bias: -0.027589, T: 2560, Avg. loss: 0.921900\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 0.14, NNZs: 44, Bias: -0.031779, T: 3200, Avg. loss: 0.737516\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.034975, T: 3840, Avg. loss: 0.649676\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.038168, T: 4480, Avg. loss: 0.654734\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.041333, T: 5120, Avg. loss: 0.612543\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.044426, T: 5760, Avg. loss: 0.567650\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.047042, T: 6400, Avg. loss: 0.558362\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.19, NNZs: 44, Bias: -0.049740, T: 7040, Avg. loss: 0.546509\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.19, NNZs: 44, Bias: -0.052214, T: 7680, Avg. loss: 0.536491\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.20, NNZs: 44, Bias: -0.054853, T: 8320, Avg. loss: 0.494764\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.20, NNZs: 44, Bias: -0.056945, T: 8960, Avg. loss: 0.522660\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.21, NNZs: 44, Bias: -0.059607, T: 9600, Avg. loss: 0.512106\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.21, NNZs: 44, Bias: -0.061642, T: 10240, Avg. loss: 0.487472\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.22, NNZs: 44, Bias: -0.064052, T: 10880, Avg. loss: 0.448072\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.066284, T: 11520, Avg. loss: 0.466046\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.068396, T: 12160, Avg. loss: 0.460946\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.070376, T: 12800, Avg. loss: 0.473061\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.24, NNZs: 44, Bias: -0.072256, T: 13440, Avg. loss: 0.466358\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.24, NNZs: 44, Bias: -0.074107, T: 14080, Avg. loss: 0.420802\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.25, NNZs: 44, Bias: -0.075874, T: 14720, Avg. loss: 0.437950\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.077713, T: 15360, Avg. loss: 0.414708\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.079615, T: 16000, Avg. loss: 0.419000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.081175, T: 16640, Avg. loss: 0.416462\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.27, NNZs: 44, Bias: -0.082705, T: 17280, Avg. loss: 0.399610\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.27, NNZs: 44, Bias: -0.084400, T: 17920, Avg. loss: 0.406214\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.28, NNZs: 44, Bias: -0.086092, T: 18560, Avg. loss: 0.404670\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.087828, T: 19200, Avg. loss: 0.393779\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.089294, T: 19840, Avg. loss: 0.408178\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.090851, T: 20480, Avg. loss: 0.415089\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.092223, T: 21120, Avg. loss: 0.385259\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.30, NNZs: 44, Bias: -0.093777, T: 21760, Avg. loss: 0.389855\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.30, NNZs: 44, Bias: -0.095357, T: 22400, Avg. loss: 0.395306\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.31, NNZs: 44, Bias: -0.096812, T: 23040, Avg. loss: 0.398555\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.31, NNZs: 44, Bias: -0.098326, T: 23680, Avg. loss: 0.403534\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.099797, T: 24320, Avg. loss: 0.395906\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 38 epochs took 0.02 seconds\n",
      "--- training time 0.018620014190673828 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.28, NNZs: 44, Bias: -0.013512, T: 640, Avg. loss: 3.020409\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.018760, T: 1280, Avg. loss: 1.296850\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.023565, T: 1920, Avg. loss: 0.963469\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.15, NNZs: 44, Bias: -0.027589, T: 2560, Avg. loss: 0.921900\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.14, NNZs: 44, Bias: -0.031779, T: 3200, Avg. loss: 0.737516\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.034975, T: 3840, Avg. loss: 0.649676\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.038168, T: 4480, Avg. loss: 0.654734\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.041333, T: 5120, Avg. loss: 0.612543\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.044426, T: 5760, Avg. loss: 0.567650\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.047042, T: 6400, Avg. loss: 0.558362\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.19, NNZs: 44, Bias: -0.049740, T: 7040, Avg. loss: 0.546509\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.19, NNZs: 44, Bias: -0.052214, T: 7680, Avg. loss: 0.536491\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.20, NNZs: 44, Bias: -0.054853, T: 8320, Avg. loss: 0.494764\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.20, NNZs: 44, Bias: -0.056945, T: 8960, Avg. loss: 0.522660\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.21, NNZs: 44, Bias: -0.059607, T: 9600, Avg. loss: 0.512106\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.21, NNZs: 44, Bias: -0.061642, T: 10240, Avg. loss: 0.487472\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.22, NNZs: 44, Bias: -0.064052, T: 10880, Avg. loss: 0.448072\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.066284, T: 11520, Avg. loss: 0.466046\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.068396, T: 12160, Avg. loss: 0.460946\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.070376, T: 12800, Avg. loss: 0.473061\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.24, NNZs: 44, Bias: -0.072256, T: 13440, Avg. loss: 0.466358\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.24, NNZs: 44, Bias: -0.074107, T: 14080, Avg. loss: 0.420802\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.25, NNZs: 44, Bias: -0.075874, T: 14720, Avg. loss: 0.437950\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.077713, T: 15360, Avg. loss: 0.414708\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.079615, T: 16000, Avg. loss: 0.419000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.081175, T: 16640, Avg. loss: 0.416462\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.27, NNZs: 44, Bias: -0.082705, T: 17280, Avg. loss: 0.399610\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.27, NNZs: 44, Bias: -0.084400, T: 17920, Avg. loss: 0.406214\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.28, NNZs: 44, Bias: -0.086092, T: 18560, Avg. loss: 0.404670\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.087828, T: 19200, Avg. loss: 0.393779\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.089294, T: 19840, Avg. loss: 0.408178\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.090851, T: 20480, Avg. loss: 0.415089\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.092223, T: 21120, Avg. loss: 0.385259\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.30, NNZs: 44, Bias: -0.093777, T: 21760, Avg. loss: 0.389855\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.30, NNZs: 44, Bias: -0.095357, T: 22400, Avg. loss: 0.395306\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.31, NNZs: 44, Bias: -0.096812, T: 23040, Avg. loss: 0.398555\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.31, NNZs: 44, Bias: -0.098326, T: 23680, Avg. loss: 0.403534\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.099797, T: 24320, Avg. loss: 0.395906\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 38 epochs took 0.01 seconds\n",
      "--- training time 0.01782965660095215 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.28, NNZs: 44, Bias: -0.013512, T: 640, Avg. loss: 3.020409\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.018760, T: 1280, Avg. loss: 1.296850\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.023565, T: 1920, Avg. loss: 0.963469\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.15, NNZs: 44, Bias: -0.027589, T: 2560, Avg. loss: 0.921900\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.14, NNZs: 44, Bias: -0.031779, T: 3200, Avg. loss: 0.737516\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.034975, T: 3840, Avg. loss: 0.649676\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.038168, T: 4480, Avg. loss: 0.654734\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.041333, T: 5120, Avg. loss: 0.612543\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.044426, T: 5760, Avg. loss: 0.567650\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.047042, T: 6400, Avg. loss: 0.558362\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.19, NNZs: 44, Bias: -0.049740, T: 7040, Avg. loss: 0.546509\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.19, NNZs: 44, Bias: -0.052214, T: 7680, Avg. loss: 0.536491\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.20, NNZs: 44, Bias: -0.054853, T: 8320, Avg. loss: 0.494764\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.20, NNZs: 44, Bias: -0.056945, T: 8960, Avg. loss: 0.522660\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.21, NNZs: 44, Bias: -0.059607, T: 9600, Avg. loss: 0.512106\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.21, NNZs: 44, Bias: -0.061642, T: 10240, Avg. loss: 0.487472\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.22, NNZs: 44, Bias: -0.064052, T: 10880, Avg. loss: 0.448072\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.066284, T: 11520, Avg. loss: 0.466046\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.068396, T: 12160, Avg. loss: 0.460946\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.070376, T: 12800, Avg. loss: 0.473061\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.24, NNZs: 44, Bias: -0.072256, T: 13440, Avg. loss: 0.466358\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.24, NNZs: 44, Bias: -0.074107, T: 14080, Avg. loss: 0.420802\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.25, NNZs: 44, Bias: -0.075874, T: 14720, Avg. loss: 0.437950\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.077713, T: 15360, Avg. loss: 0.414708\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.079615, T: 16000, Avg. loss: 0.419000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.081175, T: 16640, Avg. loss: 0.416462\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.27, NNZs: 44, Bias: -0.082705, T: 17280, Avg. loss: 0.399610\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.27, NNZs: 44, Bias: -0.084400, T: 17920, Avg. loss: 0.406214\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.28, NNZs: 44, Bias: -0.086092, T: 18560, Avg. loss: 0.404670\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.087828, T: 19200, Avg. loss: 0.393779\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.089294, T: 19840, Avg. loss: 0.408178\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.090851, T: 20480, Avg. loss: 0.415089\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.092223, T: 21120, Avg. loss: 0.385259\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.30, NNZs: 44, Bias: -0.093777, T: 21760, Avg. loss: 0.389855\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.30, NNZs: 44, Bias: -0.095357, T: 22400, Avg. loss: 0.395306\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.31, NNZs: 44, Bias: -0.096812, T: 23040, Avg. loss: 0.398555\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.31, NNZs: 44, Bias: -0.098326, T: 23680, Avg. loss: 0.403534\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.099797, T: 24320, Avg. loss: 0.395906\n",
      "Total training time: 0.08 seconds.\n",
      "Convergence after 38 epochs took 0.08 seconds\n",
      "--- training time 0.08500909805297852 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 3.92, NNZs: 44, Bias: -0.229017, T: 640, Avg. loss: 39.588520\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.22, NNZs: 44, Bias: -0.412678, T: 1280, Avg. loss: 36.358448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.77, NNZs: 44, Bias: -0.608724, T: 1920, Avg. loss: 37.326056\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.16, NNZs: 44, Bias: -0.820996, T: 2560, Avg. loss: 41.772040\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.046754, T: 3200, Avg. loss: 40.525607\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.70, NNZs: 44, Bias: -1.233228, T: 3840, Avg. loss: 39.758304\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 6.79, NNZs: 44, Bias: -1.422213, T: 4480, Avg. loss: 39.742680\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 4.53, NNZs: 44, Bias: -1.450692, T: 5120, Avg. loss: 16.560021\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 4.10, NNZs: 44, Bias: -1.488961, T: 5760, Avg. loss: 9.079159\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 4.12, NNZs: 44, Bias: -1.526367, T: 6400, Avg. loss: 7.795266\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 4.13, NNZs: 44, Bias: -1.563871, T: 7040, Avg. loss: 7.278739\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 4.18, NNZs: 44, Bias: -1.597494, T: 7680, Avg. loss: 7.476793\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 4.20, NNZs: 44, Bias: -1.635171, T: 8320, Avg. loss: 6.880366\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 4.23, NNZs: 44, Bias: -1.670875, T: 8960, Avg. loss: 8.182257\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 4.29, NNZs: 44, Bias: -1.708758, T: 9600, Avg. loss: 7.790961\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 4.42, NNZs: 44, Bias: -1.745993, T: 10240, Avg. loss: 6.813259\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 4.53, NNZs: 44, Bias: -1.787712, T: 10880, Avg. loss: 6.377116\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 4.54, NNZs: 44, Bias: -1.826082, T: 11520, Avg. loss: 7.133107\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 4.61, NNZs: 44, Bias: -1.865045, T: 12160, Avg. loss: 7.854998\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 4.62, NNZs: 44, Bias: -1.900519, T: 12800, Avg. loss: 8.339434\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 4.69, NNZs: 44, Bias: -1.938469, T: 13440, Avg. loss: 7.971242\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 4.70, NNZs: 44, Bias: -1.971390, T: 14080, Avg. loss: 6.846766\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.975878, T: 14720, Avg. loss: 1.909502\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 4.65, NNZs: 44, Bias: -1.981030, T: 15360, Avg. loss: 1.337327\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 4.64, NNZs: 44, Bias: -1.986973, T: 16000, Avg. loss: 1.095216\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 4.64, NNZs: 44, Bias: -1.991376, T: 16640, Avg. loss: 1.240920\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 4.63, NNZs: 44, Bias: -1.995282, T: 17280, Avg. loss: 1.152731\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.000016, T: 17920, Avg. loss: 1.129366\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.005264, T: 18560, Avg. loss: 1.114322\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.010318, T: 19200, Avg. loss: 1.112498\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 4.62, NNZs: 44, Bias: -2.010732, T: 19840, Avg. loss: 0.529010\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 4.62, NNZs: 44, Bias: -2.011248, T: 20480, Avg. loss: 0.383808\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.011636, T: 21120, Avg. loss: 0.347171\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.012246, T: 21760, Avg. loss: 0.332399\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.012706, T: 22400, Avg. loss: 0.351599\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.013156, T: 23040, Avg. loss: 0.337051\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.013751, T: 23680, Avg. loss: 0.323753\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.014291, T: 24320, Avg. loss: 0.316370\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.014850, T: 24960, Avg. loss: 0.306305\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.015305, T: 25600, Avg. loss: 0.349897\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.015810, T: 26240, Avg. loss: 0.322652\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.016303, T: 26880, Avg. loss: 0.284620\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.016802, T: 27520, Avg. loss: 0.341514\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.017296, T: 28160, Avg. loss: 0.334507\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.017880, T: 28800, Avg. loss: 0.307931\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.018483, T: 29440, Avg. loss: 0.334228\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019125, T: 30080, Avg. loss: 0.296572\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019163, T: 30720, Avg. loss: 0.224531\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019239, T: 31360, Avg. loss: 0.215501\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019339, T: 32000, Avg. loss: 0.227935\n",
      "Total training time: 0.10 seconds.\n",
      "--- training time 0.11378693580627441 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 3.92, NNZs: 44, Bias: -0.229017, T: 640, Avg. loss: 39.588520\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.22, NNZs: 44, Bias: -0.412678, T: 1280, Avg. loss: 36.358448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.77, NNZs: 44, Bias: -0.608724, T: 1920, Avg. loss: 37.326056\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.16, NNZs: 44, Bias: -0.820996, T: 2560, Avg. loss: 41.772040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.046754, T: 3200, Avg. loss: 40.525607\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.70, NNZs: 44, Bias: -1.233228, T: 3840, Avg. loss: 39.758304\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 6.79, NNZs: 44, Bias: -1.422213, T: 4480, Avg. loss: 39.742680\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 4.53, NNZs: 44, Bias: -1.450692, T: 5120, Avg. loss: 16.560021\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 4.10, NNZs: 44, Bias: -1.488961, T: 5760, Avg. loss: 9.079159\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 4.12, NNZs: 44, Bias: -1.526367, T: 6400, Avg. loss: 7.795266\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 4.13, NNZs: 44, Bias: -1.563871, T: 7040, Avg. loss: 7.278739\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 4.18, NNZs: 44, Bias: -1.597494, T: 7680, Avg. loss: 7.476793\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 4.20, NNZs: 44, Bias: -1.635171, T: 8320, Avg. loss: 6.880366\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 4.23, NNZs: 44, Bias: -1.670875, T: 8960, Avg. loss: 8.182257\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 4.29, NNZs: 44, Bias: -1.708758, T: 9600, Avg. loss: 7.790961\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 4.42, NNZs: 44, Bias: -1.745993, T: 10240, Avg. loss: 6.813259\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 4.53, NNZs: 44, Bias: -1.787712, T: 10880, Avg. loss: 6.377116\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 4.54, NNZs: 44, Bias: -1.826082, T: 11520, Avg. loss: 7.133107\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 4.61, NNZs: 44, Bias: -1.865045, T: 12160, Avg. loss: 7.854998\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 4.62, NNZs: 44, Bias: -1.900519, T: 12800, Avg. loss: 8.339434\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 4.69, NNZs: 44, Bias: -1.938469, T: 13440, Avg. loss: 7.971242\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 4.70, NNZs: 44, Bias: -1.971390, T: 14080, Avg. loss: 6.846766\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.975878, T: 14720, Avg. loss: 1.909502\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 4.65, NNZs: 44, Bias: -1.981030, T: 15360, Avg. loss: 1.337327\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 4.64, NNZs: 44, Bias: -1.986973, T: 16000, Avg. loss: 1.095216\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 4.64, NNZs: 44, Bias: -1.991376, T: 16640, Avg. loss: 1.240920\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 4.63, NNZs: 44, Bias: -1.995282, T: 17280, Avg. loss: 1.152731\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.000016, T: 17920, Avg. loss: 1.129366\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.005264, T: 18560, Avg. loss: 1.114322\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.010318, T: 19200, Avg. loss: 1.112498\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 4.62, NNZs: 44, Bias: -2.010732, T: 19840, Avg. loss: 0.529010\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 4.62, NNZs: 44, Bias: -2.011248, T: 20480, Avg. loss: 0.383808\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.011636, T: 21120, Avg. loss: 0.347171\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.012246, T: 21760, Avg. loss: 0.332399\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.012706, T: 22400, Avg. loss: 0.351599\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.013156, T: 23040, Avg. loss: 0.337051\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.013751, T: 23680, Avg. loss: 0.323753\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.014291, T: 24320, Avg. loss: 0.316370\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.014850, T: 24960, Avg. loss: 0.306305\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.015305, T: 25600, Avg. loss: 0.349897\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.015810, T: 26240, Avg. loss: 0.322652\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.016303, T: 26880, Avg. loss: 0.284620\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.016802, T: 27520, Avg. loss: 0.341514\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.017296, T: 28160, Avg. loss: 0.334507\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.017880, T: 28800, Avg. loss: 0.307931\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.018483, T: 29440, Avg. loss: 0.334228\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019125, T: 30080, Avg. loss: 0.296572\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019163, T: 30720, Avg. loss: 0.224531\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019239, T: 31360, Avg. loss: 0.215501\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019339, T: 32000, Avg. loss: 0.227935\n",
      "Total training time: 0.03 seconds.\n",
      "--- training time 0.03158974647521973 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 3.92, NNZs: 44, Bias: -0.229017, T: 640, Avg. loss: 39.588520\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.22, NNZs: 44, Bias: -0.412678, T: 1280, Avg. loss: 36.358448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.77, NNZs: 44, Bias: -0.608724, T: 1920, Avg. loss: 37.326056\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.16, NNZs: 44, Bias: -0.820996, T: 2560, Avg. loss: 41.772040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.046754, T: 3200, Avg. loss: 40.525607\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.70, NNZs: 44, Bias: -1.233228, T: 3840, Avg. loss: 39.758304\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 6.79, NNZs: 44, Bias: -1.422213, T: 4480, Avg. loss: 39.742680\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 4.53, NNZs: 44, Bias: -1.450692, T: 5120, Avg. loss: 16.560021\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 4.10, NNZs: 44, Bias: -1.488961, T: 5760, Avg. loss: 9.079159\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 4.12, NNZs: 44, Bias: -1.526367, T: 6400, Avg. loss: 7.795266\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 4.13, NNZs: 44, Bias: -1.563871, T: 7040, Avg. loss: 7.278739\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 4.18, NNZs: 44, Bias: -1.597494, T: 7680, Avg. loss: 7.476793\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 4.20, NNZs: 44, Bias: -1.635171, T: 8320, Avg. loss: 6.880366\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 4.23, NNZs: 44, Bias: -1.670875, T: 8960, Avg. loss: 8.182257\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 4.29, NNZs: 44, Bias: -1.708758, T: 9600, Avg. loss: 7.790961\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 4.42, NNZs: 44, Bias: -1.745993, T: 10240, Avg. loss: 6.813259\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 4.53, NNZs: 44, Bias: -1.787712, T: 10880, Avg. loss: 6.377116\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 4.54, NNZs: 44, Bias: -1.826082, T: 11520, Avg. loss: 7.133107\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 4.61, NNZs: 44, Bias: -1.865045, T: 12160, Avg. loss: 7.854998\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 4.62, NNZs: 44, Bias: -1.900519, T: 12800, Avg. loss: 8.339434\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 4.69, NNZs: 44, Bias: -1.938469, T: 13440, Avg. loss: 7.971242\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 4.70, NNZs: 44, Bias: -1.971390, T: 14080, Avg. loss: 6.846766\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.975878, T: 14720, Avg. loss: 1.909502\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 4.65, NNZs: 44, Bias: -1.981030, T: 15360, Avg. loss: 1.337327\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 4.64, NNZs: 44, Bias: -1.986973, T: 16000, Avg. loss: 1.095216\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 4.64, NNZs: 44, Bias: -1.991376, T: 16640, Avg. loss: 1.240920\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 4.63, NNZs: 44, Bias: -1.995282, T: 17280, Avg. loss: 1.152731\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.000016, T: 17920, Avg. loss: 1.129366\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.005264, T: 18560, Avg. loss: 1.114322\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.010318, T: 19200, Avg. loss: 1.112498\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 4.62, NNZs: 44, Bias: -2.010732, T: 19840, Avg. loss: 0.529010\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 4.62, NNZs: 44, Bias: -2.011248, T: 20480, Avg. loss: 0.383808\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.011636, T: 21120, Avg. loss: 0.347171\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.012246, T: 21760, Avg. loss: 0.332399\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.012706, T: 22400, Avg. loss: 0.351599\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.013156, T: 23040, Avg. loss: 0.337051\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.013751, T: 23680, Avg. loss: 0.323753\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.014291, T: 24320, Avg. loss: 0.316370\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.014850, T: 24960, Avg. loss: 0.306305\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.015305, T: 25600, Avg. loss: 0.349897\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.015810, T: 26240, Avg. loss: 0.322652\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.016303, T: 26880, Avg. loss: 0.284620\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.016802, T: 27520, Avg. loss: 0.341514\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.017296, T: 28160, Avg. loss: 0.334507\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.017880, T: 28800, Avg. loss: 0.307931\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.018483, T: 29440, Avg. loss: 0.334228\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019125, T: 30080, Avg. loss: 0.296572\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019163, T: 30720, Avg. loss: 0.224531\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019239, T: 31360, Avg. loss: 0.215501\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019339, T: 32000, Avg. loss: 0.227935\n",
      "Total training time: 0.02 seconds.\n",
      "--- training time 0.024881362915039062 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 10.91, NNZs: 43, Bias: -2.550009, T: 640, Avg. loss: 402.389039\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.71, NNZs: 44, Bias: -5.050009, T: 1280, Avg. loss: 323.294791\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.46, NNZs: 44, Bias: -7.512515, T: 1920, Avg. loss: 359.311537\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.05, NNZs: 44, Bias: -10.201947, T: 2560, Avg. loss: 399.918189\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.69, NNZs: 44, Bias: -12.720222, T: 3200, Avg. loss: 361.718888\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.91, NNZs: 44, Bias: -14.880795, T: 3840, Avg. loss: 377.351976\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 19.10, NNZs: 44, Bias: -17.180424, T: 4480, Avg. loss: 376.820507\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.004854679107666016 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 10.91, NNZs: 43, Bias: -2.550009, T: 640, Avg. loss: 402.389039\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.71, NNZs: 44, Bias: -5.050009, T: 1280, Avg. loss: 323.294791\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.46, NNZs: 44, Bias: -7.512515, T: 1920, Avg. loss: 359.311537\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.05, NNZs: 44, Bias: -10.201947, T: 2560, Avg. loss: 399.918189\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.69, NNZs: 44, Bias: -12.720222, T: 3200, Avg. loss: 361.718888\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.91, NNZs: 44, Bias: -14.880795, T: 3840, Avg. loss: 377.351976\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 19.10, NNZs: 44, Bias: -17.180424, T: 4480, Avg. loss: 376.820507\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.004862785339355469 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 10.91, NNZs: 43, Bias: -2.550009, T: 640, Avg. loss: 402.389039\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.71, NNZs: 44, Bias: -5.050009, T: 1280, Avg. loss: 323.294791\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.46, NNZs: 44, Bias: -7.512515, T: 1920, Avg. loss: 359.311537\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.05, NNZs: 44, Bias: -10.201947, T: 2560, Avg. loss: 399.918189\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.69, NNZs: 44, Bias: -12.720222, T: 3200, Avg. loss: 361.718888\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.91, NNZs: 44, Bias: -14.880795, T: 3840, Avg. loss: 377.351976\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 19.10, NNZs: 44, Bias: -17.180424, T: 4480, Avg. loss: 376.820507\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.005473136901855469 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 6.35, NNZs: 44, Bias: -1.994673, T: 640, Avg. loss: 189.614785\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.05, NNZs: 44, Bias: -2.217508, T: 1280, Avg. loss: 40.077763\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3.12, NNZs: 44, Bias: -2.340662, T: 1920, Avg. loss: 23.614151\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.03, NNZs: 44, Bias: -2.422736, T: 2560, Avg. loss: 19.441969\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.59, NNZs: 44, Bias: -2.496541, T: 3200, Avg. loss: 13.700437\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.98, NNZs: 44, Bias: -2.541821, T: 3840, Avg. loss: 10.579633\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.45, NNZs: 44, Bias: -2.583415, T: 4480, Avg. loss: 9.411084\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.40, NNZs: 44, Bias: -2.630032, T: 5120, Avg. loss: 8.216800\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.50, NNZs: 44, Bias: -2.663326, T: 5760, Avg. loss: 7.242535\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.36, NNZs: 44, Bias: -2.692023, T: 6400, Avg. loss: 5.980278\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.29, NNZs: 44, Bias: -2.721187, T: 7040, Avg. loss: 5.348994\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.22, NNZs: 44, Bias: -2.743549, T: 7680, Avg. loss: 4.803177\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1.12, NNZs: 44, Bias: -2.768479, T: 8320, Avg. loss: 4.859873\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1.13, NNZs: 44, Bias: -2.788927, T: 8960, Avg. loss: 4.464438\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1.08, NNZs: 44, Bias: -2.811251, T: 9600, Avg. loss: 4.280645\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1.15, NNZs: 44, Bias: -2.830171, T: 10240, Avg. loss: 3.587939\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1.08, NNZs: 44, Bias: -2.848824, T: 10880, Avg. loss: 2.990107\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1.10, NNZs: 44, Bias: -2.867765, T: 11520, Avg. loss: 3.350379\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 1.05, NNZs: 44, Bias: -2.884974, T: 12160, Avg. loss: 3.444854\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.04, NNZs: 44, Bias: -2.900045, T: 12800, Avg. loss: 2.998987\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.10, NNZs: 44, Bias: -2.915230, T: 13440, Avg. loss: 2.910877\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 1.03, NNZs: 44, Bias: -2.927017, T: 14080, Avg. loss: 2.422828\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 1.07, NNZs: 44, Bias: -2.937955, T: 14720, Avg. loss: 2.621666\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 1.04, NNZs: 44, Bias: -2.950331, T: 15360, Avg. loss: 2.301741\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 1.05, NNZs: 44, Bias: -2.963537, T: 16000, Avg. loss: 2.276732\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 1.01, NNZs: 44, Bias: -2.972981, T: 16640, Avg. loss: 1.978905\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 1.03, NNZs: 44, Bias: -2.980866, T: 17280, Avg. loss: 2.065030\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.99, NNZs: 44, Bias: -2.991051, T: 17920, Avg. loss: 1.902420\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.00, NNZs: 44, Bias: -3.000799, T: 18560, Avg. loss: 1.688780\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.00, NNZs: 44, Bias: -3.010344, T: 19200, Avg. loss: 1.746155\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1.01, NNZs: 44, Bias: -3.018024, T: 19840, Avg. loss: 1.738377\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.026440, T: 20480, Avg. loss: 1.826953\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.032298, T: 21120, Avg. loss: 1.469212\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.041144, T: 21760, Avg. loss: 1.603329\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.049891, T: 22400, Avg. loss: 1.556712\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.99, NNZs: 44, Bias: -3.057867, T: 23040, Avg. loss: 1.499409\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.065866, T: 23680, Avg. loss: 1.552223\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.073255, T: 24320, Avg. loss: 1.350029\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.079636, T: 24960, Avg. loss: 1.202499\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.96, NNZs: 44, Bias: -3.085880, T: 25600, Avg. loss: 1.325216\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.96, NNZs: 44, Bias: -3.091427, T: 26240, Avg. loss: 1.228914\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.096794, T: 26880, Avg. loss: 1.123186\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.102410, T: 27520, Avg. loss: 1.207042\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.108396, T: 28160, Avg. loss: 1.183111\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.115113, T: 28800, Avg. loss: 1.183820\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.120594, T: 29440, Avg. loss: 1.158029\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.127762, T: 30080, Avg. loss: 1.112647\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.132704, T: 30720, Avg. loss: 0.996212\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.137911, T: 31360, Avg. loss: 0.994590\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.93, NNZs: 44, Bias: -3.142994, T: 32000, Avg. loss: 1.090287\n",
      "Total training time: 0.01 seconds.\n",
      "--- training time 0.015449762344360352 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 6.35, NNZs: 44, Bias: -1.994673, T: 640, Avg. loss: 189.614785\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.05, NNZs: 44, Bias: -2.217508, T: 1280, Avg. loss: 40.077763\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3.12, NNZs: 44, Bias: -2.340662, T: 1920, Avg. loss: 23.614151\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.03, NNZs: 44, Bias: -2.422736, T: 2560, Avg. loss: 19.441969\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.59, NNZs: 44, Bias: -2.496541, T: 3200, Avg. loss: 13.700437\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.98, NNZs: 44, Bias: -2.541821, T: 3840, Avg. loss: 10.579633\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.45, NNZs: 44, Bias: -2.583415, T: 4480, Avg. loss: 9.411084\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.40, NNZs: 44, Bias: -2.630032, T: 5120, Avg. loss: 8.216800\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.50, NNZs: 44, Bias: -2.663326, T: 5760, Avg. loss: 7.242535\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.36, NNZs: 44, Bias: -2.692023, T: 6400, Avg. loss: 5.980278\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.29, NNZs: 44, Bias: -2.721187, T: 7040, Avg. loss: 5.348994\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.22, NNZs: 44, Bias: -2.743549, T: 7680, Avg. loss: 4.803177\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1.12, NNZs: 44, Bias: -2.768479, T: 8320, Avg. loss: 4.859873\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1.13, NNZs: 44, Bias: -2.788927, T: 8960, Avg. loss: 4.464438\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1.08, NNZs: 44, Bias: -2.811251, T: 9600, Avg. loss: 4.280645\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1.15, NNZs: 44, Bias: -2.830171, T: 10240, Avg. loss: 3.587939\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1.08, NNZs: 44, Bias: -2.848824, T: 10880, Avg. loss: 2.990107\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1.10, NNZs: 44, Bias: -2.867765, T: 11520, Avg. loss: 3.350379\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 1.05, NNZs: 44, Bias: -2.884974, T: 12160, Avg. loss: 3.444854\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.04, NNZs: 44, Bias: -2.900045, T: 12800, Avg. loss: 2.998987\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.10, NNZs: 44, Bias: -2.915230, T: 13440, Avg. loss: 2.910877\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 1.03, NNZs: 44, Bias: -2.927017, T: 14080, Avg. loss: 2.422828\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 1.07, NNZs: 44, Bias: -2.937955, T: 14720, Avg. loss: 2.621666\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 1.04, NNZs: 44, Bias: -2.950331, T: 15360, Avg. loss: 2.301741\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 1.05, NNZs: 44, Bias: -2.963537, T: 16000, Avg. loss: 2.276732\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 1.01, NNZs: 44, Bias: -2.972981, T: 16640, Avg. loss: 1.978905\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 1.03, NNZs: 44, Bias: -2.980866, T: 17280, Avg. loss: 2.065030\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.99, NNZs: 44, Bias: -2.991051, T: 17920, Avg. loss: 1.902420\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.00, NNZs: 44, Bias: -3.000799, T: 18560, Avg. loss: 1.688780\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.00, NNZs: 44, Bias: -3.010344, T: 19200, Avg. loss: 1.746155\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1.01, NNZs: 44, Bias: -3.018024, T: 19840, Avg. loss: 1.738377\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.026440, T: 20480, Avg. loss: 1.826953\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.032298, T: 21120, Avg. loss: 1.469212\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.041144, T: 21760, Avg. loss: 1.603329\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.049891, T: 22400, Avg. loss: 1.556712\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.99, NNZs: 44, Bias: -3.057867, T: 23040, Avg. loss: 1.499409\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.065866, T: 23680, Avg. loss: 1.552223\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.073255, T: 24320, Avg. loss: 1.350029\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.079636, T: 24960, Avg. loss: 1.202499\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.96, NNZs: 44, Bias: -3.085880, T: 25600, Avg. loss: 1.325216\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.96, NNZs: 44, Bias: -3.091427, T: 26240, Avg. loss: 1.228914\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.096794, T: 26880, Avg. loss: 1.123186\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.102410, T: 27520, Avg. loss: 1.207042\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.108396, T: 28160, Avg. loss: 1.183111\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.115113, T: 28800, Avg. loss: 1.183820\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.120594, T: 29440, Avg. loss: 1.158029\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.127762, T: 30080, Avg. loss: 1.112647\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.132704, T: 30720, Avg. loss: 0.996212\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.137911, T: 31360, Avg. loss: 0.994590\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.93, NNZs: 44, Bias: -3.142994, T: 32000, Avg. loss: 1.090287\n",
      "Total training time: 0.01 seconds.\n",
      "--- training time 0.014355897903442383 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 6.35, NNZs: 44, Bias: -1.994673, T: 640, Avg. loss: 189.614785\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.05, NNZs: 44, Bias: -2.217508, T: 1280, Avg. loss: 40.077763\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3.12, NNZs: 44, Bias: -2.340662, T: 1920, Avg. loss: 23.614151\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.03, NNZs: 44, Bias: -2.422736, T: 2560, Avg. loss: 19.441969\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.59, NNZs: 44, Bias: -2.496541, T: 3200, Avg. loss: 13.700437\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.98, NNZs: 44, Bias: -2.541821, T: 3840, Avg. loss: 10.579633\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.45, NNZs: 44, Bias: -2.583415, T: 4480, Avg. loss: 9.411084\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.40, NNZs: 44, Bias: -2.630032, T: 5120, Avg. loss: 8.216800\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.50, NNZs: 44, Bias: -2.663326, T: 5760, Avg. loss: 7.242535\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.36, NNZs: 44, Bias: -2.692023, T: 6400, Avg. loss: 5.980278\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.29, NNZs: 44, Bias: -2.721187, T: 7040, Avg. loss: 5.348994\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.22, NNZs: 44, Bias: -2.743549, T: 7680, Avg. loss: 4.803177\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1.12, NNZs: 44, Bias: -2.768479, T: 8320, Avg. loss: 4.859873\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1.13, NNZs: 44, Bias: -2.788927, T: 8960, Avg. loss: 4.464438\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1.08, NNZs: 44, Bias: -2.811251, T: 9600, Avg. loss: 4.280645\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1.15, NNZs: 44, Bias: -2.830171, T: 10240, Avg. loss: 3.587939\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1.08, NNZs: 44, Bias: -2.848824, T: 10880, Avg. loss: 2.990107\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1.10, NNZs: 44, Bias: -2.867765, T: 11520, Avg. loss: 3.350379\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 1.05, NNZs: 44, Bias: -2.884974, T: 12160, Avg. loss: 3.444854\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.04, NNZs: 44, Bias: -2.900045, T: 12800, Avg. loss: 2.998987\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.10, NNZs: 44, Bias: -2.915230, T: 13440, Avg. loss: 2.910877\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 1.03, NNZs: 44, Bias: -2.927017, T: 14080, Avg. loss: 2.422828\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 1.07, NNZs: 44, Bias: -2.937955, T: 14720, Avg. loss: 2.621666\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 1.04, NNZs: 44, Bias: -2.950331, T: 15360, Avg. loss: 2.301741\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 1.05, NNZs: 44, Bias: -2.963537, T: 16000, Avg. loss: 2.276732\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 1.01, NNZs: 44, Bias: -2.972981, T: 16640, Avg. loss: 1.978905\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 1.03, NNZs: 44, Bias: -2.980866, T: 17280, Avg. loss: 2.065030\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.99, NNZs: 44, Bias: -2.991051, T: 17920, Avg. loss: 1.902420\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.00, NNZs: 44, Bias: -3.000799, T: 18560, Avg. loss: 1.688780\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.00, NNZs: 44, Bias: -3.010344, T: 19200, Avg. loss: 1.746155\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1.01, NNZs: 44, Bias: -3.018024, T: 19840, Avg. loss: 1.738377\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.026440, T: 20480, Avg. loss: 1.826953\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.032298, T: 21120, Avg. loss: 1.469212\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.041144, T: 21760, Avg. loss: 1.603329\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.049891, T: 22400, Avg. loss: 1.556712\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.99, NNZs: 44, Bias: -3.057867, T: 23040, Avg. loss: 1.499409\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.065866, T: 23680, Avg. loss: 1.552223\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.073255, T: 24320, Avg. loss: 1.350029\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.079636, T: 24960, Avg. loss: 1.202499\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.96, NNZs: 44, Bias: -3.085880, T: 25600, Avg. loss: 1.325216\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.96, NNZs: 44, Bias: -3.091427, T: 26240, Avg. loss: 1.228914\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.096794, T: 26880, Avg. loss: 1.123186\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.102410, T: 27520, Avg. loss: 1.207042\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.108396, T: 28160, Avg. loss: 1.183111\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.115113, T: 28800, Avg. loss: 1.183820\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.120594, T: 29440, Avg. loss: 1.158029\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.127762, T: 30080, Avg. loss: 1.112647\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.132704, T: 30720, Avg. loss: 0.996212\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.137911, T: 31360, Avg. loss: 0.994590\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.93, NNZs: 44, Bias: -3.142994, T: 32000, Avg. loss: 1.090287\n",
      "Total training time: 0.01 seconds.\n",
      "--- training time 0.013895750045776367 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 1.81, NNZs: 44, Bias: -0.132429, T: 640, Avg. loss: 30.907784\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.39, NNZs: 44, Bias: -0.188078, T: 1280, Avg. loss: 10.660232\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.25, NNZs: 44, Bias: -0.238202, T: 1920, Avg. loss: 9.212930\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.276557, T: 2560, Avg. loss: 9.238287\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.316699, T: 3200, Avg. loss: 7.258781\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.20, NNZs: 44, Bias: -0.346927, T: 3840, Avg. loss: 6.083062\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.05, NNZs: 44, Bias: -0.377001, T: 4480, Avg. loss: 6.074865\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.405743, T: 5120, Avg. loss: 5.408817\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.05, NNZs: 44, Bias: -0.434407, T: 5760, Avg. loss: 5.172337\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.07, NNZs: 44, Bias: -0.459415, T: 6400, Avg. loss: 4.729603\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.08, NNZs: 44, Bias: -0.484385, T: 7040, Avg. loss: 4.626073\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.505227, T: 7680, Avg. loss: 4.504605\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.529476, T: 8320, Avg. loss: 3.886199\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.548966, T: 8960, Avg. loss: 4.488182\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.574013, T: 9600, Avg. loss: 4.301054\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1.06, NNZs: 44, Bias: -0.594354, T: 10240, Avg. loss: 3.785013\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.616599, T: 10880, Avg. loss: 3.399852\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.636243, T: 11520, Avg. loss: 3.280211\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.96, NNZs: 44, Bias: -0.654038, T: 12160, Avg. loss: 3.690596\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.671599, T: 12800, Avg. loss: 3.693993\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.689654, T: 13440, Avg. loss: 3.407431\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.705857, T: 14080, Avg. loss: 2.926440\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.720351, T: 14720, Avg. loss: 3.038130\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.736537, T: 15360, Avg. loss: 3.017863\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.751568, T: 16000, Avg. loss: 2.732331\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.766843, T: 16640, Avg. loss: 2.835467\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.779676, T: 17280, Avg. loss: 2.794700\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.795386, T: 17920, Avg. loss: 2.689158\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.809601, T: 18560, Avg. loss: 2.586526\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.06, NNZs: 44, Bias: -0.827178, T: 19200, Avg. loss: 2.624687\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.839258, T: 19840, Avg. loss: 2.743357\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.852483, T: 20480, Avg. loss: 2.547765\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.862580, T: 21120, Avg. loss: 2.184022\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.875723, T: 21760, Avg. loss: 2.496151\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.890938, T: 22400, Avg. loss: 2.564650\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.904156, T: 23040, Avg. loss: 2.505766\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.917612, T: 23680, Avg. loss: 2.671161\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.930996, T: 24320, Avg. loss: 2.351704\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 38 epochs took 0.03 seconds\n",
      "--- training time 0.03272199630737305 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 1.81, NNZs: 44, Bias: -0.132429, T: 640, Avg. loss: 30.907784\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.39, NNZs: 44, Bias: -0.188078, T: 1280, Avg. loss: 10.660232\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.25, NNZs: 44, Bias: -0.238202, T: 1920, Avg. loss: 9.212930\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.276557, T: 2560, Avg. loss: 9.238287\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.316699, T: 3200, Avg. loss: 7.258781\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.20, NNZs: 44, Bias: -0.346927, T: 3840, Avg. loss: 6.083062\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.05, NNZs: 44, Bias: -0.377001, T: 4480, Avg. loss: 6.074865\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.405743, T: 5120, Avg. loss: 5.408817\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.05, NNZs: 44, Bias: -0.434407, T: 5760, Avg. loss: 5.172337\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.07, NNZs: 44, Bias: -0.459415, T: 6400, Avg. loss: 4.729603\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.08, NNZs: 44, Bias: -0.484385, T: 7040, Avg. loss: 4.626073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.505227, T: 7680, Avg. loss: 4.504605\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.529476, T: 8320, Avg. loss: 3.886199\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.548966, T: 8960, Avg. loss: 4.488182\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.574013, T: 9600, Avg. loss: 4.301054\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1.06, NNZs: 44, Bias: -0.594354, T: 10240, Avg. loss: 3.785013\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.616599, T: 10880, Avg. loss: 3.399852\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.636243, T: 11520, Avg. loss: 3.280211\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.96, NNZs: 44, Bias: -0.654038, T: 12160, Avg. loss: 3.690596\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.671599, T: 12800, Avg. loss: 3.693993\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.689654, T: 13440, Avg. loss: 3.407431\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.705857, T: 14080, Avg. loss: 2.926440\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.720351, T: 14720, Avg. loss: 3.038130\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.736537, T: 15360, Avg. loss: 3.017863\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.751568, T: 16000, Avg. loss: 2.732331\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.766843, T: 16640, Avg. loss: 2.835467\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.779676, T: 17280, Avg. loss: 2.794700\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.795386, T: 17920, Avg. loss: 2.689158\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.809601, T: 18560, Avg. loss: 2.586526\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.06, NNZs: 44, Bias: -0.827178, T: 19200, Avg. loss: 2.624687\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.839258, T: 19840, Avg. loss: 2.743357\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.852483, T: 20480, Avg. loss: 2.547765\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.862580, T: 21120, Avg. loss: 2.184022\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.875723, T: 21760, Avg. loss: 2.496151\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.890938, T: 22400, Avg. loss: 2.564650\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.904156, T: 23040, Avg. loss: 2.505766\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.917612, T: 23680, Avg. loss: 2.671161\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.930996, T: 24320, Avg. loss: 2.351704\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 38 epochs took 0.01 seconds\n",
      "--- training time 0.011656045913696289 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 1.81, NNZs: 44, Bias: -0.132429, T: 640, Avg. loss: 30.907784\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.39, NNZs: 44, Bias: -0.188078, T: 1280, Avg. loss: 10.660232\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.25, NNZs: 44, Bias: -0.238202, T: 1920, Avg. loss: 9.212930\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.276557, T: 2560, Avg. loss: 9.238287\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.316699, T: 3200, Avg. loss: 7.258781\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.20, NNZs: 44, Bias: -0.346927, T: 3840, Avg. loss: 6.083062\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.05, NNZs: 44, Bias: -0.377001, T: 4480, Avg. loss: 6.074865\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.405743, T: 5120, Avg. loss: 5.408817\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.05, NNZs: 44, Bias: -0.434407, T: 5760, Avg. loss: 5.172337\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.07, NNZs: 44, Bias: -0.459415, T: 6400, Avg. loss: 4.729603\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.08, NNZs: 44, Bias: -0.484385, T: 7040, Avg. loss: 4.626073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.505227, T: 7680, Avg. loss: 4.504605\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.529476, T: 8320, Avg. loss: 3.886199\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.548966, T: 8960, Avg. loss: 4.488182\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.574013, T: 9600, Avg. loss: 4.301054\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1.06, NNZs: 44, Bias: -0.594354, T: 10240, Avg. loss: 3.785013\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.616599, T: 10880, Avg. loss: 3.399852\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.636243, T: 11520, Avg. loss: 3.280211\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.96, NNZs: 44, Bias: -0.654038, T: 12160, Avg. loss: 3.690596\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.671599, T: 12800, Avg. loss: 3.693993\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.689654, T: 13440, Avg. loss: 3.407431\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.705857, T: 14080, Avg. loss: 2.926440\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.720351, T: 14720, Avg. loss: 3.038130\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.736537, T: 15360, Avg. loss: 3.017863\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.751568, T: 16000, Avg. loss: 2.732331\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.766843, T: 16640, Avg. loss: 2.835467\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.779676, T: 17280, Avg. loss: 2.794700\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.795386, T: 17920, Avg. loss: 2.689158\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.809601, T: 18560, Avg. loss: 2.586526\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.06, NNZs: 44, Bias: -0.827178, T: 19200, Avg. loss: 2.624687\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.839258, T: 19840, Avg. loss: 2.743357\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.852483, T: 20480, Avg. loss: 2.547765\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.862580, T: 21120, Avg. loss: 2.184022\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.875723, T: 21760, Avg. loss: 2.496151\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.890938, T: 22400, Avg. loss: 2.564650\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.904156, T: 23040, Avg. loss: 2.505766\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.917612, T: 23680, Avg. loss: 2.671161\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 1.03, NNZs: 44, Bias: -0.930996, T: 24320, Avg. loss: 2.351704\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 38 epochs took 0.01 seconds\n",
      "--- training time 0.012057781219482422 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 10.91, NNZs: 43, Bias: -2.550009, T: 640, Avg. loss: 402.389039\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.71, NNZs: 44, Bias: -5.050009, T: 1280, Avg. loss: 323.294791\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.46, NNZs: 44, Bias: -7.512515, T: 1920, Avg. loss: 359.311537\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.05, NNZs: 44, Bias: -10.201947, T: 2560, Avg. loss: 399.918189\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.69, NNZs: 44, Bias: -12.720222, T: 3200, Avg. loss: 361.718888\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.91, NNZs: 44, Bias: -14.880795, T: 3840, Avg. loss: 377.351976\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 19.10, NNZs: 44, Bias: -17.180424, T: 4480, Avg. loss: 376.820507\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 5.86, NNZs: 44, Bias: -17.603116, T: 5120, Avg. loss: 83.034376\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 9.02, NNZs: 44, Bias: -18.059716, T: 5760, Avg. loss: 72.589001\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 7.08, NNZs: 44, Bias: -18.459718, T: 6400, Avg. loss: 68.394544\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 7.82, NNZs: 44, Bias: -18.920503, T: 7040, Avg. loss: 75.816719\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 9.16, NNZs: 44, Bias: -19.338538, T: 7680, Avg. loss: 82.091663\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 6.28, NNZs: 44, Bias: -19.866070, T: 8320, Avg. loss: 80.338302\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 8.67, NNZs: 44, Bias: -20.249927, T: 8960, Avg. loss: 77.763763\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 6.72, NNZs: 44, Bias: -20.783372, T: 9600, Avg. loss: 84.528284\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 2.60, NNZs: 44, Bias: -20.831906, T: 10240, Avg. loss: 21.081200\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 2.52, NNZs: 44, Bias: -20.915984, T: 10880, Avg. loss: 13.879038\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 2.16, NNZs: 44, Bias: -20.997294, T: 11520, Avg. loss: 14.867438\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 1.96, NNZs: 44, Bias: -21.073347, T: 12160, Avg. loss: 15.247984\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.67, NNZs: 44, Bias: -21.147747, T: 12800, Avg. loss: 15.697421\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.95, NNZs: 44, Bias: -21.221151, T: 13440, Avg. loss: 15.912261\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 1.86, NNZs: 44, Bias: -21.289947, T: 14080, Avg. loss: 13.323098\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 2.05, NNZs: 44, Bias: -21.355879, T: 14720, Avg. loss: 15.670591\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 2.38, NNZs: 44, Bias: -21.439276, T: 15360, Avg. loss: 14.048558\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 2.40, NNZs: 44, Bias: -21.531538, T: 16000, Avg. loss: 15.405405\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 1.73, NNZs: 44, Bias: -21.595660, T: 16640, Avg. loss: 15.098512\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 2.46, NNZs: 44, Bias: -21.656147, T: 17280, Avg. loss: 14.324409\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1.48, NNZs: 44, Bias: -21.665591, T: 17920, Avg. loss: 5.804966\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.08, NNZs: 44, Bias: -21.673279, T: 18560, Avg. loss: 2.931253\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.02, NNZs: 44, Bias: -21.683801, T: 19200, Avg. loss: 2.375622\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.99, NNZs: 44, Bias: -21.692709, T: 19840, Avg. loss: 2.414061\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.95, NNZs: 44, Bias: -21.702718, T: 20480, Avg. loss: 2.667215\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.95, NNZs: 44, Bias: -21.708766, T: 21120, Avg. loss: 2.440674\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.720001, T: 21760, Avg. loss: 2.313048\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.732348, T: 22400, Avg. loss: 2.643310\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.742019, T: 23040, Avg. loss: 2.435969\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.90, NNZs: 44, Bias: -21.752661, T: 23680, Avg. loss: 2.758176\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.90, NNZs: 44, Bias: -21.763259, T: 24320, Avg. loss: 2.249982\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.91, NNZs: 44, Bias: -21.772147, T: 24960, Avg. loss: 2.264457\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.89, NNZs: 44, Bias: -21.780717, T: 25600, Avg. loss: 2.408183\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.87, NNZs: 44, Bias: -21.788835, T: 26240, Avg. loss: 2.288684\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.86, NNZs: 44, Bias: -21.796010, T: 26880, Avg. loss: 2.150486\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.88, NNZs: 44, Bias: -21.804099, T: 27520, Avg. loss: 2.213629\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.84, NNZs: 44, Bias: -21.813593, T: 28160, Avg. loss: 2.698464\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.85, NNZs: 44, Bias: -21.824923, T: 28800, Avg. loss: 2.531753\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.86, NNZs: 44, Bias: -21.835083, T: 29440, Avg. loss: 2.314919\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.87, NNZs: 44, Bias: -21.847257, T: 30080, Avg. loss: 2.572171\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.83, NNZs: 44, Bias: -21.847102, T: 30720, Avg. loss: 0.727465\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.81, NNZs: 44, Bias: -21.847476, T: 31360, Avg. loss: 0.394332\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.81, NNZs: 44, Bias: -21.847750, T: 32000, Avg. loss: 0.347348\n",
      "Total training time: 0.01 seconds.\n",
      "--- training time 0.01709604263305664 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 10.91, NNZs: 43, Bias: -2.550009, T: 640, Avg. loss: 402.389039\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.71, NNZs: 44, Bias: -5.050009, T: 1280, Avg. loss: 323.294791\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.46, NNZs: 44, Bias: -7.512515, T: 1920, Avg. loss: 359.311537\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.05, NNZs: 44, Bias: -10.201947, T: 2560, Avg. loss: 399.918189\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.69, NNZs: 44, Bias: -12.720222, T: 3200, Avg. loss: 361.718888\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.91, NNZs: 44, Bias: -14.880795, T: 3840, Avg. loss: 377.351976\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 19.10, NNZs: 44, Bias: -17.180424, T: 4480, Avg. loss: 376.820507\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 5.86, NNZs: 44, Bias: -17.603116, T: 5120, Avg. loss: 83.034376\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 9.02, NNZs: 44, Bias: -18.059716, T: 5760, Avg. loss: 72.589001\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 7.08, NNZs: 44, Bias: -18.459718, T: 6400, Avg. loss: 68.394544\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 7.82, NNZs: 44, Bias: -18.920503, T: 7040, Avg. loss: 75.816719\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 9.16, NNZs: 44, Bias: -19.338538, T: 7680, Avg. loss: 82.091663\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 6.28, NNZs: 44, Bias: -19.866070, T: 8320, Avg. loss: 80.338302\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 8.67, NNZs: 44, Bias: -20.249927, T: 8960, Avg. loss: 77.763763\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 6.72, NNZs: 44, Bias: -20.783372, T: 9600, Avg. loss: 84.528284\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 2.60, NNZs: 44, Bias: -20.831906, T: 10240, Avg. loss: 21.081200\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 2.52, NNZs: 44, Bias: -20.915984, T: 10880, Avg. loss: 13.879038\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 2.16, NNZs: 44, Bias: -20.997294, T: 11520, Avg. loss: 14.867438\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 1.96, NNZs: 44, Bias: -21.073347, T: 12160, Avg. loss: 15.247984\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.67, NNZs: 44, Bias: -21.147747, T: 12800, Avg. loss: 15.697421\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.95, NNZs: 44, Bias: -21.221151, T: 13440, Avg. loss: 15.912261\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 1.86, NNZs: 44, Bias: -21.289947, T: 14080, Avg. loss: 13.323098\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 2.05, NNZs: 44, Bias: -21.355879, T: 14720, Avg. loss: 15.670591\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 2.38, NNZs: 44, Bias: -21.439276, T: 15360, Avg. loss: 14.048558\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 2.40, NNZs: 44, Bias: -21.531538, T: 16000, Avg. loss: 15.405405\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 1.73, NNZs: 44, Bias: -21.595660, T: 16640, Avg. loss: 15.098512\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 2.46, NNZs: 44, Bias: -21.656147, T: 17280, Avg. loss: 14.324409\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1.48, NNZs: 44, Bias: -21.665591, T: 17920, Avg. loss: 5.804966\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.08, NNZs: 44, Bias: -21.673279, T: 18560, Avg. loss: 2.931253\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.02, NNZs: 44, Bias: -21.683801, T: 19200, Avg. loss: 2.375622\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.99, NNZs: 44, Bias: -21.692709, T: 19840, Avg. loss: 2.414061\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.95, NNZs: 44, Bias: -21.702718, T: 20480, Avg. loss: 2.667215\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.95, NNZs: 44, Bias: -21.708766, T: 21120, Avg. loss: 2.440674\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.720001, T: 21760, Avg. loss: 2.313048\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.732348, T: 22400, Avg. loss: 2.643310\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.742019, T: 23040, Avg. loss: 2.435969\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.90, NNZs: 44, Bias: -21.752661, T: 23680, Avg. loss: 2.758176\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.90, NNZs: 44, Bias: -21.763259, T: 24320, Avg. loss: 2.249982\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.91, NNZs: 44, Bias: -21.772147, T: 24960, Avg. loss: 2.264457\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.89, NNZs: 44, Bias: -21.780717, T: 25600, Avg. loss: 2.408183\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.87, NNZs: 44, Bias: -21.788835, T: 26240, Avg. loss: 2.288684\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.86, NNZs: 44, Bias: -21.796010, T: 26880, Avg. loss: 2.150486\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.88, NNZs: 44, Bias: -21.804099, T: 27520, Avg. loss: 2.213629\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.84, NNZs: 44, Bias: -21.813593, T: 28160, Avg. loss: 2.698464\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.85, NNZs: 44, Bias: -21.824923, T: 28800, Avg. loss: 2.531753\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.86, NNZs: 44, Bias: -21.835083, T: 29440, Avg. loss: 2.314919\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.87, NNZs: 44, Bias: -21.847257, T: 30080, Avg. loss: 2.572171\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.83, NNZs: 44, Bias: -21.847102, T: 30720, Avg. loss: 0.727465\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.81, NNZs: 44, Bias: -21.847476, T: 31360, Avg. loss: 0.394332\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.81, NNZs: 44, Bias: -21.847750, T: 32000, Avg. loss: 0.347348\n",
      "Total training time: 0.07 seconds.\n",
      "--- training time 0.07087516784667969 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 10.91, NNZs: 43, Bias: -2.550009, T: 640, Avg. loss: 402.389039\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.71, NNZs: 44, Bias: -5.050009, T: 1280, Avg. loss: 323.294791\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.46, NNZs: 44, Bias: -7.512515, T: 1920, Avg. loss: 359.311537\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.05, NNZs: 44, Bias: -10.201947, T: 2560, Avg. loss: 399.918189\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.69, NNZs: 44, Bias: -12.720222, T: 3200, Avg. loss: 361.718888\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.91, NNZs: 44, Bias: -14.880795, T: 3840, Avg. loss: 377.351976\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 19.10, NNZs: 44, Bias: -17.180424, T: 4480, Avg. loss: 376.820507\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 5.86, NNZs: 44, Bias: -17.603116, T: 5120, Avg. loss: 83.034376\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 9.02, NNZs: 44, Bias: -18.059716, T: 5760, Avg. loss: 72.589001\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 7.08, NNZs: 44, Bias: -18.459718, T: 6400, Avg. loss: 68.394544\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 7.82, NNZs: 44, Bias: -18.920503, T: 7040, Avg. loss: 75.816719\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 9.16, NNZs: 44, Bias: -19.338538, T: 7680, Avg. loss: 82.091663\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 6.28, NNZs: 44, Bias: -19.866070, T: 8320, Avg. loss: 80.338302\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 8.67, NNZs: 44, Bias: -20.249927, T: 8960, Avg. loss: 77.763763\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 6.72, NNZs: 44, Bias: -20.783372, T: 9600, Avg. loss: 84.528284\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 2.60, NNZs: 44, Bias: -20.831906, T: 10240, Avg. loss: 21.081200\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 2.52, NNZs: 44, Bias: -20.915984, T: 10880, Avg. loss: 13.879038\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 2.16, NNZs: 44, Bias: -20.997294, T: 11520, Avg. loss: 14.867438\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 1.96, NNZs: 44, Bias: -21.073347, T: 12160, Avg. loss: 15.247984\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.67, NNZs: 44, Bias: -21.147747, T: 12800, Avg. loss: 15.697421\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.95, NNZs: 44, Bias: -21.221151, T: 13440, Avg. loss: 15.912261\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 1.86, NNZs: 44, Bias: -21.289947, T: 14080, Avg. loss: 13.323098\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 2.05, NNZs: 44, Bias: -21.355879, T: 14720, Avg. loss: 15.670591\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 2.38, NNZs: 44, Bias: -21.439276, T: 15360, Avg. loss: 14.048558\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 2.40, NNZs: 44, Bias: -21.531538, T: 16000, Avg. loss: 15.405405\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 1.73, NNZs: 44, Bias: -21.595660, T: 16640, Avg. loss: 15.098512\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 2.46, NNZs: 44, Bias: -21.656147, T: 17280, Avg. loss: 14.324409\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1.48, NNZs: 44, Bias: -21.665591, T: 17920, Avg. loss: 5.804966\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.08, NNZs: 44, Bias: -21.673279, T: 18560, Avg. loss: 2.931253\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.02, NNZs: 44, Bias: -21.683801, T: 19200, Avg. loss: 2.375622\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.99, NNZs: 44, Bias: -21.692709, T: 19840, Avg. loss: 2.414061\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.95, NNZs: 44, Bias: -21.702718, T: 20480, Avg. loss: 2.667215\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.95, NNZs: 44, Bias: -21.708766, T: 21120, Avg. loss: 2.440674\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.720001, T: 21760, Avg. loss: 2.313048\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.732348, T: 22400, Avg. loss: 2.643310\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.742019, T: 23040, Avg. loss: 2.435969\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.90, NNZs: 44, Bias: -21.752661, T: 23680, Avg. loss: 2.758176\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.90, NNZs: 44, Bias: -21.763259, T: 24320, Avg. loss: 2.249982\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.91, NNZs: 44, Bias: -21.772147, T: 24960, Avg. loss: 2.264457\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.89, NNZs: 44, Bias: -21.780717, T: 25600, Avg. loss: 2.408183\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.87, NNZs: 44, Bias: -21.788835, T: 26240, Avg. loss: 2.288684\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.86, NNZs: 44, Bias: -21.796010, T: 26880, Avg. loss: 2.150486\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.88, NNZs: 44, Bias: -21.804099, T: 27520, Avg. loss: 2.213629\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.84, NNZs: 44, Bias: -21.813593, T: 28160, Avg. loss: 2.698464\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.85, NNZs: 44, Bias: -21.824923, T: 28800, Avg. loss: 2.531753\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.86, NNZs: 44, Bias: -21.835083, T: 29440, Avg. loss: 2.314919\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.87, NNZs: 44, Bias: -21.847257, T: 30080, Avg. loss: 2.572171\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.83, NNZs: 44, Bias: -21.847102, T: 30720, Avg. loss: 0.727465\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.81, NNZs: 44, Bias: -21.847476, T: 31360, Avg. loss: 0.394332\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.81, NNZs: 44, Bias: -21.847750, T: 32000, Avg. loss: 0.347348\n",
      "Total training time: 0.01 seconds.\n",
      "--- training time 0.016949892044067383 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.002804, T: 640, Avg. loss: 0.530745\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.004999, T: 1280, Avg. loss: 0.473073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.007353, T: 1920, Avg. loss: 0.477698\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.009563, T: 2560, Avg. loss: 0.526879\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.012097, T: 3200, Avg. loss: 0.492399\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.014273, T: 3840, Avg. loss: 0.483501\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.016534, T: 4480, Avg. loss: 0.501115\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.005156993865966797 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.002804, T: 640, Avg. loss: 0.530745\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.004999, T: 1280, Avg. loss: 0.473073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.007353, T: 1920, Avg. loss: 0.477698\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.009563, T: 2560, Avg. loss: 0.526879\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.012097, T: 3200, Avg. loss: 0.492399\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.014273, T: 3840, Avg. loss: 0.483501\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.016534, T: 4480, Avg. loss: 0.501115\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.005263090133666992 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.002804, T: 640, Avg. loss: 0.530745\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.004999, T: 1280, Avg. loss: 0.473073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.007353, T: 1920, Avg. loss: 0.477698\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.009563, T: 2560, Avg. loss: 0.526879\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.012097, T: 3200, Avg. loss: 0.492399\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.014273, T: 3840, Avg. loss: 0.483501\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.016534, T: 4480, Avg. loss: 0.501115\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.005447864532470703 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 2495.55, NNZs: 40, Bias: -173.243886, T: 640, Avg. loss: 30801.248757\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2050.57, NNZs: 43, Bias: -287.332502, T: 1280, Avg. loss: 18969.702448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1652.84, NNZs: 43, Bias: -367.519263, T: 1920, Avg. loss: 14798.941977\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1456.19, NNZs: 43, Bias: -429.450141, T: 2560, Avg. loss: 13148.500053\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1381.34, NNZs: 43, Bias: -483.250401, T: 3200, Avg. loss: 10270.942512\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1567.17, NNZs: 43, Bias: -522.966221, T: 3840, Avg. loss: 8722.036104\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1079.76, NNZs: 43, Bias: -553.762673, T: 4480, Avg. loss: 7476.517176\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1214.10, NNZs: 43, Bias: -595.186474, T: 5120, Avg. loss: 6678.600067\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1278.12, NNZs: 44, Bias: -624.695637, T: 5760, Avg. loss: 5915.409154\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1285.32, NNZs: 44, Bias: -651.612881, T: 6400, Avg. loss: 5752.807953\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1139.73, NNZs: 44, Bias: -675.035744, T: 7040, Avg. loss: 4983.009927\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1112.20, NNZs: 44, Bias: -692.915017, T: 7680, Avg. loss: 4710.982586\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1033.57, NNZs: 44, Bias: -716.356350, T: 8320, Avg. loss: 4034.006958\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 949.86, NNZs: 44, Bias: -735.998619, T: 8960, Avg. loss: 4552.730168\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1030.75, NNZs: 44, Bias: -758.365883, T: 9600, Avg. loss: 4016.078415\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 988.92, NNZs: 44, Bias: -775.763258, T: 10240, Avg. loss: 3432.888311\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1039.65, NNZs: 44, Bias: -792.294392, T: 10880, Avg. loss: 2936.404461\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1010.74, NNZs: 44, Bias: -806.220773, T: 11520, Avg. loss: 2984.979803\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 974.24, NNZs: 44, Bias: -821.803321, T: 12160, Avg. loss: 3316.948645\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 963.70, NNZs: 44, Bias: -835.139095, T: 12800, Avg. loss: 2951.386082\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 970.55, NNZs: 44, Bias: -849.324160, T: 13440, Avg. loss: 2989.667011\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 988.25, NNZs: 44, Bias: -861.529135, T: 14080, Avg. loss: 2281.903736\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 987.73, NNZs: 44, Bias: -871.963436, T: 14720, Avg. loss: 2682.600205\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 976.90, NNZs: 44, Bias: -884.481374, T: 15360, Avg. loss: 2330.265429\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 974.74, NNZs: 44, Bias: -895.322019, T: 16000, Avg. loss: 2155.861475\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 950.52, NNZs: 44, Bias: -905.148129, T: 16640, Avg. loss: 2048.901443\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 961.11, NNZs: 44, Bias: -914.615551, T: 17280, Avg. loss: 2048.271031\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 957.22, NNZs: 44, Bias: -926.464267, T: 17920, Avg. loss: 1869.561717\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 950.08, NNZs: 44, Bias: -936.829761, T: 18560, Avg. loss: 1802.534811\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 980.53, NNZs: 44, Bias: -947.912722, T: 19200, Avg. loss: 1866.771309\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 957.39, NNZs: 44, Bias: -954.247734, T: 19840, Avg. loss: 1798.679859\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 950.76, NNZs: 44, Bias: -963.227196, T: 20480, Avg. loss: 1781.657030\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 945.74, NNZs: 44, Bias: -968.739841, T: 21120, Avg. loss: 1624.041529\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 945.61, NNZs: 44, Bias: -977.686627, T: 21760, Avg. loss: 1596.320191\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 954.60, NNZs: 44, Bias: -985.911547, T: 22400, Avg. loss: 1568.622498\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 945.79, NNZs: 44, Bias: -993.914015, T: 23040, Avg. loss: 1572.932396\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 942.78, NNZs: 44, Bias: -1001.726833, T: 23680, Avg. loss: 1601.846946\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 938.02, NNZs: 44, Bias: -1009.316532, T: 24320, Avg. loss: 1452.959411\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 934.07, NNZs: 44, Bias: -1016.737288, T: 24960, Avg. loss: 1278.891445\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 935.74, NNZs: 44, Bias: -1023.199696, T: 25600, Avg. loss: 1403.652975\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 922.73, NNZs: 44, Bias: -1028.397080, T: 26240, Avg. loss: 1359.303331\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 915.36, NNZs: 44, Bias: -1033.470784, T: 26880, Avg. loss: 1196.712144\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 916.26, NNZs: 44, Bias: -1038.435008, T: 27520, Avg. loss: 1333.135925\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 914.79, NNZs: 44, Bias: -1044.330947, T: 28160, Avg. loss: 1226.511264\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 918.79, NNZs: 44, Bias: -1051.136086, T: 28800, Avg. loss: 1205.729002\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 910.75, NNZs: 44, Bias: -1056.290764, T: 29440, Avg. loss: 1067.009941\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 926.65, NNZs: 44, Bias: -1063.128725, T: 30080, Avg. loss: 1190.628791\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 924.57, NNZs: 44, Bias: -1068.861692, T: 30720, Avg. loss: 1049.310080\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 925.09, NNZs: 44, Bias: -1074.160225, T: 31360, Avg. loss: 1110.357461\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 919.66, NNZs: 44, Bias: -1079.057770, T: 32000, Avg. loss: 1148.884431\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 916.19, NNZs: 44, Bias: -1083.860439, T: 32640, Avg. loss: 951.042110\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 904.96, NNZs: 44, Bias: -1088.282155, T: 33280, Avg. loss: 945.939081\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 902.75, NNZs: 44, Bias: -1092.744731, T: 33920, Avg. loss: 1033.170353\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 899.03, NNZs: 44, Bias: -1097.856195, T: 34560, Avg. loss: 979.107370\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 894.86, NNZs: 44, Bias: -1102.313042, T: 35200, Avg. loss: 996.605479\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 912.39, NNZs: 44, Bias: -1107.787375, T: 35840, Avg. loss: 935.173136\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 898.29, NNZs: 44, Bias: -1112.090240, T: 36480, Avg. loss: 923.409901\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 896.24, NNZs: 44, Bias: -1116.319380, T: 37120, Avg. loss: 907.743547\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 897.41, NNZs: 44, Bias: -1120.999807, T: 37760, Avg. loss: 974.755917\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 889.59, NNZs: 44, Bias: -1125.607573, T: 38400, Avg. loss: 903.230092\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 887.86, NNZs: 44, Bias: -1129.644132, T: 39040, Avg. loss: 840.587006\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 886.24, NNZs: 44, Bias: -1133.610148, T: 39680, Avg. loss: 744.851484\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 886.11, NNZs: 44, Bias: -1137.760367, T: 40320, Avg. loss: 794.789842\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 886.62, NNZs: 44, Bias: -1141.358172, T: 40960, Avg. loss: 911.947559\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 887.62, NNZs: 44, Bias: -1145.615043, T: 41600, Avg. loss: 714.642955\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 882.87, NNZs: 44, Bias: -1148.872796, T: 42240, Avg. loss: 762.570822\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 875.14, NNZs: 44, Bias: -1153.008843, T: 42880, Avg. loss: 726.207850\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 877.37, NNZs: 44, Bias: -1156.471768, T: 43520, Avg. loss: 775.719993\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 876.79, NNZs: 44, Bias: -1159.595838, T: 44160, Avg. loss: 707.479024\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 874.91, NNZs: 44, Bias: -1163.553259, T: 44800, Avg. loss: 777.630009\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 870.75, NNZs: 44, Bias: -1166.591431, T: 45440, Avg. loss: 757.268589\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 866.30, NNZs: 44, Bias: -1169.798316, T: 46080, Avg. loss: 758.242938\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 865.10, NNZs: 44, Bias: -1173.174130, T: 46720, Avg. loss: 703.222684\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 865.32, NNZs: 44, Bias: -1176.917043, T: 47360, Avg. loss: 734.025923\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 858.54, NNZs: 44, Bias: -1179.793455, T: 48000, Avg. loss: 695.823355\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 862.10, NNZs: 44, Bias: -1182.836877, T: 48640, Avg. loss: 591.220628\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 857.91, NNZs: 44, Bias: -1185.440426, T: 49280, Avg. loss: 783.068207\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 859.97, NNZs: 44, Bias: -1188.601682, T: 49920, Avg. loss: 626.584526\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 857.29, NNZs: 44, Bias: -1191.921791, T: 50560, Avg. loss: 623.839323\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 856.27, NNZs: 44, Bias: -1194.621243, T: 51200, Avg. loss: 646.226516\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 851.58, NNZs: 44, Bias: -1197.477257, T: 51840, Avg. loss: 640.572277\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 81 epochs took 0.05 seconds\n",
      "--- training time 0.048757076263427734 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 2495.55, NNZs: 40, Bias: -173.243886, T: 640, Avg. loss: 30801.248757\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2050.57, NNZs: 43, Bias: -287.332502, T: 1280, Avg. loss: 18969.702448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1652.84, NNZs: 43, Bias: -367.519263, T: 1920, Avg. loss: 14798.941977\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1456.19, NNZs: 43, Bias: -429.450141, T: 2560, Avg. loss: 13148.500053\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1381.34, NNZs: 43, Bias: -483.250401, T: 3200, Avg. loss: 10270.942512\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1567.17, NNZs: 43, Bias: -522.966221, T: 3840, Avg. loss: 8722.036104\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1079.76, NNZs: 43, Bias: -553.762673, T: 4480, Avg. loss: 7476.517176\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1214.10, NNZs: 43, Bias: -595.186474, T: 5120, Avg. loss: 6678.600067\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1278.12, NNZs: 44, Bias: -624.695637, T: 5760, Avg. loss: 5915.409154\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1285.32, NNZs: 44, Bias: -651.612881, T: 6400, Avg. loss: 5752.807953\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1139.73, NNZs: 44, Bias: -675.035744, T: 7040, Avg. loss: 4983.009927\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1112.20, NNZs: 44, Bias: -692.915017, T: 7680, Avg. loss: 4710.982586\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1033.57, NNZs: 44, Bias: -716.356350, T: 8320, Avg. loss: 4034.006958\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 949.86, NNZs: 44, Bias: -735.998619, T: 8960, Avg. loss: 4552.730168\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1030.75, NNZs: 44, Bias: -758.365883, T: 9600, Avg. loss: 4016.078415\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 988.92, NNZs: 44, Bias: -775.763258, T: 10240, Avg. loss: 3432.888311\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1039.65, NNZs: 44, Bias: -792.294392, T: 10880, Avg. loss: 2936.404461\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1010.74, NNZs: 44, Bias: -806.220773, T: 11520, Avg. loss: 2984.979803\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 974.24, NNZs: 44, Bias: -821.803321, T: 12160, Avg. loss: 3316.948645\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 963.70, NNZs: 44, Bias: -835.139095, T: 12800, Avg. loss: 2951.386082\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 970.55, NNZs: 44, Bias: -849.324160, T: 13440, Avg. loss: 2989.667011\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 988.25, NNZs: 44, Bias: -861.529135, T: 14080, Avg. loss: 2281.903736\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 987.73, NNZs: 44, Bias: -871.963436, T: 14720, Avg. loss: 2682.600205\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 976.90, NNZs: 44, Bias: -884.481374, T: 15360, Avg. loss: 2330.265429\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 974.74, NNZs: 44, Bias: -895.322019, T: 16000, Avg. loss: 2155.861475\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 950.52, NNZs: 44, Bias: -905.148129, T: 16640, Avg. loss: 2048.901443\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 961.11, NNZs: 44, Bias: -914.615551, T: 17280, Avg. loss: 2048.271031\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 957.22, NNZs: 44, Bias: -926.464267, T: 17920, Avg. loss: 1869.561717\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 950.08, NNZs: 44, Bias: -936.829761, T: 18560, Avg. loss: 1802.534811\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 980.53, NNZs: 44, Bias: -947.912722, T: 19200, Avg. loss: 1866.771309\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 957.39, NNZs: 44, Bias: -954.247734, T: 19840, Avg. loss: 1798.679859\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 950.76, NNZs: 44, Bias: -963.227196, T: 20480, Avg. loss: 1781.657030\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 945.74, NNZs: 44, Bias: -968.739841, T: 21120, Avg. loss: 1624.041529\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 945.61, NNZs: 44, Bias: -977.686627, T: 21760, Avg. loss: 1596.320191\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 954.60, NNZs: 44, Bias: -985.911547, T: 22400, Avg. loss: 1568.622498\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 945.79, NNZs: 44, Bias: -993.914015, T: 23040, Avg. loss: 1572.932396\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 942.78, NNZs: 44, Bias: -1001.726833, T: 23680, Avg. loss: 1601.846946\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 938.02, NNZs: 44, Bias: -1009.316532, T: 24320, Avg. loss: 1452.959411\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 934.07, NNZs: 44, Bias: -1016.737288, T: 24960, Avg. loss: 1278.891445\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 935.74, NNZs: 44, Bias: -1023.199696, T: 25600, Avg. loss: 1403.652975\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 922.73, NNZs: 44, Bias: -1028.397080, T: 26240, Avg. loss: 1359.303331\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 915.36, NNZs: 44, Bias: -1033.470784, T: 26880, Avg. loss: 1196.712144\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 916.26, NNZs: 44, Bias: -1038.435008, T: 27520, Avg. loss: 1333.135925\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 914.79, NNZs: 44, Bias: -1044.330947, T: 28160, Avg. loss: 1226.511264\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 918.79, NNZs: 44, Bias: -1051.136086, T: 28800, Avg. loss: 1205.729002\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 910.75, NNZs: 44, Bias: -1056.290764, T: 29440, Avg. loss: 1067.009941\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 926.65, NNZs: 44, Bias: -1063.128725, T: 30080, Avg. loss: 1190.628791\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 924.57, NNZs: 44, Bias: -1068.861692, T: 30720, Avg. loss: 1049.310080\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 925.09, NNZs: 44, Bias: -1074.160225, T: 31360, Avg. loss: 1110.357461\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 919.66, NNZs: 44, Bias: -1079.057770, T: 32000, Avg. loss: 1148.884431\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 916.19, NNZs: 44, Bias: -1083.860439, T: 32640, Avg. loss: 951.042110\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 904.96, NNZs: 44, Bias: -1088.282155, T: 33280, Avg. loss: 945.939081\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 902.75, NNZs: 44, Bias: -1092.744731, T: 33920, Avg. loss: 1033.170353\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 899.03, NNZs: 44, Bias: -1097.856195, T: 34560, Avg. loss: 979.107370\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 894.86, NNZs: 44, Bias: -1102.313042, T: 35200, Avg. loss: 996.605479\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 912.39, NNZs: 44, Bias: -1107.787375, T: 35840, Avg. loss: 935.173136\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 898.29, NNZs: 44, Bias: -1112.090240, T: 36480, Avg. loss: 923.409901\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 896.24, NNZs: 44, Bias: -1116.319380, T: 37120, Avg. loss: 907.743547\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 897.41, NNZs: 44, Bias: -1120.999807, T: 37760, Avg. loss: 974.755917\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 889.59, NNZs: 44, Bias: -1125.607573, T: 38400, Avg. loss: 903.230092\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 887.86, NNZs: 44, Bias: -1129.644132, T: 39040, Avg. loss: 840.587006\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 886.24, NNZs: 44, Bias: -1133.610148, T: 39680, Avg. loss: 744.851484\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 886.11, NNZs: 44, Bias: -1137.760367, T: 40320, Avg. loss: 794.789842\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 886.62, NNZs: 44, Bias: -1141.358172, T: 40960, Avg. loss: 911.947559\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 887.62, NNZs: 44, Bias: -1145.615043, T: 41600, Avg. loss: 714.642955\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 882.87, NNZs: 44, Bias: -1148.872796, T: 42240, Avg. loss: 762.570822\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 875.14, NNZs: 44, Bias: -1153.008843, T: 42880, Avg. loss: 726.207850\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 877.37, NNZs: 44, Bias: -1156.471768, T: 43520, Avg. loss: 775.719993\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 876.79, NNZs: 44, Bias: -1159.595838, T: 44160, Avg. loss: 707.479024\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 874.91, NNZs: 44, Bias: -1163.553259, T: 44800, Avg. loss: 777.630009\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 870.75, NNZs: 44, Bias: -1166.591431, T: 45440, Avg. loss: 757.268589\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 866.30, NNZs: 44, Bias: -1169.798316, T: 46080, Avg. loss: 758.242938\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 865.10, NNZs: 44, Bias: -1173.174130, T: 46720, Avg. loss: 703.222684\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 865.32, NNZs: 44, Bias: -1176.917043, T: 47360, Avg. loss: 734.025923\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 858.54, NNZs: 44, Bias: -1179.793455, T: 48000, Avg. loss: 695.823355\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 862.10, NNZs: 44, Bias: -1182.836877, T: 48640, Avg. loss: 591.220628\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 857.91, NNZs: 44, Bias: -1185.440426, T: 49280, Avg. loss: 783.068207\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 859.97, NNZs: 44, Bias: -1188.601682, T: 49920, Avg. loss: 626.584526\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 857.29, NNZs: 44, Bias: -1191.921791, T: 50560, Avg. loss: 623.839323\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 856.27, NNZs: 44, Bias: -1194.621243, T: 51200, Avg. loss: 646.226516\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 851.58, NNZs: 44, Bias: -1197.477257, T: 51840, Avg. loss: 640.572277\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 81 epochs took 0.02 seconds\n",
      "--- training time 0.024911165237426758 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 2495.55, NNZs: 40, Bias: -173.243886, T: 640, Avg. loss: 30801.248757\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2050.57, NNZs: 43, Bias: -287.332502, T: 1280, Avg. loss: 18969.702448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1652.84, NNZs: 43, Bias: -367.519263, T: 1920, Avg. loss: 14798.941977\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1456.19, NNZs: 43, Bias: -429.450141, T: 2560, Avg. loss: 13148.500053\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1381.34, NNZs: 43, Bias: -483.250401, T: 3200, Avg. loss: 10270.942512\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1567.17, NNZs: 43, Bias: -522.966221, T: 3840, Avg. loss: 8722.036104\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1079.76, NNZs: 43, Bias: -553.762673, T: 4480, Avg. loss: 7476.517176\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1214.10, NNZs: 43, Bias: -595.186474, T: 5120, Avg. loss: 6678.600067\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1278.12, NNZs: 44, Bias: -624.695637, T: 5760, Avg. loss: 5915.409154\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1285.32, NNZs: 44, Bias: -651.612881, T: 6400, Avg. loss: 5752.807953\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1139.73, NNZs: 44, Bias: -675.035744, T: 7040, Avg. loss: 4983.009927\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1112.20, NNZs: 44, Bias: -692.915017, T: 7680, Avg. loss: 4710.982586\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1033.57, NNZs: 44, Bias: -716.356350, T: 8320, Avg. loss: 4034.006958\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 949.86, NNZs: 44, Bias: -735.998619, T: 8960, Avg. loss: 4552.730168\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1030.75, NNZs: 44, Bias: -758.365883, T: 9600, Avg. loss: 4016.078415\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 988.92, NNZs: 44, Bias: -775.763258, T: 10240, Avg. loss: 3432.888311\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1039.65, NNZs: 44, Bias: -792.294392, T: 10880, Avg. loss: 2936.404461\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1010.74, NNZs: 44, Bias: -806.220773, T: 11520, Avg. loss: 2984.979803\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 974.24, NNZs: 44, Bias: -821.803321, T: 12160, Avg. loss: 3316.948645\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 963.70, NNZs: 44, Bias: -835.139095, T: 12800, Avg. loss: 2951.386082\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 970.55, NNZs: 44, Bias: -849.324160, T: 13440, Avg. loss: 2989.667011\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 988.25, NNZs: 44, Bias: -861.529135, T: 14080, Avg. loss: 2281.903736\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 987.73, NNZs: 44, Bias: -871.963436, T: 14720, Avg. loss: 2682.600205\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 976.90, NNZs: 44, Bias: -884.481374, T: 15360, Avg. loss: 2330.265429\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 974.74, NNZs: 44, Bias: -895.322019, T: 16000, Avg. loss: 2155.861475\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 950.52, NNZs: 44, Bias: -905.148129, T: 16640, Avg. loss: 2048.901443\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 961.11, NNZs: 44, Bias: -914.615551, T: 17280, Avg. loss: 2048.271031\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 957.22, NNZs: 44, Bias: -926.464267, T: 17920, Avg. loss: 1869.561717\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 950.08, NNZs: 44, Bias: -936.829761, T: 18560, Avg. loss: 1802.534811\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 980.53, NNZs: 44, Bias: -947.912722, T: 19200, Avg. loss: 1866.771309\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 957.39, NNZs: 44, Bias: -954.247734, T: 19840, Avg. loss: 1798.679859\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 950.76, NNZs: 44, Bias: -963.227196, T: 20480, Avg. loss: 1781.657030\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 945.74, NNZs: 44, Bias: -968.739841, T: 21120, Avg. loss: 1624.041529\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 945.61, NNZs: 44, Bias: -977.686627, T: 21760, Avg. loss: 1596.320191\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 954.60, NNZs: 44, Bias: -985.911547, T: 22400, Avg. loss: 1568.622498\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 945.79, NNZs: 44, Bias: -993.914015, T: 23040, Avg. loss: 1572.932396\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 942.78, NNZs: 44, Bias: -1001.726833, T: 23680, Avg. loss: 1601.846946\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 938.02, NNZs: 44, Bias: -1009.316532, T: 24320, Avg. loss: 1452.959411\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 934.07, NNZs: 44, Bias: -1016.737288, T: 24960, Avg. loss: 1278.891445\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 935.74, NNZs: 44, Bias: -1023.199696, T: 25600, Avg. loss: 1403.652975\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 922.73, NNZs: 44, Bias: -1028.397080, T: 26240, Avg. loss: 1359.303331\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 915.36, NNZs: 44, Bias: -1033.470784, T: 26880, Avg. loss: 1196.712144\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 916.26, NNZs: 44, Bias: -1038.435008, T: 27520, Avg. loss: 1333.135925\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 914.79, NNZs: 44, Bias: -1044.330947, T: 28160, Avg. loss: 1226.511264\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 918.79, NNZs: 44, Bias: -1051.136086, T: 28800, Avg. loss: 1205.729002\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 910.75, NNZs: 44, Bias: -1056.290764, T: 29440, Avg. loss: 1067.009941\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 926.65, NNZs: 44, Bias: -1063.128725, T: 30080, Avg. loss: 1190.628791\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 924.57, NNZs: 44, Bias: -1068.861692, T: 30720, Avg. loss: 1049.310080\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 925.09, NNZs: 44, Bias: -1074.160225, T: 31360, Avg. loss: 1110.357461\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 919.66, NNZs: 44, Bias: -1079.057770, T: 32000, Avg. loss: 1148.884431\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 916.19, NNZs: 44, Bias: -1083.860439, T: 32640, Avg. loss: 951.042110\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 904.96, NNZs: 44, Bias: -1088.282155, T: 33280, Avg. loss: 945.939081\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 902.75, NNZs: 44, Bias: -1092.744731, T: 33920, Avg. loss: 1033.170353\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 899.03, NNZs: 44, Bias: -1097.856195, T: 34560, Avg. loss: 979.107370\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 894.86, NNZs: 44, Bias: -1102.313042, T: 35200, Avg. loss: 996.605479\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 912.39, NNZs: 44, Bias: -1107.787375, T: 35840, Avg. loss: 935.173136\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 898.29, NNZs: 44, Bias: -1112.090240, T: 36480, Avg. loss: 923.409901\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 896.24, NNZs: 44, Bias: -1116.319380, T: 37120, Avg. loss: 907.743547\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 897.41, NNZs: 44, Bias: -1120.999807, T: 37760, Avg. loss: 974.755917\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 889.59, NNZs: 44, Bias: -1125.607573, T: 38400, Avg. loss: 903.230092\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 887.86, NNZs: 44, Bias: -1129.644132, T: 39040, Avg. loss: 840.587006\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 886.24, NNZs: 44, Bias: -1133.610148, T: 39680, Avg. loss: 744.851484\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 886.11, NNZs: 44, Bias: -1137.760367, T: 40320, Avg. loss: 794.789842\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 886.62, NNZs: 44, Bias: -1141.358172, T: 40960, Avg. loss: 911.947559\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 887.62, NNZs: 44, Bias: -1145.615043, T: 41600, Avg. loss: 714.642955\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 882.87, NNZs: 44, Bias: -1148.872796, T: 42240, Avg. loss: 762.570822\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 875.14, NNZs: 44, Bias: -1153.008843, T: 42880, Avg. loss: 726.207850\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 877.37, NNZs: 44, Bias: -1156.471768, T: 43520, Avg. loss: 775.719993\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 876.79, NNZs: 44, Bias: -1159.595838, T: 44160, Avg. loss: 707.479024\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 874.91, NNZs: 44, Bias: -1163.553259, T: 44800, Avg. loss: 777.630009\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 870.75, NNZs: 44, Bias: -1166.591431, T: 45440, Avg. loss: 757.268589\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 866.30, NNZs: 44, Bias: -1169.798316, T: 46080, Avg. loss: 758.242938\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 865.10, NNZs: 44, Bias: -1173.174130, T: 46720, Avg. loss: 703.222684\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 865.32, NNZs: 44, Bias: -1176.917043, T: 47360, Avg. loss: 734.025923\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 858.54, NNZs: 44, Bias: -1179.793455, T: 48000, Avg. loss: 695.823355\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 862.10, NNZs: 44, Bias: -1182.836877, T: 48640, Avg. loss: 591.220628\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 857.91, NNZs: 44, Bias: -1185.440426, T: 49280, Avg. loss: 783.068207\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 859.97, NNZs: 44, Bias: -1188.601682, T: 49920, Avg. loss: 626.584526\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 857.29, NNZs: 44, Bias: -1191.921791, T: 50560, Avg. loss: 623.839323\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 856.27, NNZs: 44, Bias: -1194.621243, T: 51200, Avg. loss: 646.226516\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 851.58, NNZs: 44, Bias: -1197.477257, T: 51840, Avg. loss: 640.572277\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 81 epochs took 0.05 seconds\n",
      "--- training time 0.05045914649963379 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000268, T: 640, Avg. loss: 0.365764\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000371, T: 1280, Avg. loss: 0.356616\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000440, T: 1920, Avg. loss: 0.351156\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000512, T: 2560, Avg. loss: 0.349170\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000571, T: 3200, Avg. loss: 0.344668\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000626, T: 3840, Avg. loss: 0.344730\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000670, T: 4480, Avg. loss: 0.341486\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000723, T: 5120, Avg. loss: 0.340767\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000765, T: 5760, Avg. loss: 0.340707\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000802, T: 6400, Avg. loss: 0.339845\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000839, T: 7040, Avg. loss: 0.338683\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000873, T: 7680, Avg. loss: 0.337827\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000916, T: 8320, Avg. loss: 0.336225\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000941, T: 8960, Avg. loss: 0.336617\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000975, T: 9600, Avg. loss: 0.336643\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001005, T: 10240, Avg. loss: 0.336029\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001040, T: 10880, Avg. loss: 0.334355\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001068, T: 11520, Avg. loss: 0.335234\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001097, T: 12160, Avg. loss: 0.334441\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001120, T: 12800, Avg. loss: 0.334514\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001147, T: 13440, Avg. loss: 0.334017\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001171, T: 14080, Avg. loss: 0.333580\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 22 epochs took 0.01 seconds\n",
      "--- training time 0.017143964767456055 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000268, T: 640, Avg. loss: 0.365764\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000371, T: 1280, Avg. loss: 0.356616\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000440, T: 1920, Avg. loss: 0.351156\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000512, T: 2560, Avg. loss: 0.349170\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000571, T: 3200, Avg. loss: 0.344668\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000626, T: 3840, Avg. loss: 0.344730\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000670, T: 4480, Avg. loss: 0.341486\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000723, T: 5120, Avg. loss: 0.340767\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000765, T: 5760, Avg. loss: 0.340707\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000802, T: 6400, Avg. loss: 0.339845\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000839, T: 7040, Avg. loss: 0.338683\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000873, T: 7680, Avg. loss: 0.337827\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000916, T: 8320, Avg. loss: 0.336225\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000941, T: 8960, Avg. loss: 0.336617\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000975, T: 9600, Avg. loss: 0.336643\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001005, T: 10240, Avg. loss: 0.336029\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001040, T: 10880, Avg. loss: 0.334355\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001068, T: 11520, Avg. loss: 0.335234\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001097, T: 12160, Avg. loss: 0.334441\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001120, T: 12800, Avg. loss: 0.334514\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001147, T: 13440, Avg. loss: 0.334017\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001171, T: 14080, Avg. loss: 0.333580\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 22 epochs took 0.01 seconds\n",
      "--- training time 0.013614892959594727 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000268, T: 640, Avg. loss: 0.365764\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000371, T: 1280, Avg. loss: 0.356616\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000440, T: 1920, Avg. loss: 0.351156\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000512, T: 2560, Avg. loss: 0.349170\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000571, T: 3200, Avg. loss: 0.344668\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000626, T: 3840, Avg. loss: 0.344730\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000670, T: 4480, Avg. loss: 0.341486\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000723, T: 5120, Avg. loss: 0.340767\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000765, T: 5760, Avg. loss: 0.340707\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000802, T: 6400, Avg. loss: 0.339845\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000839, T: 7040, Avg. loss: 0.338683\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000873, T: 7680, Avg. loss: 0.337827\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000916, T: 8320, Avg. loss: 0.336225\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000941, T: 8960, Avg. loss: 0.336617\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000975, T: 9600, Avg. loss: 0.336643\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001005, T: 10240, Avg. loss: 0.336029\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001040, T: 10880, Avg. loss: 0.334355\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001068, T: 11520, Avg. loss: 0.335234\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001097, T: 12160, Avg. loss: 0.334441\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001120, T: 12800, Avg. loss: 0.334514\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001147, T: 13440, Avg. loss: 0.334017\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001171, T: 14080, Avg. loss: 0.333580\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 22 epochs took 0.01 seconds\n",
      "--- training time 0.011871337890625 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.002804, T: 640, Avg. loss: 0.530745\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.004999, T: 1280, Avg. loss: 0.473073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.007353, T: 1920, Avg. loss: 0.477698\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.009563, T: 2560, Avg. loss: 0.526879\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.012097, T: 3200, Avg. loss: 0.492399\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.014273, T: 3840, Avg. loss: 0.483501\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.016534, T: 4480, Avg. loss: 0.501115\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.016942, T: 5120, Avg. loss: 0.367130\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.017476, T: 5760, Avg. loss: 0.352643\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.017962, T: 6400, Avg. loss: 0.350942\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.018492, T: 7040, Avg. loss: 0.344682\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.018956, T: 7680, Avg. loss: 0.348603\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.019531, T: 8320, Avg. loss: 0.343703\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.019971, T: 8960, Avg. loss: 0.350367\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.020559, T: 9600, Avg. loss: 0.348111\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021010, T: 10240, Avg. loss: 0.348495\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021158, T: 10880, Avg. loss: 0.317506\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021251, T: 11520, Avg. loss: 0.324189\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021362, T: 12160, Avg. loss: 0.320888\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021453, T: 12800, Avg. loss: 0.324178\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021557, T: 13440, Avg. loss: 0.322479\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021656, T: 14080, Avg. loss: 0.321282\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021682, T: 14720, Avg. loss: 0.318814\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021707, T: 15360, Avg. loss: 0.317611\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021731, T: 16000, Avg. loss: 0.317027\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021748, T: 16640, Avg. loss: 0.318004\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021771, T: 17280, Avg. loss: 0.317610\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 27 epochs took 0.02 seconds\n",
      "--- training time 0.01807093620300293 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.002804, T: 640, Avg. loss: 0.530745\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.004999, T: 1280, Avg. loss: 0.473073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.007353, T: 1920, Avg. loss: 0.477698\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.009563, T: 2560, Avg. loss: 0.526879\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.012097, T: 3200, Avg. loss: 0.492399\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.014273, T: 3840, Avg. loss: 0.483501\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.016534, T: 4480, Avg. loss: 0.501115\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.016942, T: 5120, Avg. loss: 0.367130\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.017476, T: 5760, Avg. loss: 0.352643\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.017962, T: 6400, Avg. loss: 0.350942\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.018492, T: 7040, Avg. loss: 0.344682\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.018956, T: 7680, Avg. loss: 0.348603\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.019531, T: 8320, Avg. loss: 0.343703\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.019971, T: 8960, Avg. loss: 0.350367\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.020559, T: 9600, Avg. loss: 0.348111\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021010, T: 10240, Avg. loss: 0.348495\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021158, T: 10880, Avg. loss: 0.317506\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021251, T: 11520, Avg. loss: 0.324189\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021362, T: 12160, Avg. loss: 0.320888\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021453, T: 12800, Avg. loss: 0.324178\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021557, T: 13440, Avg. loss: 0.322479\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021656, T: 14080, Avg. loss: 0.321282\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021682, T: 14720, Avg. loss: 0.318814\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021707, T: 15360, Avg. loss: 0.317611\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021731, T: 16000, Avg. loss: 0.317027\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021748, T: 16640, Avg. loss: 0.318004\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021771, T: 17280, Avg. loss: 0.317610\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 27 epochs took 0.01 seconds\n",
      "--- training time 0.016409873962402344 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.002804, T: 640, Avg. loss: 0.530745\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.004999, T: 1280, Avg. loss: 0.473073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.007353, T: 1920, Avg. loss: 0.477698\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.009563, T: 2560, Avg. loss: 0.526879\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.012097, T: 3200, Avg. loss: 0.492399\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.014273, T: 3840, Avg. loss: 0.483501\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.016534, T: 4480, Avg. loss: 0.501115\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.016942, T: 5120, Avg. loss: 0.367130\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.017476, T: 5760, Avg. loss: 0.352643\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.017962, T: 6400, Avg. loss: 0.350942\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.018492, T: 7040, Avg. loss: 0.344682\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.018956, T: 7680, Avg. loss: 0.348603\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.019531, T: 8320, Avg. loss: 0.343703\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.019971, T: 8960, Avg. loss: 0.350367\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.020559, T: 9600, Avg. loss: 0.348111\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021010, T: 10240, Avg. loss: 0.348495\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021158, T: 10880, Avg. loss: 0.317506\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021251, T: 11520, Avg. loss: 0.324189\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021362, T: 12160, Avg. loss: 0.320888\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021453, T: 12800, Avg. loss: 0.324178\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021557, T: 13440, Avg. loss: 0.322479\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021656, T: 14080, Avg. loss: 0.321282\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021682, T: 14720, Avg. loss: 0.318814\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021707, T: 15360, Avg. loss: 0.317611\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021731, T: 16000, Avg. loss: 0.317027\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021748, T: 16640, Avg. loss: 0.318004\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021771, T: 17280, Avg. loss: 0.317610\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 27 epochs took 0.03 seconds\n",
      "--- training time 0.032032012939453125 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.021067, T: 640, Avg. loss: 3.984145\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.48, NNZs: 44, Bias: -0.040317, T: 1280, Avg. loss: 3.222851\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.059537, T: 1920, Avg. loss: 3.644051\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.50, NNZs: 44, Bias: -0.078804, T: 2560, Avg. loss: 4.137911\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.45, NNZs: 44, Bias: -0.098773, T: 3200, Avg. loss: 3.813206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.74, NNZs: 44, Bias: -0.116994, T: 3840, Avg. loss: 3.862541\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.70, NNZs: 44, Bias: -0.135162, T: 4480, Avg. loss: 3.740942\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.008265972137451172 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.021067, T: 640, Avg. loss: 3.984145\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.48, NNZs: 44, Bias: -0.040317, T: 1280, Avg. loss: 3.222851\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.059537, T: 1920, Avg. loss: 3.644051\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.50, NNZs: 44, Bias: -0.078804, T: 2560, Avg. loss: 4.137911\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.45, NNZs: 44, Bias: -0.098773, T: 3200, Avg. loss: 3.813206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.74, NNZs: 44, Bias: -0.116994, T: 3840, Avg. loss: 3.862541\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.70, NNZs: 44, Bias: -0.135162, T: 4480, Avg. loss: 3.740942\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.008150100708007812 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.021067, T: 640, Avg. loss: 3.984145\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.48, NNZs: 44, Bias: -0.040317, T: 1280, Avg. loss: 3.222851\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.059537, T: 1920, Avg. loss: 3.644051\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.50, NNZs: 44, Bias: -0.078804, T: 2560, Avg. loss: 4.137911\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.45, NNZs: 44, Bias: -0.098773, T: 3200, Avg. loss: 3.813206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.74, NNZs: 44, Bias: -0.116994, T: 3840, Avg. loss: 3.862541\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.70, NNZs: 44, Bias: -0.135162, T: 4480, Avg. loss: 3.740942\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.0074999332427978516 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 500.74, NNZs: 40, Bias: -52.512065, T: 640, Avg. loss: 8966.903966\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 320.78, NNZs: 43, Bias: -72.608925, T: 1280, Avg. loss: 3357.209314\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 230.09, NNZs: 43, Bias: -84.340473, T: 1920, Avg. loss: 2166.524856\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 189.36, NNZs: 43, Bias: -92.661941, T: 2560, Avg. loss: 1764.310331\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 168.40, NNZs: 44, Bias: -99.779847, T: 3200, Avg. loss: 1306.004672\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 202.15, NNZs: 44, Bias: -104.232835, T: 3840, Avg. loss: 995.721480\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 137.92, NNZs: 44, Bias: -108.116835, T: 4480, Avg. loss: 926.979040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 151.23, NNZs: 44, Bias: -112.749757, T: 5120, Avg. loss: 746.909156\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 148.27, NNZs: 44, Bias: -116.665804, T: 5760, Avg. loss: 699.113288\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 153.32, NNZs: 44, Bias: -119.708379, T: 6400, Avg. loss: 599.858419\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 133.29, NNZs: 44, Bias: -122.480550, T: 7040, Avg. loss: 555.386621\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 126.49, NNZs: 44, Bias: -124.739493, T: 7680, Avg. loss: 528.065646\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 117.66, NNZs: 44, Bias: -127.544830, T: 8320, Avg. loss: 475.009744\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 109.57, NNZs: 44, Bias: -129.587971, T: 8960, Avg. loss: 491.862829\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 106.81, NNZs: 44, Bias: -131.703656, T: 9600, Avg. loss: 446.339582\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 112.49, NNZs: 44, Bias: -133.685142, T: 10240, Avg. loss: 363.660773\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 115.80, NNZs: 44, Bias: -135.462435, T: 10880, Avg. loss: 317.797125\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 114.90, NNZs: 44, Bias: -137.127378, T: 11520, Avg. loss: 313.789935\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 105.54, NNZs: 44, Bias: -138.791050, T: 12160, Avg. loss: 348.313547\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 104.84, NNZs: 44, Bias: -140.210565, T: 12800, Avg. loss: 334.727113\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 107.89, NNZs: 44, Bias: -141.560703, T: 13440, Avg. loss: 298.511347\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 100.53, NNZs: 44, Bias: -142.568970, T: 14080, Avg. loss: 257.251948\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 104.61, NNZs: 44, Bias: -143.586413, T: 14720, Avg. loss: 250.219567\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 105.06, NNZs: 44, Bias: -144.970692, T: 15360, Avg. loss: 247.542619\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 100.92, NNZs: 44, Bias: -146.237201, T: 16000, Avg. loss: 248.501058\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 100.15, NNZs: 44, Bias: -147.451414, T: 16640, Avg. loss: 225.751338\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 103.35, NNZs: 44, Bias: -148.561394, T: 17280, Avg. loss: 212.981286\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 100.88, NNZs: 44, Bias: -149.463165, T: 17920, Avg. loss: 191.596918\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 101.96, NNZs: 44, Bias: -150.548571, T: 18560, Avg. loss: 189.725798\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 103.52, NNZs: 44, Bias: -151.611007, T: 19200, Avg. loss: 183.233201\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 102.28, NNZs: 44, Bias: -152.380246, T: 19840, Avg. loss: 201.349287\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 101.43, NNZs: 44, Bias: -153.315040, T: 20480, Avg. loss: 194.863840\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 98.98, NNZs: 44, Bias: -153.983702, T: 21120, Avg. loss: 169.953737\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 98.06, NNZs: 44, Bias: -154.831632, T: 21760, Avg. loss: 173.155293\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 99.43, NNZs: 44, Bias: -155.729074, T: 22400, Avg. loss: 155.416821\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 100.79, NNZs: 44, Bias: -156.597047, T: 23040, Avg. loss: 153.429602\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 97.84, NNZs: 44, Bias: -157.191383, T: 23680, Avg. loss: 159.924902\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 97.13, NNZs: 44, Bias: -157.891737, T: 24320, Avg. loss: 148.308670\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 97.03, NNZs: 44, Bias: -158.613327, T: 24960, Avg. loss: 133.659802\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 96.85, NNZs: 44, Bias: -159.227607, T: 25600, Avg. loss: 145.577644\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 95.71, NNZs: 44, Bias: -159.751561, T: 26240, Avg. loss: 132.080117\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 95.59, NNZs: 44, Bias: -160.375331, T: 26880, Avg. loss: 117.890443\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 96.42, NNZs: 44, Bias: -160.953157, T: 27520, Avg. loss: 134.577507\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 95.09, NNZs: 44, Bias: -161.520962, T: 28160, Avg. loss: 136.019925\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 94.90, NNZs: 44, Bias: -162.150253, T: 28800, Avg. loss: 127.672971\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 94.33, NNZs: 44, Bias: -162.662278, T: 29440, Avg. loss: 127.475931\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 95.54, NNZs: 44, Bias: -163.365363, T: 30080, Avg. loss: 123.089532\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 47 epochs took 0.02 seconds\n",
      "--- training time 0.023511171340942383 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 500.74, NNZs: 40, Bias: -52.512065, T: 640, Avg. loss: 8966.903966\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 320.78, NNZs: 43, Bias: -72.608925, T: 1280, Avg. loss: 3357.209314\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 230.09, NNZs: 43, Bias: -84.340473, T: 1920, Avg. loss: 2166.524856\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 189.36, NNZs: 43, Bias: -92.661941, T: 2560, Avg. loss: 1764.310331\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 168.40, NNZs: 44, Bias: -99.779847, T: 3200, Avg. loss: 1306.004672\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 202.15, NNZs: 44, Bias: -104.232835, T: 3840, Avg. loss: 995.721480\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 137.92, NNZs: 44, Bias: -108.116835, T: 4480, Avg. loss: 926.979040\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 151.23, NNZs: 44, Bias: -112.749757, T: 5120, Avg. loss: 746.909156\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 148.27, NNZs: 44, Bias: -116.665804, T: 5760, Avg. loss: 699.113288\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 153.32, NNZs: 44, Bias: -119.708379, T: 6400, Avg. loss: 599.858419\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 133.29, NNZs: 44, Bias: -122.480550, T: 7040, Avg. loss: 555.386621\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 126.49, NNZs: 44, Bias: -124.739493, T: 7680, Avg. loss: 528.065646\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 117.66, NNZs: 44, Bias: -127.544830, T: 8320, Avg. loss: 475.009744\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 109.57, NNZs: 44, Bias: -129.587971, T: 8960, Avg. loss: 491.862829\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 106.81, NNZs: 44, Bias: -131.703656, T: 9600, Avg. loss: 446.339582\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 112.49, NNZs: 44, Bias: -133.685142, T: 10240, Avg. loss: 363.660773\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 115.80, NNZs: 44, Bias: -135.462435, T: 10880, Avg. loss: 317.797125\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 114.90, NNZs: 44, Bias: -137.127378, T: 11520, Avg. loss: 313.789935\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 105.54, NNZs: 44, Bias: -138.791050, T: 12160, Avg. loss: 348.313547\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 104.84, NNZs: 44, Bias: -140.210565, T: 12800, Avg. loss: 334.727113\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 107.89, NNZs: 44, Bias: -141.560703, T: 13440, Avg. loss: 298.511347\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 100.53, NNZs: 44, Bias: -142.568970, T: 14080, Avg. loss: 257.251948\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 104.61, NNZs: 44, Bias: -143.586413, T: 14720, Avg. loss: 250.219567\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 105.06, NNZs: 44, Bias: -144.970692, T: 15360, Avg. loss: 247.542619\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 100.92, NNZs: 44, Bias: -146.237201, T: 16000, Avg. loss: 248.501058\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 100.15, NNZs: 44, Bias: -147.451414, T: 16640, Avg. loss: 225.751338\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 103.35, NNZs: 44, Bias: -148.561394, T: 17280, Avg. loss: 212.981286\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 100.88, NNZs: 44, Bias: -149.463165, T: 17920, Avg. loss: 191.596918\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 101.96, NNZs: 44, Bias: -150.548571, T: 18560, Avg. loss: 189.725798\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 103.52, NNZs: 44, Bias: -151.611007, T: 19200, Avg. loss: 183.233201\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 102.28, NNZs: 44, Bias: -152.380246, T: 19840, Avg. loss: 201.349287\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 101.43, NNZs: 44, Bias: -153.315040, T: 20480, Avg. loss: 194.863840\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 98.98, NNZs: 44, Bias: -153.983702, T: 21120, Avg. loss: 169.953737\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 98.06, NNZs: 44, Bias: -154.831632, T: 21760, Avg. loss: 173.155293\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 99.43, NNZs: 44, Bias: -155.729074, T: 22400, Avg. loss: 155.416821\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 100.79, NNZs: 44, Bias: -156.597047, T: 23040, Avg. loss: 153.429602\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 97.84, NNZs: 44, Bias: -157.191383, T: 23680, Avg. loss: 159.924902\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 97.13, NNZs: 44, Bias: -157.891737, T: 24320, Avg. loss: 148.308670\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 97.03, NNZs: 44, Bias: -158.613327, T: 24960, Avg. loss: 133.659802\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 96.85, NNZs: 44, Bias: -159.227607, T: 25600, Avg. loss: 145.577644\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 95.71, NNZs: 44, Bias: -159.751561, T: 26240, Avg. loss: 132.080117\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 95.59, NNZs: 44, Bias: -160.375331, T: 26880, Avg. loss: 117.890443\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 96.42, NNZs: 44, Bias: -160.953157, T: 27520, Avg. loss: 134.577507\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 95.09, NNZs: 44, Bias: -161.520962, T: 28160, Avg. loss: 136.019925\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 94.90, NNZs: 44, Bias: -162.150253, T: 28800, Avg. loss: 127.672971\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 94.33, NNZs: 44, Bias: -162.662278, T: 29440, Avg. loss: 127.475931\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 95.54, NNZs: 44, Bias: -163.365363, T: 30080, Avg. loss: 123.089532\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 47 epochs took 0.02 seconds\n",
      "--- training time 0.028397083282470703 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 500.74, NNZs: 40, Bias: -52.512065, T: 640, Avg. loss: 8966.903966\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 320.78, NNZs: 43, Bias: -72.608925, T: 1280, Avg. loss: 3357.209314\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 230.09, NNZs: 43, Bias: -84.340473, T: 1920, Avg. loss: 2166.524856\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 189.36, NNZs: 43, Bias: -92.661941, T: 2560, Avg. loss: 1764.310331\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 168.40, NNZs: 44, Bias: -99.779847, T: 3200, Avg. loss: 1306.004672\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 202.15, NNZs: 44, Bias: -104.232835, T: 3840, Avg. loss: 995.721480\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 137.92, NNZs: 44, Bias: -108.116835, T: 4480, Avg. loss: 926.979040\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 151.23, NNZs: 44, Bias: -112.749757, T: 5120, Avg. loss: 746.909156\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 148.27, NNZs: 44, Bias: -116.665804, T: 5760, Avg. loss: 699.113288\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 153.32, NNZs: 44, Bias: -119.708379, T: 6400, Avg. loss: 599.858419\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 133.29, NNZs: 44, Bias: -122.480550, T: 7040, Avg. loss: 555.386621\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 126.49, NNZs: 44, Bias: -124.739493, T: 7680, Avg. loss: 528.065646\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 117.66, NNZs: 44, Bias: -127.544830, T: 8320, Avg. loss: 475.009744\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 109.57, NNZs: 44, Bias: -129.587971, T: 8960, Avg. loss: 491.862829\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 106.81, NNZs: 44, Bias: -131.703656, T: 9600, Avg. loss: 446.339582\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 112.49, NNZs: 44, Bias: -133.685142, T: 10240, Avg. loss: 363.660773\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 115.80, NNZs: 44, Bias: -135.462435, T: 10880, Avg. loss: 317.797125\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 114.90, NNZs: 44, Bias: -137.127378, T: 11520, Avg. loss: 313.789935\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 105.54, NNZs: 44, Bias: -138.791050, T: 12160, Avg. loss: 348.313547\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 104.84, NNZs: 44, Bias: -140.210565, T: 12800, Avg. loss: 334.727113\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 107.89, NNZs: 44, Bias: -141.560703, T: 13440, Avg. loss: 298.511347\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 100.53, NNZs: 44, Bias: -142.568970, T: 14080, Avg. loss: 257.251948\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 104.61, NNZs: 44, Bias: -143.586413, T: 14720, Avg. loss: 250.219567\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 105.06, NNZs: 44, Bias: -144.970692, T: 15360, Avg. loss: 247.542619\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 100.92, NNZs: 44, Bias: -146.237201, T: 16000, Avg. loss: 248.501058\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 100.15, NNZs: 44, Bias: -147.451414, T: 16640, Avg. loss: 225.751338\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 103.35, NNZs: 44, Bias: -148.561394, T: 17280, Avg. loss: 212.981286\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 100.88, NNZs: 44, Bias: -149.463165, T: 17920, Avg. loss: 191.596918\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 101.96, NNZs: 44, Bias: -150.548571, T: 18560, Avg. loss: 189.725798\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 103.52, NNZs: 44, Bias: -151.611007, T: 19200, Avg. loss: 183.233201\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 102.28, NNZs: 44, Bias: -152.380246, T: 19840, Avg. loss: 201.349287\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 101.43, NNZs: 44, Bias: -153.315040, T: 20480, Avg. loss: 194.863840\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 98.98, NNZs: 44, Bias: -153.983702, T: 21120, Avg. loss: 169.953737\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 98.06, NNZs: 44, Bias: -154.831632, T: 21760, Avg. loss: 173.155293\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 99.43, NNZs: 44, Bias: -155.729074, T: 22400, Avg. loss: 155.416821\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 100.79, NNZs: 44, Bias: -156.597047, T: 23040, Avg. loss: 153.429602\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 97.84, NNZs: 44, Bias: -157.191383, T: 23680, Avg. loss: 159.924902\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 97.13, NNZs: 44, Bias: -157.891737, T: 24320, Avg. loss: 148.308670\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 97.03, NNZs: 44, Bias: -158.613327, T: 24960, Avg. loss: 133.659802\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 96.85, NNZs: 44, Bias: -159.227607, T: 25600, Avg. loss: 145.577644\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 95.71, NNZs: 44, Bias: -159.751561, T: 26240, Avg. loss: 132.080117\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 95.59, NNZs: 44, Bias: -160.375331, T: 26880, Avg. loss: 117.890443\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 96.42, NNZs: 44, Bias: -160.953157, T: 27520, Avg. loss: 134.577507\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 95.09, NNZs: 44, Bias: -161.520962, T: 28160, Avg. loss: 136.019925\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 94.90, NNZs: 44, Bias: -162.150253, T: 28800, Avg. loss: 127.672971\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 94.33, NNZs: 44, Bias: -162.662278, T: 29440, Avg. loss: 127.475931\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 95.54, NNZs: 44, Bias: -163.365363, T: 30080, Avg. loss: 123.089532\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 47 epochs took 0.03 seconds\n",
      "--- training time 0.03471112251281738 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.04, NNZs: 44, Bias: -0.001716, T: 640, Avg. loss: 0.494289\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.04, NNZs: 44, Bias: -0.002572, T: 1280, Avg. loss: 0.364677\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.003237, T: 1920, Avg. loss: 0.349521\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.003750, T: 2560, Avg. loss: 0.365191\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.004277, T: 3200, Avg. loss: 0.343723\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.004730, T: 3840, Avg. loss: 0.350922\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005132, T: 4480, Avg. loss: 0.338571\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005522, T: 5120, Avg. loss: 0.343426\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005915, T: 5760, Avg. loss: 0.344485\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006246, T: 6400, Avg. loss: 0.344850\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006582, T: 7040, Avg. loss: 0.339307\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006865, T: 7680, Avg. loss: 0.340507\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 12 epochs took 0.01 seconds\n",
      "--- training time 0.009697914123535156 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.04, NNZs: 44, Bias: -0.001716, T: 640, Avg. loss: 0.494289\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.04, NNZs: 44, Bias: -0.002572, T: 1280, Avg. loss: 0.364677\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.003237, T: 1920, Avg. loss: 0.349521\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.003750, T: 2560, Avg. loss: 0.365191\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.004277, T: 3200, Avg. loss: 0.343723\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.004730, T: 3840, Avg. loss: 0.350922\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005132, T: 4480, Avg. loss: 0.338571\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005522, T: 5120, Avg. loss: 0.343426\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005915, T: 5760, Avg. loss: 0.344485\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006246, T: 6400, Avg. loss: 0.344850\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006582, T: 7040, Avg. loss: 0.339307\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006865, T: 7680, Avg. loss: 0.340507\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 12 epochs took 0.01 seconds\n",
      "--- training time 0.01087498664855957 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.04, NNZs: 44, Bias: -0.001716, T: 640, Avg. loss: 0.494289\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.04, NNZs: 44, Bias: -0.002572, T: 1280, Avg. loss: 0.364677\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.003237, T: 1920, Avg. loss: 0.349521\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.003750, T: 2560, Avg. loss: 0.365191\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.004277, T: 3200, Avg. loss: 0.343723\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.004730, T: 3840, Avg. loss: 0.350922\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005132, T: 4480, Avg. loss: 0.338571\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005522, T: 5120, Avg. loss: 0.343426\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005915, T: 5760, Avg. loss: 0.344485\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006246, T: 6400, Avg. loss: 0.344850\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006582, T: 7040, Avg. loss: 0.339307\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006865, T: 7680, Avg. loss: 0.340507\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 12 epochs took 0.01 seconds\n",
      "--- training time 0.010627031326293945 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.021067, T: 640, Avg. loss: 3.984145\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.48, NNZs: 44, Bias: -0.040317, T: 1280, Avg. loss: 3.222851\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.059537, T: 1920, Avg. loss: 3.644051\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.50, NNZs: 44, Bias: -0.078804, T: 2560, Avg. loss: 4.137911\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.45, NNZs: 44, Bias: -0.098773, T: 3200, Avg. loss: 3.813206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.74, NNZs: 44, Bias: -0.116994, T: 3840, Avg. loss: 3.862541\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.70, NNZs: 44, Bias: -0.135162, T: 4480, Avg. loss: 3.740942\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.138026, T: 5120, Avg. loss: 1.398175\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.51, NNZs: 44, Bias: -0.141678, T: 5760, Avg. loss: 0.953206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.52, NNZs: 44, Bias: -0.145249, T: 6400, Avg. loss: 0.784679\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.52, NNZs: 44, Bias: -0.149089, T: 7040, Avg. loss: 0.727688\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.53, NNZs: 44, Bias: -0.152845, T: 7680, Avg. loss: 0.727317\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.54, NNZs: 44, Bias: -0.156963, T: 8320, Avg. loss: 0.685719\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.55, NNZs: 44, Bias: -0.160600, T: 8960, Avg. loss: 0.805217\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.165141, T: 9600, Avg. loss: 0.780246\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.57, NNZs: 44, Bias: -0.168779, T: 10240, Avg. loss: 0.745140\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.59, NNZs: 44, Bias: -0.173353, T: 10880, Avg. loss: 0.668678\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.60, NNZs: 44, Bias: -0.177487, T: 11520, Avg. loss: 0.741204\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.61, NNZs: 44, Bias: -0.181503, T: 12160, Avg. loss: 0.770187\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.62, NNZs: 44, Bias: -0.185364, T: 12800, Avg. loss: 0.800654\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.63, NNZs: 44, Bias: -0.189288, T: 13440, Avg. loss: 0.788337\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.193096, T: 14080, Avg. loss: 0.677807\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.193678, T: 14720, Avg. loss: 0.353993\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.194425, T: 15360, Avg. loss: 0.313918\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.195239, T: 16000, Avg. loss: 0.305386\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.195940, T: 16640, Avg. loss: 0.306292\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.196674, T: 17280, Avg. loss: 0.298847\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.197423, T: 17920, Avg. loss: 0.304501\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.198198, T: 18560, Avg. loss: 0.304672\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.199014, T: 19200, Avg. loss: 0.298193\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.199779, T: 19840, Avg. loss: 0.313134\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200556, T: 20480, Avg. loss: 0.311360\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200677, T: 21120, Avg. loss: 0.266225\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200840, T: 21760, Avg. loss: 0.258514\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200990, T: 22400, Avg. loss: 0.262786\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.201148, T: 23040, Avg. loss: 0.263645\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.201312, T: 23680, Avg. loss: 0.266481\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201486, T: 24320, Avg. loss: 0.261895\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201651, T: 24960, Avg. loss: 0.259777\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201667, T: 25600, Avg. loss: 0.260109\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201695, T: 26240, Avg. loss: 0.254555\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201730, T: 26880, Avg. loss: 0.254708\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201758, T: 27520, Avg. loss: 0.254875\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201796, T: 28160, Avg. loss: 0.254540\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201830, T: 28800, Avg. loss: 0.254008\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201855, T: 29440, Avg. loss: 0.255364\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201862, T: 30080, Avg. loss: 0.252925\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201869, T: 30720, Avg. loss: 0.252909\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201875, T: 31360, Avg. loss: 0.252805\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201882, T: 32000, Avg. loss: 0.252968\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201888, T: 32640, Avg. loss: 0.252887\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201895, T: 33280, Avg. loss: 0.252886\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 52 epochs took 0.02 seconds\n",
      "--- training time 0.02795696258544922 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.021067, T: 640, Avg. loss: 3.984145\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.48, NNZs: 44, Bias: -0.040317, T: 1280, Avg. loss: 3.222851\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.059537, T: 1920, Avg. loss: 3.644051\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.50, NNZs: 44, Bias: -0.078804, T: 2560, Avg. loss: 4.137911\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.45, NNZs: 44, Bias: -0.098773, T: 3200, Avg. loss: 3.813206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.74, NNZs: 44, Bias: -0.116994, T: 3840, Avg. loss: 3.862541\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.70, NNZs: 44, Bias: -0.135162, T: 4480, Avg. loss: 3.740942\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.138026, T: 5120, Avg. loss: 1.398175\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.51, NNZs: 44, Bias: -0.141678, T: 5760, Avg. loss: 0.953206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.52, NNZs: 44, Bias: -0.145249, T: 6400, Avg. loss: 0.784679\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.52, NNZs: 44, Bias: -0.149089, T: 7040, Avg. loss: 0.727688\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.53, NNZs: 44, Bias: -0.152845, T: 7680, Avg. loss: 0.727317\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.54, NNZs: 44, Bias: -0.156963, T: 8320, Avg. loss: 0.685719\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.55, NNZs: 44, Bias: -0.160600, T: 8960, Avg. loss: 0.805217\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.165141, T: 9600, Avg. loss: 0.780246\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.57, NNZs: 44, Bias: -0.168779, T: 10240, Avg. loss: 0.745140\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.59, NNZs: 44, Bias: -0.173353, T: 10880, Avg. loss: 0.668678\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.60, NNZs: 44, Bias: -0.177487, T: 11520, Avg. loss: 0.741204\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.61, NNZs: 44, Bias: -0.181503, T: 12160, Avg. loss: 0.770187\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.62, NNZs: 44, Bias: -0.185364, T: 12800, Avg. loss: 0.800654\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.63, NNZs: 44, Bias: -0.189288, T: 13440, Avg. loss: 0.788337\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.193096, T: 14080, Avg. loss: 0.677807\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.193678, T: 14720, Avg. loss: 0.353993\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.194425, T: 15360, Avg. loss: 0.313918\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.195239, T: 16000, Avg. loss: 0.305386\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.195940, T: 16640, Avg. loss: 0.306292\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.196674, T: 17280, Avg. loss: 0.298847\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.197423, T: 17920, Avg. loss: 0.304501\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.198198, T: 18560, Avg. loss: 0.304672\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.199014, T: 19200, Avg. loss: 0.298193\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.199779, T: 19840, Avg. loss: 0.313134\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200556, T: 20480, Avg. loss: 0.311360\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200677, T: 21120, Avg. loss: 0.266225\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200840, T: 21760, Avg. loss: 0.258514\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200990, T: 22400, Avg. loss: 0.262786\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.201148, T: 23040, Avg. loss: 0.263645\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.201312, T: 23680, Avg. loss: 0.266481\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201486, T: 24320, Avg. loss: 0.261895\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201651, T: 24960, Avg. loss: 0.259777\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201667, T: 25600, Avg. loss: 0.260109\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201695, T: 26240, Avg. loss: 0.254555\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201730, T: 26880, Avg. loss: 0.254708\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201758, T: 27520, Avg. loss: 0.254875\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201796, T: 28160, Avg. loss: 0.254540\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201830, T: 28800, Avg. loss: 0.254008\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201855, T: 29440, Avg. loss: 0.255364\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201862, T: 30080, Avg. loss: 0.252925\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201869, T: 30720, Avg. loss: 0.252909\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201875, T: 31360, Avg. loss: 0.252805\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201882, T: 32000, Avg. loss: 0.252968\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201888, T: 32640, Avg. loss: 0.252887\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201895, T: 33280, Avg. loss: 0.252886\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 52 epochs took 0.03 seconds\n",
      "--- training time 0.03362321853637695 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.021067, T: 640, Avg. loss: 3.984145\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.48, NNZs: 44, Bias: -0.040317, T: 1280, Avg. loss: 3.222851\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.059537, T: 1920, Avg. loss: 3.644051\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.50, NNZs: 44, Bias: -0.078804, T: 2560, Avg. loss: 4.137911\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.45, NNZs: 44, Bias: -0.098773, T: 3200, Avg. loss: 3.813206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.74, NNZs: 44, Bias: -0.116994, T: 3840, Avg. loss: 3.862541\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.70, NNZs: 44, Bias: -0.135162, T: 4480, Avg. loss: 3.740942\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.138026, T: 5120, Avg. loss: 1.398175\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.51, NNZs: 44, Bias: -0.141678, T: 5760, Avg. loss: 0.953206\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.52, NNZs: 44, Bias: -0.145249, T: 6400, Avg. loss: 0.784679\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.52, NNZs: 44, Bias: -0.149089, T: 7040, Avg. loss: 0.727688\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.53, NNZs: 44, Bias: -0.152845, T: 7680, Avg. loss: 0.727317\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.54, NNZs: 44, Bias: -0.156963, T: 8320, Avg. loss: 0.685719\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.55, NNZs: 44, Bias: -0.160600, T: 8960, Avg. loss: 0.805217\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.165141, T: 9600, Avg. loss: 0.780246\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.57, NNZs: 44, Bias: -0.168779, T: 10240, Avg. loss: 0.745140\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.59, NNZs: 44, Bias: -0.173353, T: 10880, Avg. loss: 0.668678\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.60, NNZs: 44, Bias: -0.177487, T: 11520, Avg. loss: 0.741204\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.61, NNZs: 44, Bias: -0.181503, T: 12160, Avg. loss: 0.770187\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.62, NNZs: 44, Bias: -0.185364, T: 12800, Avg. loss: 0.800654\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.63, NNZs: 44, Bias: -0.189288, T: 13440, Avg. loss: 0.788337\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.193096, T: 14080, Avg. loss: 0.677807\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.193678, T: 14720, Avg. loss: 0.353993\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.194425, T: 15360, Avg. loss: 0.313918\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.195239, T: 16000, Avg. loss: 0.305386\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.195940, T: 16640, Avg. loss: 0.306292\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.196674, T: 17280, Avg. loss: 0.298847\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.197423, T: 17920, Avg. loss: 0.304501\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.198198, T: 18560, Avg. loss: 0.304672\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.199014, T: 19200, Avg. loss: 0.298193\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.199779, T: 19840, Avg. loss: 0.313134\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200556, T: 20480, Avg. loss: 0.311360\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200677, T: 21120, Avg. loss: 0.266225\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200840, T: 21760, Avg. loss: 0.258514\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200990, T: 22400, Avg. loss: 0.262786\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.201148, T: 23040, Avg. loss: 0.263645\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.201312, T: 23680, Avg. loss: 0.266481\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201486, T: 24320, Avg. loss: 0.261895\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201651, T: 24960, Avg. loss: 0.259777\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201667, T: 25600, Avg. loss: 0.260109\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201695, T: 26240, Avg. loss: 0.254555\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201730, T: 26880, Avg. loss: 0.254708\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201758, T: 27520, Avg. loss: 0.254875\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201796, T: 28160, Avg. loss: 0.254540\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201830, T: 28800, Avg. loss: 0.254008\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201855, T: 29440, Avg. loss: 0.255364\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201862, T: 30080, Avg. loss: 0.252925\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201869, T: 30720, Avg. loss: 0.252909\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201875, T: 31360, Avg. loss: 0.252805\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201882, T: 32000, Avg. loss: 0.252968\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201888, T: 32640, Avg. loss: 0.252887\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201895, T: 33280, Avg. loss: 0.252886\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 52 epochs took 0.03 seconds\n",
      "--- training time 0.03286409378051758 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 3.92, NNZs: 44, Bias: -0.229017, T: 640, Avg. loss: 39.588520\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.22, NNZs: 44, Bias: -0.412678, T: 1280, Avg. loss: 36.358448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.77, NNZs: 44, Bias: -0.608724, T: 1920, Avg. loss: 37.326056\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.16, NNZs: 44, Bias: -0.820996, T: 2560, Avg. loss: 41.772040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.046754, T: 3200, Avg. loss: 40.525607\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.70, NNZs: 44, Bias: -1.233228, T: 3840, Avg. loss: 39.758304\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 6.79, NNZs: 44, Bias: -1.422213, T: 4480, Avg. loss: 39.742680\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 7 epochs took 0.01 seconds\n",
      "--- training time 0.010908842086791992 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 3.92, NNZs: 44, Bias: -0.229017, T: 640, Avg. loss: 39.588520\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.22, NNZs: 44, Bias: -0.412678, T: 1280, Avg. loss: 36.358448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.77, NNZs: 44, Bias: -0.608724, T: 1920, Avg. loss: 37.326056\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.16, NNZs: 44, Bias: -0.820996, T: 2560, Avg. loss: 41.772040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.046754, T: 3200, Avg. loss: 40.525607\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.70, NNZs: 44, Bias: -1.233228, T: 3840, Avg. loss: 39.758304\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 6.79, NNZs: 44, Bias: -1.422213, T: 4480, Avg. loss: 39.742680\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.00945591926574707 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 3.92, NNZs: 44, Bias: -0.229017, T: 640, Avg. loss: 39.588520\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.22, NNZs: 44, Bias: -0.412678, T: 1280, Avg. loss: 36.358448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.77, NNZs: 44, Bias: -0.608724, T: 1920, Avg. loss: 37.326056\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.16, NNZs: 44, Bias: -0.820996, T: 2560, Avg. loss: 41.772040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.046754, T: 3200, Avg. loss: 40.525607\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.70, NNZs: 44, Bias: -1.233228, T: 3840, Avg. loss: 39.758304\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 6.79, NNZs: 44, Bias: -1.422213, T: 4480, Avg. loss: 39.742680\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.0071599483489990234 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 60.99, NNZs: 42, Bias: -10.453885, T: 640, Avg. loss: 1552.509515\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 35.66, NNZs: 43, Bias: -12.783554, T: 1280, Avg. loss: 389.856725\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24.73, NNZs: 43, Bias: -14.062543, T: 1920, Avg. loss: 236.101649\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 20.01, NNZs: 44, Bias: -14.948544, T: 2560, Avg. loss: 187.732636\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 18.39, NNZs: 44, Bias: -15.671130, T: 3200, Avg. loss: 136.399263\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.70, NNZs: 44, Bias: -16.116936, T: 3840, Avg. loss: 111.364907\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 15.98, NNZs: 44, Bias: -16.589929, T: 4480, Avg. loss: 97.613050\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 14.31, NNZs: 44, Bias: -16.987956, T: 5120, Avg. loss: 74.871437\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 15.61, NNZs: 44, Bias: -17.388014, T: 5760, Avg. loss: 67.966306\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 13.92, NNZs: 44, Bias: -17.682240, T: 6400, Avg. loss: 61.636073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 11.86, NNZs: 44, Bias: -17.950590, T: 7040, Avg. loss: 55.904815\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 12.77, NNZs: 44, Bias: -18.208976, T: 7680, Avg. loss: 46.708359\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 11.33, NNZs: 44, Bias: -18.482606, T: 8320, Avg. loss: 45.033947\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 11.24, NNZs: 44, Bias: -18.677592, T: 8960, Avg. loss: 44.011195\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 11.42, NNZs: 44, Bias: -18.902786, T: 9600, Avg. loss: 43.701096\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 11.15, NNZs: 44, Bias: -19.059339, T: 10240, Avg. loss: 36.234746\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 11.28, NNZs: 44, Bias: -19.274144, T: 10880, Avg. loss: 33.412584\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 11.10, NNZs: 44, Bias: -19.442793, T: 11520, Avg. loss: 33.555258\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 10.71, NNZs: 44, Bias: -19.610984, T: 12160, Avg. loss: 34.817090\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 10.65, NNZs: 44, Bias: -19.756785, T: 12800, Avg. loss: 33.258951\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 11.12, NNZs: 44, Bias: -19.904638, T: 13440, Avg. loss: 30.816617\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 10.41, NNZs: 44, Bias: -20.032428, T: 14080, Avg. loss: 25.012433\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 10.57, NNZs: 44, Bias: -20.137965, T: 14720, Avg. loss: 28.452017\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 10.37, NNZs: 44, Bias: -20.251578, T: 15360, Avg. loss: 21.674290\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 10.47, NNZs: 44, Bias: -20.372988, T: 16000, Avg. loss: 22.736932\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 10.00, NNZs: 44, Bias: -20.472535, T: 16640, Avg. loss: 22.318439\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 10.02, NNZs: 44, Bias: -20.558950, T: 17280, Avg. loss: 20.445041\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 9.96, NNZs: 44, Bias: -20.664347, T: 17920, Avg. loss: 19.539886\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 9.83, NNZs: 44, Bias: -20.762185, T: 18560, Avg. loss: 19.285078\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 10.04, NNZs: 44, Bias: -20.861298, T: 19200, Avg. loss: 18.476698\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 10.05, NNZs: 44, Bias: -20.937798, T: 19840, Avg. loss: 19.100710\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 9.78, NNZs: 44, Bias: -21.031560, T: 20480, Avg. loss: 19.932161\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 9.73, NNZs: 44, Bias: -21.091787, T: 21120, Avg. loss: 16.569235\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 9.61, NNZs: 44, Bias: -21.180585, T: 21760, Avg. loss: 17.286220\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 9.71, NNZs: 44, Bias: -21.269395, T: 22400, Avg. loss: 16.595709\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 9.69, NNZs: 44, Bias: -21.341714, T: 23040, Avg. loss: 15.801840\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 9.62, NNZs: 44, Bias: -21.409972, T: 23680, Avg. loss: 15.241195\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 9.56, NNZs: 44, Bias: -21.492169, T: 24320, Avg. loss: 14.953152\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 9.59, NNZs: 44, Bias: -21.566195, T: 24960, Avg. loss: 13.076712\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 9.55, NNZs: 44, Bias: -21.629678, T: 25600, Avg. loss: 14.345237\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 9.57, NNZs: 44, Bias: -21.692393, T: 26240, Avg. loss: 13.411980\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 9.47, NNZs: 44, Bias: -21.744887, T: 26880, Avg. loss: 12.224874\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 9.46, NNZs: 44, Bias: -21.804454, T: 27520, Avg. loss: 12.965197\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 9.36, NNZs: 44, Bias: -21.862684, T: 28160, Avg. loss: 13.809267\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 9.37, NNZs: 44, Bias: -21.925840, T: 28800, Avg. loss: 11.215663\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 9.29, NNZs: 44, Bias: -21.977134, T: 29440, Avg. loss: 10.919410\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 9.44, NNZs: 44, Bias: -22.046628, T: 30080, Avg. loss: 11.670287\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 9.33, NNZs: 44, Bias: -22.098766, T: 30720, Avg. loss: 10.678681\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 9.37, NNZs: 44, Bias: -22.149601, T: 31360, Avg. loss: 11.416260\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 9.30, NNZs: 44, Bias: -22.196523, T: 32000, Avg. loss: 11.358393\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 9.26, NNZs: 44, Bias: -22.242260, T: 32640, Avg. loss: 9.731031\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 9.12, NNZs: 44, Bias: -22.280656, T: 33280, Avg. loss: 9.006451\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 9.22, NNZs: 44, Bias: -22.328328, T: 33920, Avg. loss: 9.207657\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 9.12, NNZs: 44, Bias: -22.374595, T: 34560, Avg. loss: 9.882925\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 9.09, NNZs: 44, Bias: -22.421797, T: 35200, Avg. loss: 9.979394\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 9.11, NNZs: 44, Bias: -22.466248, T: 35840, Avg. loss: 8.893490\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 9.06, NNZs: 44, Bias: -22.513793, T: 36480, Avg. loss: 8.991318\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 9.03, NNZs: 44, Bias: -22.553100, T: 37120, Avg. loss: 8.224942\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 9.07, NNZs: 44, Bias: -22.589988, T: 37760, Avg. loss: 8.861412\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 9.01, NNZs: 44, Bias: -22.640601, T: 38400, Avg. loss: 8.698771\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 9.01, NNZs: 44, Bias: -22.685427, T: 39040, Avg. loss: 8.509588\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 8.98, NNZs: 44, Bias: -22.722693, T: 39680, Avg. loss: 7.738338\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 8.93, NNZs: 44, Bias: -22.760115, T: 40320, Avg. loss: 8.054029\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 8.93, NNZs: 44, Bias: -22.797019, T: 40960, Avg. loss: 8.500504\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 8.93, NNZs: 44, Bias: -22.838322, T: 41600, Avg. loss: 6.743084\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 8.90, NNZs: 44, Bias: -22.869848, T: 42240, Avg. loss: 7.161529\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 8.83, NNZs: 44, Bias: -22.908464, T: 42880, Avg. loss: 6.941667\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 8.84, NNZs: 44, Bias: -22.948904, T: 43520, Avg. loss: 9.023189\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 8.83, NNZs: 44, Bias: -22.979528, T: 44160, Avg. loss: 6.340707\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 8.79, NNZs: 44, Bias: -23.009289, T: 44800, Avg. loss: 7.420992\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 8.77, NNZs: 44, Bias: -23.043158, T: 45440, Avg. loss: 6.921390\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 8.71, NNZs: 44, Bias: -23.073129, T: 46080, Avg. loss: 7.010272\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 8.69, NNZs: 44, Bias: -23.106556, T: 46720, Avg. loss: 6.390169\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 8.68, NNZs: 44, Bias: -23.137707, T: 47360, Avg. loss: 6.870737\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 74 epochs took 0.02 seconds\n",
      "--- training time 0.025758981704711914 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 60.99, NNZs: 42, Bias: -10.453885, T: 640, Avg. loss: 1552.509515\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 35.66, NNZs: 43, Bias: -12.783554, T: 1280, Avg. loss: 389.856725\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24.73, NNZs: 43, Bias: -14.062543, T: 1920, Avg. loss: 236.101649\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 20.01, NNZs: 44, Bias: -14.948544, T: 2560, Avg. loss: 187.732636\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 18.39, NNZs: 44, Bias: -15.671130, T: 3200, Avg. loss: 136.399263\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.70, NNZs: 44, Bias: -16.116936, T: 3840, Avg. loss: 111.364907\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 15.98, NNZs: 44, Bias: -16.589929, T: 4480, Avg. loss: 97.613050\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 14.31, NNZs: 44, Bias: -16.987956, T: 5120, Avg. loss: 74.871437\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 15.61, NNZs: 44, Bias: -17.388014, T: 5760, Avg. loss: 67.966306\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 13.92, NNZs: 44, Bias: -17.682240, T: 6400, Avg. loss: 61.636073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 11.86, NNZs: 44, Bias: -17.950590, T: 7040, Avg. loss: 55.904815\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 12.77, NNZs: 44, Bias: -18.208976, T: 7680, Avg. loss: 46.708359\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 11.33, NNZs: 44, Bias: -18.482606, T: 8320, Avg. loss: 45.033947\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 11.24, NNZs: 44, Bias: -18.677592, T: 8960, Avg. loss: 44.011195\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 11.42, NNZs: 44, Bias: -18.902786, T: 9600, Avg. loss: 43.701096\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 11.15, NNZs: 44, Bias: -19.059339, T: 10240, Avg. loss: 36.234746\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 11.28, NNZs: 44, Bias: -19.274144, T: 10880, Avg. loss: 33.412584\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 11.10, NNZs: 44, Bias: -19.442793, T: 11520, Avg. loss: 33.555258\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 10.71, NNZs: 44, Bias: -19.610984, T: 12160, Avg. loss: 34.817090\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 10.65, NNZs: 44, Bias: -19.756785, T: 12800, Avg. loss: 33.258951\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 11.12, NNZs: 44, Bias: -19.904638, T: 13440, Avg. loss: 30.816617\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 10.41, NNZs: 44, Bias: -20.032428, T: 14080, Avg. loss: 25.012433\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 10.57, NNZs: 44, Bias: -20.137965, T: 14720, Avg. loss: 28.452017\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 10.37, NNZs: 44, Bias: -20.251578, T: 15360, Avg. loss: 21.674290\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 10.47, NNZs: 44, Bias: -20.372988, T: 16000, Avg. loss: 22.736932\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 10.00, NNZs: 44, Bias: -20.472535, T: 16640, Avg. loss: 22.318439\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 10.02, NNZs: 44, Bias: -20.558950, T: 17280, Avg. loss: 20.445041\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 9.96, NNZs: 44, Bias: -20.664347, T: 17920, Avg. loss: 19.539886\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 9.83, NNZs: 44, Bias: -20.762185, T: 18560, Avg. loss: 19.285078\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 10.04, NNZs: 44, Bias: -20.861298, T: 19200, Avg. loss: 18.476698\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 10.05, NNZs: 44, Bias: -20.937798, T: 19840, Avg. loss: 19.100710\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 9.78, NNZs: 44, Bias: -21.031560, T: 20480, Avg. loss: 19.932161\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 9.73, NNZs: 44, Bias: -21.091787, T: 21120, Avg. loss: 16.569235\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 9.61, NNZs: 44, Bias: -21.180585, T: 21760, Avg. loss: 17.286220\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 9.71, NNZs: 44, Bias: -21.269395, T: 22400, Avg. loss: 16.595709\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 9.69, NNZs: 44, Bias: -21.341714, T: 23040, Avg. loss: 15.801840\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 9.62, NNZs: 44, Bias: -21.409972, T: 23680, Avg. loss: 15.241195\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 9.56, NNZs: 44, Bias: -21.492169, T: 24320, Avg. loss: 14.953152\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 9.59, NNZs: 44, Bias: -21.566195, T: 24960, Avg. loss: 13.076712\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 9.55, NNZs: 44, Bias: -21.629678, T: 25600, Avg. loss: 14.345237\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 9.57, NNZs: 44, Bias: -21.692393, T: 26240, Avg. loss: 13.411980\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 9.47, NNZs: 44, Bias: -21.744887, T: 26880, Avg. loss: 12.224874\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 9.46, NNZs: 44, Bias: -21.804454, T: 27520, Avg. loss: 12.965197\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 9.36, NNZs: 44, Bias: -21.862684, T: 28160, Avg. loss: 13.809267\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 9.37, NNZs: 44, Bias: -21.925840, T: 28800, Avg. loss: 11.215663\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 9.29, NNZs: 44, Bias: -21.977134, T: 29440, Avg. loss: 10.919410\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 9.44, NNZs: 44, Bias: -22.046628, T: 30080, Avg. loss: 11.670287\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 9.33, NNZs: 44, Bias: -22.098766, T: 30720, Avg. loss: 10.678681\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 9.37, NNZs: 44, Bias: -22.149601, T: 31360, Avg. loss: 11.416260\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 9.30, NNZs: 44, Bias: -22.196523, T: 32000, Avg. loss: 11.358393\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 9.26, NNZs: 44, Bias: -22.242260, T: 32640, Avg. loss: 9.731031\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 9.12, NNZs: 44, Bias: -22.280656, T: 33280, Avg. loss: 9.006451\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 9.22, NNZs: 44, Bias: -22.328328, T: 33920, Avg. loss: 9.207657\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 9.12, NNZs: 44, Bias: -22.374595, T: 34560, Avg. loss: 9.882925\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 9.09, NNZs: 44, Bias: -22.421797, T: 35200, Avg. loss: 9.979394\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 9.11, NNZs: 44, Bias: -22.466248, T: 35840, Avg. loss: 8.893490\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 9.06, NNZs: 44, Bias: -22.513793, T: 36480, Avg. loss: 8.991318\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 9.03, NNZs: 44, Bias: -22.553100, T: 37120, Avg. loss: 8.224942\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 9.07, NNZs: 44, Bias: -22.589988, T: 37760, Avg. loss: 8.861412\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 9.01, NNZs: 44, Bias: -22.640601, T: 38400, Avg. loss: 8.698771\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 9.01, NNZs: 44, Bias: -22.685427, T: 39040, Avg. loss: 8.509588\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 8.98, NNZs: 44, Bias: -22.722693, T: 39680, Avg. loss: 7.738338\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 8.93, NNZs: 44, Bias: -22.760115, T: 40320, Avg. loss: 8.054029\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 8.93, NNZs: 44, Bias: -22.797019, T: 40960, Avg. loss: 8.500504\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 8.93, NNZs: 44, Bias: -22.838322, T: 41600, Avg. loss: 6.743084\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 8.90, NNZs: 44, Bias: -22.869848, T: 42240, Avg. loss: 7.161529\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 8.83, NNZs: 44, Bias: -22.908464, T: 42880, Avg. loss: 6.941667\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 8.84, NNZs: 44, Bias: -22.948904, T: 43520, Avg. loss: 9.023189\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 8.83, NNZs: 44, Bias: -22.979528, T: 44160, Avg. loss: 6.340707\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 8.79, NNZs: 44, Bias: -23.009289, T: 44800, Avg. loss: 7.420992\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 8.77, NNZs: 44, Bias: -23.043158, T: 45440, Avg. loss: 6.921390\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 8.71, NNZs: 44, Bias: -23.073129, T: 46080, Avg. loss: 7.010272\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 8.69, NNZs: 44, Bias: -23.106556, T: 46720, Avg. loss: 6.390169\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 8.68, NNZs: 44, Bias: -23.137707, T: 47360, Avg. loss: 6.870737\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 74 epochs took 0.03 seconds\n",
      "--- training time 0.03014206886291504 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 60.99, NNZs: 42, Bias: -10.453885, T: 640, Avg. loss: 1552.509515\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 35.66, NNZs: 43, Bias: -12.783554, T: 1280, Avg. loss: 389.856725\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24.73, NNZs: 43, Bias: -14.062543, T: 1920, Avg. loss: 236.101649\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 20.01, NNZs: 44, Bias: -14.948544, T: 2560, Avg. loss: 187.732636\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 18.39, NNZs: 44, Bias: -15.671130, T: 3200, Avg. loss: 136.399263\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.70, NNZs: 44, Bias: -16.116936, T: 3840, Avg. loss: 111.364907\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 15.98, NNZs: 44, Bias: -16.589929, T: 4480, Avg. loss: 97.613050\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 14.31, NNZs: 44, Bias: -16.987956, T: 5120, Avg. loss: 74.871437\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 15.61, NNZs: 44, Bias: -17.388014, T: 5760, Avg. loss: 67.966306\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 13.92, NNZs: 44, Bias: -17.682240, T: 6400, Avg. loss: 61.636073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 11.86, NNZs: 44, Bias: -17.950590, T: 7040, Avg. loss: 55.904815\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 12.77, NNZs: 44, Bias: -18.208976, T: 7680, Avg. loss: 46.708359\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 11.33, NNZs: 44, Bias: -18.482606, T: 8320, Avg. loss: 45.033947\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 11.24, NNZs: 44, Bias: -18.677592, T: 8960, Avg. loss: 44.011195\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 11.42, NNZs: 44, Bias: -18.902786, T: 9600, Avg. loss: 43.701096\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 11.15, NNZs: 44, Bias: -19.059339, T: 10240, Avg. loss: 36.234746\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 11.28, NNZs: 44, Bias: -19.274144, T: 10880, Avg. loss: 33.412584\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 11.10, NNZs: 44, Bias: -19.442793, T: 11520, Avg. loss: 33.555258\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 10.71, NNZs: 44, Bias: -19.610984, T: 12160, Avg. loss: 34.817090\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 10.65, NNZs: 44, Bias: -19.756785, T: 12800, Avg. loss: 33.258951\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 11.12, NNZs: 44, Bias: -19.904638, T: 13440, Avg. loss: 30.816617\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 10.41, NNZs: 44, Bias: -20.032428, T: 14080, Avg. loss: 25.012433\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 10.57, NNZs: 44, Bias: -20.137965, T: 14720, Avg. loss: 28.452017\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 10.37, NNZs: 44, Bias: -20.251578, T: 15360, Avg. loss: 21.674290\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 10.47, NNZs: 44, Bias: -20.372988, T: 16000, Avg. loss: 22.736932\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 10.00, NNZs: 44, Bias: -20.472535, T: 16640, Avg. loss: 22.318439\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 10.02, NNZs: 44, Bias: -20.558950, T: 17280, Avg. loss: 20.445041\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 9.96, NNZs: 44, Bias: -20.664347, T: 17920, Avg. loss: 19.539886\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 9.83, NNZs: 44, Bias: -20.762185, T: 18560, Avg. loss: 19.285078\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 10.04, NNZs: 44, Bias: -20.861298, T: 19200, Avg. loss: 18.476698\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 10.05, NNZs: 44, Bias: -20.937798, T: 19840, Avg. loss: 19.100710\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 9.78, NNZs: 44, Bias: -21.031560, T: 20480, Avg. loss: 19.932161\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 9.73, NNZs: 44, Bias: -21.091787, T: 21120, Avg. loss: 16.569235\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 9.61, NNZs: 44, Bias: -21.180585, T: 21760, Avg. loss: 17.286220\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 9.71, NNZs: 44, Bias: -21.269395, T: 22400, Avg. loss: 16.595709\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 9.69, NNZs: 44, Bias: -21.341714, T: 23040, Avg. loss: 15.801840\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 9.62, NNZs: 44, Bias: -21.409972, T: 23680, Avg. loss: 15.241195\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 9.56, NNZs: 44, Bias: -21.492169, T: 24320, Avg. loss: 14.953152\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 9.59, NNZs: 44, Bias: -21.566195, T: 24960, Avg. loss: 13.076712\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 9.55, NNZs: 44, Bias: -21.629678, T: 25600, Avg. loss: 14.345237\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 9.57, NNZs: 44, Bias: -21.692393, T: 26240, Avg. loss: 13.411980\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 9.47, NNZs: 44, Bias: -21.744887, T: 26880, Avg. loss: 12.224874\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 9.46, NNZs: 44, Bias: -21.804454, T: 27520, Avg. loss: 12.965197\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 9.36, NNZs: 44, Bias: -21.862684, T: 28160, Avg. loss: 13.809267\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 9.37, NNZs: 44, Bias: -21.925840, T: 28800, Avg. loss: 11.215663\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 9.29, NNZs: 44, Bias: -21.977134, T: 29440, Avg. loss: 10.919410\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 9.44, NNZs: 44, Bias: -22.046628, T: 30080, Avg. loss: 11.670287\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 9.33, NNZs: 44, Bias: -22.098766, T: 30720, Avg. loss: 10.678681\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 9.37, NNZs: 44, Bias: -22.149601, T: 31360, Avg. loss: 11.416260\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 9.30, NNZs: 44, Bias: -22.196523, T: 32000, Avg. loss: 11.358393\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 9.26, NNZs: 44, Bias: -22.242260, T: 32640, Avg. loss: 9.731031\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 9.12, NNZs: 44, Bias: -22.280656, T: 33280, Avg. loss: 9.006451\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 9.22, NNZs: 44, Bias: -22.328328, T: 33920, Avg. loss: 9.207657\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 9.12, NNZs: 44, Bias: -22.374595, T: 34560, Avg. loss: 9.882925\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 9.09, NNZs: 44, Bias: -22.421797, T: 35200, Avg. loss: 9.979394\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 9.11, NNZs: 44, Bias: -22.466248, T: 35840, Avg. loss: 8.893490\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 9.06, NNZs: 44, Bias: -22.513793, T: 36480, Avg. loss: 8.991318\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 9.03, NNZs: 44, Bias: -22.553100, T: 37120, Avg. loss: 8.224942\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 9.07, NNZs: 44, Bias: -22.589988, T: 37760, Avg. loss: 8.861412\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 9.01, NNZs: 44, Bias: -22.640601, T: 38400, Avg. loss: 8.698771\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 9.01, NNZs: 44, Bias: -22.685427, T: 39040, Avg. loss: 8.509588\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 8.98, NNZs: 44, Bias: -22.722693, T: 39680, Avg. loss: 7.738338\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 8.93, NNZs: 44, Bias: -22.760115, T: 40320, Avg. loss: 8.054029\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 8.93, NNZs: 44, Bias: -22.797019, T: 40960, Avg. loss: 8.500504\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 8.93, NNZs: 44, Bias: -22.838322, T: 41600, Avg. loss: 6.743084\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 8.90, NNZs: 44, Bias: -22.869848, T: 42240, Avg. loss: 7.161529\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 8.83, NNZs: 44, Bias: -22.908464, T: 42880, Avg. loss: 6.941667\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 8.84, NNZs: 44, Bias: -22.948904, T: 43520, Avg. loss: 9.023189\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 8.83, NNZs: 44, Bias: -22.979528, T: 44160, Avg. loss: 6.340707\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 8.79, NNZs: 44, Bias: -23.009289, T: 44800, Avg. loss: 7.420992\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 8.77, NNZs: 44, Bias: -23.043158, T: 45440, Avg. loss: 6.921390\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 8.71, NNZs: 44, Bias: -23.073129, T: 46080, Avg. loss: 7.010272\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 8.69, NNZs: 44, Bias: -23.106556, T: 46720, Avg. loss: 6.390169\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 8.68, NNZs: 44, Bias: -23.137707, T: 47360, Avg. loss: 6.870737\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 74 epochs took 0.03 seconds\n",
      "--- training time 0.0394749641418457 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.28, NNZs: 44, Bias: -0.013512, T: 640, Avg. loss: 3.020409\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.018760, T: 1280, Avg. loss: 1.296850\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.023565, T: 1920, Avg. loss: 0.963469\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.15, NNZs: 44, Bias: -0.027589, T: 2560, Avg. loss: 0.921900\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.14, NNZs: 44, Bias: -0.031779, T: 3200, Avg. loss: 0.737516\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.034975, T: 3840, Avg. loss: 0.649676\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.038168, T: 4480, Avg. loss: 0.654734\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.041333, T: 5120, Avg. loss: 0.612543\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.044426, T: 5760, Avg. loss: 0.567650\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.047042, T: 6400, Avg. loss: 0.558362\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.19, NNZs: 44, Bias: -0.049740, T: 7040, Avg. loss: 0.546509\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.19, NNZs: 44, Bias: -0.052214, T: 7680, Avg. loss: 0.536491\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.20, NNZs: 44, Bias: -0.054853, T: 8320, Avg. loss: 0.494764\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.20, NNZs: 44, Bias: -0.056945, T: 8960, Avg. loss: 0.522660\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.21, NNZs: 44, Bias: -0.059607, T: 9600, Avg. loss: 0.512106\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.21, NNZs: 44, Bias: -0.061642, T: 10240, Avg. loss: 0.487472\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.22, NNZs: 44, Bias: -0.064052, T: 10880, Avg. loss: 0.448072\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.066284, T: 11520, Avg. loss: 0.466046\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.068396, T: 12160, Avg. loss: 0.460946\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.070376, T: 12800, Avg. loss: 0.473061\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.24, NNZs: 44, Bias: -0.072256, T: 13440, Avg. loss: 0.466358\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.24, NNZs: 44, Bias: -0.074107, T: 14080, Avg. loss: 0.420802\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.25, NNZs: 44, Bias: -0.075874, T: 14720, Avg. loss: 0.437950\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.077713, T: 15360, Avg. loss: 0.414708\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.079615, T: 16000, Avg. loss: 0.419000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.081175, T: 16640, Avg. loss: 0.416462\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.27, NNZs: 44, Bias: -0.082705, T: 17280, Avg. loss: 0.399610\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.27, NNZs: 44, Bias: -0.084400, T: 17920, Avg. loss: 0.406214\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.28, NNZs: 44, Bias: -0.086092, T: 18560, Avg. loss: 0.404670\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.087828, T: 19200, Avg. loss: 0.393779\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.089294, T: 19840, Avg. loss: 0.408178\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.090851, T: 20480, Avg. loss: 0.415089\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.092223, T: 21120, Avg. loss: 0.385259\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.30, NNZs: 44, Bias: -0.093777, T: 21760, Avg. loss: 0.389855\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.30, NNZs: 44, Bias: -0.095357, T: 22400, Avg. loss: 0.395306\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.31, NNZs: 44, Bias: -0.096812, T: 23040, Avg. loss: 0.398555\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.31, NNZs: 44, Bias: -0.098326, T: 23680, Avg. loss: 0.403534\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.099797, T: 24320, Avg. loss: 0.395906\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 38 epochs took 0.02 seconds\n",
      "--- training time 0.024741172790527344 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.28, NNZs: 44, Bias: -0.013512, T: 640, Avg. loss: 3.020409\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.018760, T: 1280, Avg. loss: 1.296850\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.023565, T: 1920, Avg. loss: 0.963469\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.15, NNZs: 44, Bias: -0.027589, T: 2560, Avg. loss: 0.921900\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.14, NNZs: 44, Bias: -0.031779, T: 3200, Avg. loss: 0.737516\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.034975, T: 3840, Avg. loss: 0.649676\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.038168, T: 4480, Avg. loss: 0.654734\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.041333, T: 5120, Avg. loss: 0.612543\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.044426, T: 5760, Avg. loss: 0.567650\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.047042, T: 6400, Avg. loss: 0.558362\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.19, NNZs: 44, Bias: -0.049740, T: 7040, Avg. loss: 0.546509\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.19, NNZs: 44, Bias: -0.052214, T: 7680, Avg. loss: 0.536491\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.20, NNZs: 44, Bias: -0.054853, T: 8320, Avg. loss: 0.494764\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.20, NNZs: 44, Bias: -0.056945, T: 8960, Avg. loss: 0.522660\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.21, NNZs: 44, Bias: -0.059607, T: 9600, Avg. loss: 0.512106\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.21, NNZs: 44, Bias: -0.061642, T: 10240, Avg. loss: 0.487472\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.22, NNZs: 44, Bias: -0.064052, T: 10880, Avg. loss: 0.448072\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.066284, T: 11520, Avg. loss: 0.466046\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.068396, T: 12160, Avg. loss: 0.460946\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.070376, T: 12800, Avg. loss: 0.473061\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.24, NNZs: 44, Bias: -0.072256, T: 13440, Avg. loss: 0.466358\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.24, NNZs: 44, Bias: -0.074107, T: 14080, Avg. loss: 0.420802\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.25, NNZs: 44, Bias: -0.075874, T: 14720, Avg. loss: 0.437950\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.077713, T: 15360, Avg. loss: 0.414708\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.079615, T: 16000, Avg. loss: 0.419000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.081175, T: 16640, Avg. loss: 0.416462\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.27, NNZs: 44, Bias: -0.082705, T: 17280, Avg. loss: 0.399610\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.27, NNZs: 44, Bias: -0.084400, T: 17920, Avg. loss: 0.406214\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.28, NNZs: 44, Bias: -0.086092, T: 18560, Avg. loss: 0.404670\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.087828, T: 19200, Avg. loss: 0.393779\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.089294, T: 19840, Avg. loss: 0.408178\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.090851, T: 20480, Avg. loss: 0.415089\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.092223, T: 21120, Avg. loss: 0.385259\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.30, NNZs: 44, Bias: -0.093777, T: 21760, Avg. loss: 0.389855\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.30, NNZs: 44, Bias: -0.095357, T: 22400, Avg. loss: 0.395306\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.31, NNZs: 44, Bias: -0.096812, T: 23040, Avg. loss: 0.398555\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.31, NNZs: 44, Bias: -0.098326, T: 23680, Avg. loss: 0.403534\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.099797, T: 24320, Avg. loss: 0.395906\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 38 epochs took 0.04 seconds\n",
      "--- training time 0.04220700263977051 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.28, NNZs: 44, Bias: -0.013512, T: 640, Avg. loss: 3.020409\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.018760, T: 1280, Avg. loss: 1.296850\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.023565, T: 1920, Avg. loss: 0.963469\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.15, NNZs: 44, Bias: -0.027589, T: 2560, Avg. loss: 0.921900\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.14, NNZs: 44, Bias: -0.031779, T: 3200, Avg. loss: 0.737516\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.034975, T: 3840, Avg. loss: 0.649676\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.038168, T: 4480, Avg. loss: 0.654734\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.041333, T: 5120, Avg. loss: 0.612543\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.044426, T: 5760, Avg. loss: 0.567650\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.047042, T: 6400, Avg. loss: 0.558362\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.19, NNZs: 44, Bias: -0.049740, T: 7040, Avg. loss: 0.546509\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.19, NNZs: 44, Bias: -0.052214, T: 7680, Avg. loss: 0.536491\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.20, NNZs: 44, Bias: -0.054853, T: 8320, Avg. loss: 0.494764\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.20, NNZs: 44, Bias: -0.056945, T: 8960, Avg. loss: 0.522660\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.21, NNZs: 44, Bias: -0.059607, T: 9600, Avg. loss: 0.512106\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.21, NNZs: 44, Bias: -0.061642, T: 10240, Avg. loss: 0.487472\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.22, NNZs: 44, Bias: -0.064052, T: 10880, Avg. loss: 0.448072\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.066284, T: 11520, Avg. loss: 0.466046\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.068396, T: 12160, Avg. loss: 0.460946\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.070376, T: 12800, Avg. loss: 0.473061\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.24, NNZs: 44, Bias: -0.072256, T: 13440, Avg. loss: 0.466358\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.24, NNZs: 44, Bias: -0.074107, T: 14080, Avg. loss: 0.420802\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.25, NNZs: 44, Bias: -0.075874, T: 14720, Avg. loss: 0.437950\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.077713, T: 15360, Avg. loss: 0.414708\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.079615, T: 16000, Avg. loss: 0.419000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.081175, T: 16640, Avg. loss: 0.416462\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.27, NNZs: 44, Bias: -0.082705, T: 17280, Avg. loss: 0.399610\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.27, NNZs: 44, Bias: -0.084400, T: 17920, Avg. loss: 0.406214\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.28, NNZs: 44, Bias: -0.086092, T: 18560, Avg. loss: 0.404670\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.087828, T: 19200, Avg. loss: 0.393779\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.089294, T: 19840, Avg. loss: 0.408178\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.090851, T: 20480, Avg. loss: 0.415089\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.092223, T: 21120, Avg. loss: 0.385259\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.30, NNZs: 44, Bias: -0.093777, T: 21760, Avg. loss: 0.389855\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.30, NNZs: 44, Bias: -0.095357, T: 22400, Avg. loss: 0.395306\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.31, NNZs: 44, Bias: -0.096812, T: 23040, Avg. loss: 0.398555\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.31, NNZs: 44, Bias: -0.098326, T: 23680, Avg. loss: 0.403534\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.099797, T: 24320, Avg. loss: 0.395906\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 38 epochs took 0.02 seconds\n",
      "--- training time 0.02263927459716797 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 3.92, NNZs: 44, Bias: -0.229017, T: 640, Avg. loss: 39.588520\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.22, NNZs: 44, Bias: -0.412678, T: 1280, Avg. loss: 36.358448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.77, NNZs: 44, Bias: -0.608724, T: 1920, Avg. loss: 37.326056\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.16, NNZs: 44, Bias: -0.820996, T: 2560, Avg. loss: 41.772040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.046754, T: 3200, Avg. loss: 40.525607\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.70, NNZs: 44, Bias: -1.233228, T: 3840, Avg. loss: 39.758304\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 6.79, NNZs: 44, Bias: -1.422213, T: 4480, Avg. loss: 39.742680\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 4.53, NNZs: 44, Bias: -1.450692, T: 5120, Avg. loss: 16.560021\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 4.10, NNZs: 44, Bias: -1.488961, T: 5760, Avg. loss: 9.079159\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 4.12, NNZs: 44, Bias: -1.526367, T: 6400, Avg. loss: 7.795266\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 4.13, NNZs: 44, Bias: -1.563871, T: 7040, Avg. loss: 7.278739\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 4.18, NNZs: 44, Bias: -1.597494, T: 7680, Avg. loss: 7.476793\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 4.20, NNZs: 44, Bias: -1.635171, T: 8320, Avg. loss: 6.880366\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 4.23, NNZs: 44, Bias: -1.670875, T: 8960, Avg. loss: 8.182257\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 4.29, NNZs: 44, Bias: -1.708758, T: 9600, Avg. loss: 7.790961\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 4.42, NNZs: 44, Bias: -1.745993, T: 10240, Avg. loss: 6.813259\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 4.53, NNZs: 44, Bias: -1.787712, T: 10880, Avg. loss: 6.377116\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 4.54, NNZs: 44, Bias: -1.826082, T: 11520, Avg. loss: 7.133107\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 4.61, NNZs: 44, Bias: -1.865045, T: 12160, Avg. loss: 7.854998\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 4.62, NNZs: 44, Bias: -1.900519, T: 12800, Avg. loss: 8.339434\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 4.69, NNZs: 44, Bias: -1.938469, T: 13440, Avg. loss: 7.971242\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 4.70, NNZs: 44, Bias: -1.971390, T: 14080, Avg. loss: 6.846766\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.975878, T: 14720, Avg. loss: 1.909502\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 4.65, NNZs: 44, Bias: -1.981030, T: 15360, Avg. loss: 1.337327\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 4.64, NNZs: 44, Bias: -1.986973, T: 16000, Avg. loss: 1.095216\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 4.64, NNZs: 44, Bias: -1.991376, T: 16640, Avg. loss: 1.240920\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 4.63, NNZs: 44, Bias: -1.995282, T: 17280, Avg. loss: 1.152731\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.000016, T: 17920, Avg. loss: 1.129366\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.005264, T: 18560, Avg. loss: 1.114322\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.010318, T: 19200, Avg. loss: 1.112498\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 4.62, NNZs: 44, Bias: -2.010732, T: 19840, Avg. loss: 0.529010\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 4.62, NNZs: 44, Bias: -2.011248, T: 20480, Avg. loss: 0.383808\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.011636, T: 21120, Avg. loss: 0.347171\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.012246, T: 21760, Avg. loss: 0.332399\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.012706, T: 22400, Avg. loss: 0.351599\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.013156, T: 23040, Avg. loss: 0.337051\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.013751, T: 23680, Avg. loss: 0.323753\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.014291, T: 24320, Avg. loss: 0.316370\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.014850, T: 24960, Avg. loss: 0.306305\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.015305, T: 25600, Avg. loss: 0.349897\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.015810, T: 26240, Avg. loss: 0.322652\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.016303, T: 26880, Avg. loss: 0.284620\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.016802, T: 27520, Avg. loss: 0.341514\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.017296, T: 28160, Avg. loss: 0.334507\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.017880, T: 28800, Avg. loss: 0.307931\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.018483, T: 29440, Avg. loss: 0.334228\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019125, T: 30080, Avg. loss: 0.296572\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019163, T: 30720, Avg. loss: 0.224531\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019239, T: 31360, Avg. loss: 0.215501\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019339, T: 32000, Avg. loss: 0.227935\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019387, T: 32640, Avg. loss: 0.213606\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019489, T: 33280, Avg. loss: 0.218986\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019590, T: 33920, Avg. loss: 0.228519\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019696, T: 34560, Avg. loss: 0.219427\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019733, T: 35200, Avg. loss: 0.221081\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019877, T: 35840, Avg. loss: 0.221838\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019869, T: 36480, Avg. loss: 0.214944\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019888, T: 37120, Avg. loss: 0.209974\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019906, T: 37760, Avg. loss: 0.209764\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019922, T: 38400, Avg. loss: 0.207634\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019936, T: 39040, Avg. loss: 0.209592\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019947, T: 39680, Avg. loss: 0.208848\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019974, T: 40320, Avg. loss: 0.210157\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019986, T: 40960, Avg. loss: 0.208959\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020005, T: 41600, Avg. loss: 0.209884\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020008, T: 42240, Avg. loss: 0.205329\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020012, T: 42880, Avg. loss: 0.205593\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020015, T: 43520, Avg. loss: 0.205441\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020019, T: 44160, Avg. loss: 0.205546\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020022, T: 44800, Avg. loss: 0.205484\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020026, T: 45440, Avg. loss: 0.205467\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 71 epochs took 0.03 seconds\n",
      "--- training time 0.03465890884399414 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 3.92, NNZs: 44, Bias: -0.229017, T: 640, Avg. loss: 39.588520\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.22, NNZs: 44, Bias: -0.412678, T: 1280, Avg. loss: 36.358448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.77, NNZs: 44, Bias: -0.608724, T: 1920, Avg. loss: 37.326056\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.16, NNZs: 44, Bias: -0.820996, T: 2560, Avg. loss: 41.772040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.046754, T: 3200, Avg. loss: 40.525607\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.70, NNZs: 44, Bias: -1.233228, T: 3840, Avg. loss: 39.758304\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 6.79, NNZs: 44, Bias: -1.422213, T: 4480, Avg. loss: 39.742680\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 4.53, NNZs: 44, Bias: -1.450692, T: 5120, Avg. loss: 16.560021\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 4.10, NNZs: 44, Bias: -1.488961, T: 5760, Avg. loss: 9.079159\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 4.12, NNZs: 44, Bias: -1.526367, T: 6400, Avg. loss: 7.795266\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 4.13, NNZs: 44, Bias: -1.563871, T: 7040, Avg. loss: 7.278739\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 4.18, NNZs: 44, Bias: -1.597494, T: 7680, Avg. loss: 7.476793\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 4.20, NNZs: 44, Bias: -1.635171, T: 8320, Avg. loss: 6.880366\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 4.23, NNZs: 44, Bias: -1.670875, T: 8960, Avg. loss: 8.182257\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 4.29, NNZs: 44, Bias: -1.708758, T: 9600, Avg. loss: 7.790961\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 4.42, NNZs: 44, Bias: -1.745993, T: 10240, Avg. loss: 6.813259\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 4.53, NNZs: 44, Bias: -1.787712, T: 10880, Avg. loss: 6.377116\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 4.54, NNZs: 44, Bias: -1.826082, T: 11520, Avg. loss: 7.133107\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 4.61, NNZs: 44, Bias: -1.865045, T: 12160, Avg. loss: 7.854998\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 4.62, NNZs: 44, Bias: -1.900519, T: 12800, Avg. loss: 8.339434\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 4.69, NNZs: 44, Bias: -1.938469, T: 13440, Avg. loss: 7.971242\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 4.70, NNZs: 44, Bias: -1.971390, T: 14080, Avg. loss: 6.846766\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.975878, T: 14720, Avg. loss: 1.909502\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 4.65, NNZs: 44, Bias: -1.981030, T: 15360, Avg. loss: 1.337327\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 4.64, NNZs: 44, Bias: -1.986973, T: 16000, Avg. loss: 1.095216\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 4.64, NNZs: 44, Bias: -1.991376, T: 16640, Avg. loss: 1.240920\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 4.63, NNZs: 44, Bias: -1.995282, T: 17280, Avg. loss: 1.152731\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.000016, T: 17920, Avg. loss: 1.129366\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.005264, T: 18560, Avg. loss: 1.114322\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.010318, T: 19200, Avg. loss: 1.112498\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 4.62, NNZs: 44, Bias: -2.010732, T: 19840, Avg. loss: 0.529010\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 4.62, NNZs: 44, Bias: -2.011248, T: 20480, Avg. loss: 0.383808\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.011636, T: 21120, Avg. loss: 0.347171\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.012246, T: 21760, Avg. loss: 0.332399\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.012706, T: 22400, Avg. loss: 0.351599\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.013156, T: 23040, Avg. loss: 0.337051\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.013751, T: 23680, Avg. loss: 0.323753\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.014291, T: 24320, Avg. loss: 0.316370\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.014850, T: 24960, Avg. loss: 0.306305\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.015305, T: 25600, Avg. loss: 0.349897\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.015810, T: 26240, Avg. loss: 0.322652\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.016303, T: 26880, Avg. loss: 0.284620\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.016802, T: 27520, Avg. loss: 0.341514\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.017296, T: 28160, Avg. loss: 0.334507\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.017880, T: 28800, Avg. loss: 0.307931\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.018483, T: 29440, Avg. loss: 0.334228\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019125, T: 30080, Avg. loss: 0.296572\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019163, T: 30720, Avg. loss: 0.224531\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019239, T: 31360, Avg. loss: 0.215501\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019339, T: 32000, Avg. loss: 0.227935\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019387, T: 32640, Avg. loss: 0.213606\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019489, T: 33280, Avg. loss: 0.218986\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019590, T: 33920, Avg. loss: 0.228519\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019696, T: 34560, Avg. loss: 0.219427\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019733, T: 35200, Avg. loss: 0.221081\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019877, T: 35840, Avg. loss: 0.221838\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019869, T: 36480, Avg. loss: 0.214944\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019888, T: 37120, Avg. loss: 0.209974\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019906, T: 37760, Avg. loss: 0.209764\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019922, T: 38400, Avg. loss: 0.207634\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019936, T: 39040, Avg. loss: 0.209592\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019947, T: 39680, Avg. loss: 0.208848\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019974, T: 40320, Avg. loss: 0.210157\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019986, T: 40960, Avg. loss: 0.208959\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020005, T: 41600, Avg. loss: 0.209884\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020008, T: 42240, Avg. loss: 0.205329\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020012, T: 42880, Avg. loss: 0.205593\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020015, T: 43520, Avg. loss: 0.205441\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020019, T: 44160, Avg. loss: 0.205546\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020022, T: 44800, Avg. loss: 0.205484\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020026, T: 45440, Avg. loss: 0.205467\n",
      "Total training time: 0.08 seconds.\n",
      "Convergence after 71 epochs took 0.08 seconds\n",
      "--- training time 0.08411693572998047 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 3.92, NNZs: 44, Bias: -0.229017, T: 640, Avg. loss: 39.588520\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.22, NNZs: 44, Bias: -0.412678, T: 1280, Avg. loss: 36.358448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.77, NNZs: 44, Bias: -0.608724, T: 1920, Avg. loss: 37.326056\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.16, NNZs: 44, Bias: -0.820996, T: 2560, Avg. loss: 41.772040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.046754, T: 3200, Avg. loss: 40.525607\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.70, NNZs: 44, Bias: -1.233228, T: 3840, Avg. loss: 39.758304\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 6.79, NNZs: 44, Bias: -1.422213, T: 4480, Avg. loss: 39.742680\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 4.53, NNZs: 44, Bias: -1.450692, T: 5120, Avg. loss: 16.560021\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 4.10, NNZs: 44, Bias: -1.488961, T: 5760, Avg. loss: 9.079159\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 4.12, NNZs: 44, Bias: -1.526367, T: 6400, Avg. loss: 7.795266\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 4.13, NNZs: 44, Bias: -1.563871, T: 7040, Avg. loss: 7.278739\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 4.18, NNZs: 44, Bias: -1.597494, T: 7680, Avg. loss: 7.476793\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 4.20, NNZs: 44, Bias: -1.635171, T: 8320, Avg. loss: 6.880366\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 4.23, NNZs: 44, Bias: -1.670875, T: 8960, Avg. loss: 8.182257\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 4.29, NNZs: 44, Bias: -1.708758, T: 9600, Avg. loss: 7.790961\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 4.42, NNZs: 44, Bias: -1.745993, T: 10240, Avg. loss: 6.813259\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 4.53, NNZs: 44, Bias: -1.787712, T: 10880, Avg. loss: 6.377116\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 4.54, NNZs: 44, Bias: -1.826082, T: 11520, Avg. loss: 7.133107\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 4.61, NNZs: 44, Bias: -1.865045, T: 12160, Avg. loss: 7.854998\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 4.62, NNZs: 44, Bias: -1.900519, T: 12800, Avg. loss: 8.339434\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 4.69, NNZs: 44, Bias: -1.938469, T: 13440, Avg. loss: 7.971242\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 4.70, NNZs: 44, Bias: -1.971390, T: 14080, Avg. loss: 6.846766\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.975878, T: 14720, Avg. loss: 1.909502\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 4.65, NNZs: 44, Bias: -1.981030, T: 15360, Avg. loss: 1.337327\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 4.64, NNZs: 44, Bias: -1.986973, T: 16000, Avg. loss: 1.095216\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 4.64, NNZs: 44, Bias: -1.991376, T: 16640, Avg. loss: 1.240920\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 4.63, NNZs: 44, Bias: -1.995282, T: 17280, Avg. loss: 1.152731\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.000016, T: 17920, Avg. loss: 1.129366\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.005264, T: 18560, Avg. loss: 1.114322\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.010318, T: 19200, Avg. loss: 1.112498\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 4.62, NNZs: 44, Bias: -2.010732, T: 19840, Avg. loss: 0.529010\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 4.62, NNZs: 44, Bias: -2.011248, T: 20480, Avg. loss: 0.383808\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.011636, T: 21120, Avg. loss: 0.347171\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.012246, T: 21760, Avg. loss: 0.332399\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.012706, T: 22400, Avg. loss: 0.351599\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.013156, T: 23040, Avg. loss: 0.337051\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.013751, T: 23680, Avg. loss: 0.323753\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.014291, T: 24320, Avg. loss: 0.316370\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.014850, T: 24960, Avg. loss: 0.306305\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.015305, T: 25600, Avg. loss: 0.349897\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.015810, T: 26240, Avg. loss: 0.322652\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.016303, T: 26880, Avg. loss: 0.284620\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.016802, T: 27520, Avg. loss: 0.341514\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.017296, T: 28160, Avg. loss: 0.334507\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.017880, T: 28800, Avg. loss: 0.307931\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.018483, T: 29440, Avg. loss: 0.334228\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019125, T: 30080, Avg. loss: 0.296572\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019163, T: 30720, Avg. loss: 0.224531\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019239, T: 31360, Avg. loss: 0.215501\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019339, T: 32000, Avg. loss: 0.227935\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019387, T: 32640, Avg. loss: 0.213606\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019489, T: 33280, Avg. loss: 0.218986\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019590, T: 33920, Avg. loss: 0.228519\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019696, T: 34560, Avg. loss: 0.219427\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019733, T: 35200, Avg. loss: 0.221081\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019877, T: 35840, Avg. loss: 0.221838\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019869, T: 36480, Avg. loss: 0.214944\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019888, T: 37120, Avg. loss: 0.209974\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019906, T: 37760, Avg. loss: 0.209764\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019922, T: 38400, Avg. loss: 0.207634\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019936, T: 39040, Avg. loss: 0.209592\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019947, T: 39680, Avg. loss: 0.208848\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019974, T: 40320, Avg. loss: 0.210157\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019986, T: 40960, Avg. loss: 0.208959\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020005, T: 41600, Avg. loss: 0.209884\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020008, T: 42240, Avg. loss: 0.205329\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020012, T: 42880, Avg. loss: 0.205593\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020015, T: 43520, Avg. loss: 0.205441\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020019, T: 44160, Avg. loss: 0.205546\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020022, T: 44800, Avg. loss: 0.205484\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020026, T: 45440, Avg. loss: 0.205467\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 71 epochs took 0.03 seconds\n",
      "--- training time 0.03262805938720703 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 10.91, NNZs: 43, Bias: -2.550009, T: 640, Avg. loss: 402.389039\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.71, NNZs: 44, Bias: -5.050009, T: 1280, Avg. loss: 323.294791\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.46, NNZs: 44, Bias: -7.512515, T: 1920, Avg. loss: 359.311537\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.05, NNZs: 44, Bias: -10.201947, T: 2560, Avg. loss: 399.918189\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.69, NNZs: 44, Bias: -12.720222, T: 3200, Avg. loss: 361.718888\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.91, NNZs: 44, Bias: -14.880795, T: 3840, Avg. loss: 377.351976\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 19.10, NNZs: 44, Bias: -17.180424, T: 4480, Avg. loss: 376.820507\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.009539127349853516 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 10.91, NNZs: 43, Bias: -2.550009, T: 640, Avg. loss: 402.389039\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.71, NNZs: 44, Bias: -5.050009, T: 1280, Avg. loss: 323.294791\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.46, NNZs: 44, Bias: -7.512515, T: 1920, Avg. loss: 359.311537\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.05, NNZs: 44, Bias: -10.201947, T: 2560, Avg. loss: 399.918189\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.69, NNZs: 44, Bias: -12.720222, T: 3200, Avg. loss: 361.718888\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.91, NNZs: 44, Bias: -14.880795, T: 3840, Avg. loss: 377.351976\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 19.10, NNZs: 44, Bias: -17.180424, T: 4480, Avg. loss: 376.820507\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.007816314697265625 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 10.91, NNZs: 43, Bias: -2.550009, T: 640, Avg. loss: 402.389039\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.71, NNZs: 44, Bias: -5.050009, T: 1280, Avg. loss: 323.294791\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.46, NNZs: 44, Bias: -7.512515, T: 1920, Avg. loss: 359.311537\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.05, NNZs: 44, Bias: -10.201947, T: 2560, Avg. loss: 399.918189\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.69, NNZs: 44, Bias: -12.720222, T: 3200, Avg. loss: 361.718888\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.91, NNZs: 44, Bias: -14.880795, T: 3840, Avg. loss: 377.351976\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 19.10, NNZs: 44, Bias: -17.180424, T: 4480, Avg. loss: 376.820507\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.008923053741455078 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 6.35, NNZs: 44, Bias: -1.994673, T: 640, Avg. loss: 189.614785\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.05, NNZs: 44, Bias: -2.217508, T: 1280, Avg. loss: 40.077763\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3.12, NNZs: 44, Bias: -2.340662, T: 1920, Avg. loss: 23.614151\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.03, NNZs: 44, Bias: -2.422736, T: 2560, Avg. loss: 19.441969\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.59, NNZs: 44, Bias: -2.496541, T: 3200, Avg. loss: 13.700437\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.98, NNZs: 44, Bias: -2.541821, T: 3840, Avg. loss: 10.579633\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.45, NNZs: 44, Bias: -2.583415, T: 4480, Avg. loss: 9.411084\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.40, NNZs: 44, Bias: -2.630032, T: 5120, Avg. loss: 8.216800\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.50, NNZs: 44, Bias: -2.663326, T: 5760, Avg. loss: 7.242535\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.36, NNZs: 44, Bias: -2.692023, T: 6400, Avg. loss: 5.980278\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.29, NNZs: 44, Bias: -2.721187, T: 7040, Avg. loss: 5.348994\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.22, NNZs: 44, Bias: -2.743549, T: 7680, Avg. loss: 4.803177\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1.12, NNZs: 44, Bias: -2.768479, T: 8320, Avg. loss: 4.859873\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1.13, NNZs: 44, Bias: -2.788927, T: 8960, Avg. loss: 4.464438\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1.08, NNZs: 44, Bias: -2.811251, T: 9600, Avg. loss: 4.280645\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1.15, NNZs: 44, Bias: -2.830171, T: 10240, Avg. loss: 3.587939\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1.08, NNZs: 44, Bias: -2.848824, T: 10880, Avg. loss: 2.990107\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1.10, NNZs: 44, Bias: -2.867765, T: 11520, Avg. loss: 3.350379\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 1.05, NNZs: 44, Bias: -2.884974, T: 12160, Avg. loss: 3.444854\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.04, NNZs: 44, Bias: -2.900045, T: 12800, Avg. loss: 2.998987\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.10, NNZs: 44, Bias: -2.915230, T: 13440, Avg. loss: 2.910877\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 1.03, NNZs: 44, Bias: -2.927017, T: 14080, Avg. loss: 2.422828\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 1.07, NNZs: 44, Bias: -2.937955, T: 14720, Avg. loss: 2.621666\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 1.04, NNZs: 44, Bias: -2.950331, T: 15360, Avg. loss: 2.301741\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 1.05, NNZs: 44, Bias: -2.963537, T: 16000, Avg. loss: 2.276732\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 1.01, NNZs: 44, Bias: -2.972981, T: 16640, Avg. loss: 1.978905\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 1.03, NNZs: 44, Bias: -2.980866, T: 17280, Avg. loss: 2.065030\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.99, NNZs: 44, Bias: -2.991051, T: 17920, Avg. loss: 1.902420\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.00, NNZs: 44, Bias: -3.000799, T: 18560, Avg. loss: 1.688780\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.00, NNZs: 44, Bias: -3.010344, T: 19200, Avg. loss: 1.746155\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1.01, NNZs: 44, Bias: -3.018024, T: 19840, Avg. loss: 1.738377\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.026440, T: 20480, Avg. loss: 1.826953\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.032298, T: 21120, Avg. loss: 1.469212\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.041144, T: 21760, Avg. loss: 1.603329\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.049891, T: 22400, Avg. loss: 1.556712\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.99, NNZs: 44, Bias: -3.057867, T: 23040, Avg. loss: 1.499409\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.065866, T: 23680, Avg. loss: 1.552223\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.073255, T: 24320, Avg. loss: 1.350029\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.079636, T: 24960, Avg. loss: 1.202499\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.96, NNZs: 44, Bias: -3.085880, T: 25600, Avg. loss: 1.325216\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.96, NNZs: 44, Bias: -3.091427, T: 26240, Avg. loss: 1.228914\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.096794, T: 26880, Avg. loss: 1.123186\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.102410, T: 27520, Avg. loss: 1.207042\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.108396, T: 28160, Avg. loss: 1.183111\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.115113, T: 28800, Avg. loss: 1.183820\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.120594, T: 29440, Avg. loss: 1.158029\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.127762, T: 30080, Avg. loss: 1.112647\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.132704, T: 30720, Avg. loss: 0.996212\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.137911, T: 31360, Avg. loss: 0.994590\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.93, NNZs: 44, Bias: -3.142994, T: 32000, Avg. loss: 1.090287\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.93, NNZs: 44, Bias: -3.147777, T: 32640, Avg. loss: 0.860229\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.151914, T: 33280, Avg. loss: 0.912170\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.93, NNZs: 44, Bias: -3.157041, T: 33920, Avg. loss: 0.980728\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.161423, T: 34560, Avg. loss: 0.904690\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.165488, T: 35200, Avg. loss: 0.944352\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.170430, T: 35840, Avg. loss: 0.842694\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.174331, T: 36480, Avg. loss: 0.944322\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.178124, T: 37120, Avg. loss: 0.781941\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.181930, T: 37760, Avg. loss: 0.884373\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.187088, T: 38400, Avg. loss: 0.870619\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.90, NNZs: 44, Bias: -3.190889, T: 39040, Avg. loss: 0.779619\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.90, NNZs: 44, Bias: -3.194808, T: 39680, Avg. loss: 0.654711\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.90, NNZs: 44, Bias: -3.198546, T: 40320, Avg. loss: 0.780250\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.89, NNZs: 44, Bias: -3.201925, T: 40960, Avg. loss: 0.800828\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.89, NNZs: 44, Bias: -3.205871, T: 41600, Avg. loss: 0.675419\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.89, NNZs: 44, Bias: -3.209167, T: 42240, Avg. loss: 0.707917\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.213082, T: 42880, Avg. loss: 0.645659\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.216838, T: 43520, Avg. loss: 0.806701\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.219861, T: 44160, Avg. loss: 0.591332\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.223250, T: 44800, Avg. loss: 0.737523\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.226684, T: 45440, Avg. loss: 0.697447\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.87, NNZs: 44, Bias: -3.229653, T: 46080, Avg. loss: 0.670614\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.87, NNZs: 44, Bias: -3.232981, T: 46720, Avg. loss: 0.653457\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.87, NNZs: 44, Bias: -3.236241, T: 47360, Avg. loss: 0.691059\n",
      "Total training time: 0.09 seconds.\n",
      "Convergence after 74 epochs took 0.09 seconds\n",
      "--- training time 0.09561800956726074 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 6.35, NNZs: 44, Bias: -1.994673, T: 640, Avg. loss: 189.614785\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.05, NNZs: 44, Bias: -2.217508, T: 1280, Avg. loss: 40.077763\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3.12, NNZs: 44, Bias: -2.340662, T: 1920, Avg. loss: 23.614151\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.03, NNZs: 44, Bias: -2.422736, T: 2560, Avg. loss: 19.441969\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.59, NNZs: 44, Bias: -2.496541, T: 3200, Avg. loss: 13.700437\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.98, NNZs: 44, Bias: -2.541821, T: 3840, Avg. loss: 10.579633\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.45, NNZs: 44, Bias: -2.583415, T: 4480, Avg. loss: 9.411084\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.40, NNZs: 44, Bias: -2.630032, T: 5120, Avg. loss: 8.216800\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.50, NNZs: 44, Bias: -2.663326, T: 5760, Avg. loss: 7.242535\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.36, NNZs: 44, Bias: -2.692023, T: 6400, Avg. loss: 5.980278\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.29, NNZs: 44, Bias: -2.721187, T: 7040, Avg. loss: 5.348994\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.22, NNZs: 44, Bias: -2.743549, T: 7680, Avg. loss: 4.803177\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1.12, NNZs: 44, Bias: -2.768479, T: 8320, Avg. loss: 4.859873\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1.13, NNZs: 44, Bias: -2.788927, T: 8960, Avg. loss: 4.464438\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1.08, NNZs: 44, Bias: -2.811251, T: 9600, Avg. loss: 4.280645\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1.15, NNZs: 44, Bias: -2.830171, T: 10240, Avg. loss: 3.587939\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1.08, NNZs: 44, Bias: -2.848824, T: 10880, Avg. loss: 2.990107\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1.10, NNZs: 44, Bias: -2.867765, T: 11520, Avg. loss: 3.350379\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 1.05, NNZs: 44, Bias: -2.884974, T: 12160, Avg. loss: 3.444854\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.04, NNZs: 44, Bias: -2.900045, T: 12800, Avg. loss: 2.998987\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.10, NNZs: 44, Bias: -2.915230, T: 13440, Avg. loss: 2.910877\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 1.03, NNZs: 44, Bias: -2.927017, T: 14080, Avg. loss: 2.422828\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 1.07, NNZs: 44, Bias: -2.937955, T: 14720, Avg. loss: 2.621666\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 1.04, NNZs: 44, Bias: -2.950331, T: 15360, Avg. loss: 2.301741\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 1.05, NNZs: 44, Bias: -2.963537, T: 16000, Avg. loss: 2.276732\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 1.01, NNZs: 44, Bias: -2.972981, T: 16640, Avg. loss: 1.978905\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 1.03, NNZs: 44, Bias: -2.980866, T: 17280, Avg. loss: 2.065030\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.99, NNZs: 44, Bias: -2.991051, T: 17920, Avg. loss: 1.902420\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.00, NNZs: 44, Bias: -3.000799, T: 18560, Avg. loss: 1.688780\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.00, NNZs: 44, Bias: -3.010344, T: 19200, Avg. loss: 1.746155\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1.01, NNZs: 44, Bias: -3.018024, T: 19840, Avg. loss: 1.738377\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.026440, T: 20480, Avg. loss: 1.826953\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.032298, T: 21120, Avg. loss: 1.469212\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.041144, T: 21760, Avg. loss: 1.603329\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.049891, T: 22400, Avg. loss: 1.556712\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.99, NNZs: 44, Bias: -3.057867, T: 23040, Avg. loss: 1.499409\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.065866, T: 23680, Avg. loss: 1.552223\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.073255, T: 24320, Avg. loss: 1.350029\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.079636, T: 24960, Avg. loss: 1.202499\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.96, NNZs: 44, Bias: -3.085880, T: 25600, Avg. loss: 1.325216\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.96, NNZs: 44, Bias: -3.091427, T: 26240, Avg. loss: 1.228914\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.096794, T: 26880, Avg. loss: 1.123186\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.102410, T: 27520, Avg. loss: 1.207042\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.108396, T: 28160, Avg. loss: 1.183111\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.115113, T: 28800, Avg. loss: 1.183820\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.120594, T: 29440, Avg. loss: 1.158029\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.127762, T: 30080, Avg. loss: 1.112647\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.132704, T: 30720, Avg. loss: 0.996212\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.137911, T: 31360, Avg. loss: 0.994590\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.93, NNZs: 44, Bias: -3.142994, T: 32000, Avg. loss: 1.090287\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.93, NNZs: 44, Bias: -3.147777, T: 32640, Avg. loss: 0.860229\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.151914, T: 33280, Avg. loss: 0.912170\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.93, NNZs: 44, Bias: -3.157041, T: 33920, Avg. loss: 0.980728\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.161423, T: 34560, Avg. loss: 0.904690\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.165488, T: 35200, Avg. loss: 0.944352\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.170430, T: 35840, Avg. loss: 0.842694\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.174331, T: 36480, Avg. loss: 0.944322\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.178124, T: 37120, Avg. loss: 0.781941\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.181930, T: 37760, Avg. loss: 0.884373\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.187088, T: 38400, Avg. loss: 0.870619\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.90, NNZs: 44, Bias: -3.190889, T: 39040, Avg. loss: 0.779619\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.90, NNZs: 44, Bias: -3.194808, T: 39680, Avg. loss: 0.654711\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.90, NNZs: 44, Bias: -3.198546, T: 40320, Avg. loss: 0.780250\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.89, NNZs: 44, Bias: -3.201925, T: 40960, Avg. loss: 0.800828\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.89, NNZs: 44, Bias: -3.205871, T: 41600, Avg. loss: 0.675419\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.89, NNZs: 44, Bias: -3.209167, T: 42240, Avg. loss: 0.707917\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.213082, T: 42880, Avg. loss: 0.645659\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.216838, T: 43520, Avg. loss: 0.806701\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.219861, T: 44160, Avg. loss: 0.591332\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.223250, T: 44800, Avg. loss: 0.737523\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.226684, T: 45440, Avg. loss: 0.697447\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.87, NNZs: 44, Bias: -3.229653, T: 46080, Avg. loss: 0.670614\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.87, NNZs: 44, Bias: -3.232981, T: 46720, Avg. loss: 0.653457\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.87, NNZs: 44, Bias: -3.236241, T: 47360, Avg. loss: 0.691059\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 74 epochs took 0.02 seconds\n",
      "--- training time 0.02172398567199707 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 6.35, NNZs: 44, Bias: -1.994673, T: 640, Avg. loss: 189.614785\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.05, NNZs: 44, Bias: -2.217508, T: 1280, Avg. loss: 40.077763\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3.12, NNZs: 44, Bias: -2.340662, T: 1920, Avg. loss: 23.614151\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.03, NNZs: 44, Bias: -2.422736, T: 2560, Avg. loss: 19.441969\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.59, NNZs: 44, Bias: -2.496541, T: 3200, Avg. loss: 13.700437\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.98, NNZs: 44, Bias: -2.541821, T: 3840, Avg. loss: 10.579633\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.45, NNZs: 44, Bias: -2.583415, T: 4480, Avg. loss: 9.411084\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.40, NNZs: 44, Bias: -2.630032, T: 5120, Avg. loss: 8.216800\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.50, NNZs: 44, Bias: -2.663326, T: 5760, Avg. loss: 7.242535\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.36, NNZs: 44, Bias: -2.692023, T: 6400, Avg. loss: 5.980278\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.29, NNZs: 44, Bias: -2.721187, T: 7040, Avg. loss: 5.348994\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.22, NNZs: 44, Bias: -2.743549, T: 7680, Avg. loss: 4.803177\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1.12, NNZs: 44, Bias: -2.768479, T: 8320, Avg. loss: 4.859873\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1.13, NNZs: 44, Bias: -2.788927, T: 8960, Avg. loss: 4.464438\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1.08, NNZs: 44, Bias: -2.811251, T: 9600, Avg. loss: 4.280645\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1.15, NNZs: 44, Bias: -2.830171, T: 10240, Avg. loss: 3.587939\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1.08, NNZs: 44, Bias: -2.848824, T: 10880, Avg. loss: 2.990107\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1.10, NNZs: 44, Bias: -2.867765, T: 11520, Avg. loss: 3.350379\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 1.05, NNZs: 44, Bias: -2.884974, T: 12160, Avg. loss: 3.444854\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.04, NNZs: 44, Bias: -2.900045, T: 12800, Avg. loss: 2.998987\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.10, NNZs: 44, Bias: -2.915230, T: 13440, Avg. loss: 2.910877\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 1.03, NNZs: 44, Bias: -2.927017, T: 14080, Avg. loss: 2.422828\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 1.07, NNZs: 44, Bias: -2.937955, T: 14720, Avg. loss: 2.621666\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 1.04, NNZs: 44, Bias: -2.950331, T: 15360, Avg. loss: 2.301741\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 1.05, NNZs: 44, Bias: -2.963537, T: 16000, Avg. loss: 2.276732\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 1.01, NNZs: 44, Bias: -2.972981, T: 16640, Avg. loss: 1.978905\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 1.03, NNZs: 44, Bias: -2.980866, T: 17280, Avg. loss: 2.065030\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.99, NNZs: 44, Bias: -2.991051, T: 17920, Avg. loss: 1.902420\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.00, NNZs: 44, Bias: -3.000799, T: 18560, Avg. loss: 1.688780\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.00, NNZs: 44, Bias: -3.010344, T: 19200, Avg. loss: 1.746155\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1.01, NNZs: 44, Bias: -3.018024, T: 19840, Avg. loss: 1.738377\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.026440, T: 20480, Avg. loss: 1.826953\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.032298, T: 21120, Avg. loss: 1.469212\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.041144, T: 21760, Avg. loss: 1.603329\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.049891, T: 22400, Avg. loss: 1.556712\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.99, NNZs: 44, Bias: -3.057867, T: 23040, Avg. loss: 1.499409\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.065866, T: 23680, Avg. loss: 1.552223\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.073255, T: 24320, Avg. loss: 1.350029\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.079636, T: 24960, Avg. loss: 1.202499\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.96, NNZs: 44, Bias: -3.085880, T: 25600, Avg. loss: 1.325216\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.96, NNZs: 44, Bias: -3.091427, T: 26240, Avg. loss: 1.228914\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.096794, T: 26880, Avg. loss: 1.123186\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.102410, T: 27520, Avg. loss: 1.207042\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.108396, T: 28160, Avg. loss: 1.183111\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.115113, T: 28800, Avg. loss: 1.183820\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.120594, T: 29440, Avg. loss: 1.158029\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.127762, T: 30080, Avg. loss: 1.112647\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.132704, T: 30720, Avg. loss: 0.996212\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.137911, T: 31360, Avg. loss: 0.994590\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.93, NNZs: 44, Bias: -3.142994, T: 32000, Avg. loss: 1.090287\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.93, NNZs: 44, Bias: -3.147777, T: 32640, Avg. loss: 0.860229\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.151914, T: 33280, Avg. loss: 0.912170\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.93, NNZs: 44, Bias: -3.157041, T: 33920, Avg. loss: 0.980728\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.161423, T: 34560, Avg. loss: 0.904690\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.165488, T: 35200, Avg. loss: 0.944352\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.170430, T: 35840, Avg. loss: 0.842694\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.174331, T: 36480, Avg. loss: 0.944322\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.178124, T: 37120, Avg. loss: 0.781941\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.181930, T: 37760, Avg. loss: 0.884373\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.187088, T: 38400, Avg. loss: 0.870619\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.90, NNZs: 44, Bias: -3.190889, T: 39040, Avg. loss: 0.779619\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.90, NNZs: 44, Bias: -3.194808, T: 39680, Avg. loss: 0.654711\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.90, NNZs: 44, Bias: -3.198546, T: 40320, Avg. loss: 0.780250\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.89, NNZs: 44, Bias: -3.201925, T: 40960, Avg. loss: 0.800828\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.89, NNZs: 44, Bias: -3.205871, T: 41600, Avg. loss: 0.675419\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.89, NNZs: 44, Bias: -3.209167, T: 42240, Avg. loss: 0.707917\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.213082, T: 42880, Avg. loss: 0.645659\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.216838, T: 43520, Avg. loss: 0.806701\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.219861, T: 44160, Avg. loss: 0.591332\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.223250, T: 44800, Avg. loss: 0.737523\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.226684, T: 45440, Avg. loss: 0.697447\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.87, NNZs: 44, Bias: -3.229653, T: 46080, Avg. loss: 0.670614\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.87, NNZs: 44, Bias: -3.232981, T: 46720, Avg. loss: 0.653457\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.87, NNZs: 44, Bias: -3.236241, T: 47360, Avg. loss: 0.691059\n",
      "Total training time: 0.09 seconds.\n",
      "Convergence after 74 epochs took 0.09 seconds\n",
      "--- training time 0.09048914909362793 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 1.81, NNZs: 44, Bias: -0.132429, T: 640, Avg. loss: 30.907784\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.39, NNZs: 44, Bias: -0.188078, T: 1280, Avg. loss: 10.660232\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.25, NNZs: 44, Bias: -0.238202, T: 1920, Avg. loss: 9.212930\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.276557, T: 2560, Avg. loss: 9.238287\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.316699, T: 3200, Avg. loss: 7.258781\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.20, NNZs: 44, Bias: -0.346927, T: 3840, Avg. loss: 6.083062\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.05, NNZs: 44, Bias: -0.377001, T: 4480, Avg. loss: 6.074865\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.405743, T: 5120, Avg. loss: 5.408817\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.05, NNZs: 44, Bias: -0.434407, T: 5760, Avg. loss: 5.172337\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.07, NNZs: 44, Bias: -0.459415, T: 6400, Avg. loss: 4.729603\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.08, NNZs: 44, Bias: -0.484385, T: 7040, Avg. loss: 4.626073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.505227, T: 7680, Avg. loss: 4.504605\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.529476, T: 8320, Avg. loss: 3.886199\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.548966, T: 8960, Avg. loss: 4.488182\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.574013, T: 9600, Avg. loss: 4.301054\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1.06, NNZs: 44, Bias: -0.594354, T: 10240, Avg. loss: 3.785013\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.616599, T: 10880, Avg. loss: 3.399852\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.636243, T: 11520, Avg. loss: 3.280211\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.96, NNZs: 44, Bias: -0.654038, T: 12160, Avg. loss: 3.690596\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.671599, T: 12800, Avg. loss: 3.693993\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.689654, T: 13440, Avg. loss: 3.407431\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.705857, T: 14080, Avg. loss: 2.926440\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.720351, T: 14720, Avg. loss: 3.038130\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.736537, T: 15360, Avg. loss: 3.017863\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.751568, T: 16000, Avg. loss: 2.732331\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.766843, T: 16640, Avg. loss: 2.835467\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.779676, T: 17280, Avg. loss: 2.794700\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.795386, T: 17920, Avg. loss: 2.689158\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.809601, T: 18560, Avg. loss: 2.586526\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.06, NNZs: 44, Bias: -0.827178, T: 19200, Avg. loss: 2.624687\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.839258, T: 19840, Avg. loss: 2.743357\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.852483, T: 20480, Avg. loss: 2.547765\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.862580, T: 21120, Avg. loss: 2.184022\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.875723, T: 21760, Avg. loss: 2.496151\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.890938, T: 22400, Avg. loss: 2.564650\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.904156, T: 23040, Avg. loss: 2.505766\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.917612, T: 23680, Avg. loss: 2.671161\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.930996, T: 24320, Avg. loss: 2.351704\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 38 epochs took 0.01 seconds\n",
      "--- training time 0.015709877014160156 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 1.81, NNZs: 44, Bias: -0.132429, T: 640, Avg. loss: 30.907784\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.39, NNZs: 44, Bias: -0.188078, T: 1280, Avg. loss: 10.660232\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.25, NNZs: 44, Bias: -0.238202, T: 1920, Avg. loss: 9.212930\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.276557, T: 2560, Avg. loss: 9.238287\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.316699, T: 3200, Avg. loss: 7.258781\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.20, NNZs: 44, Bias: -0.346927, T: 3840, Avg. loss: 6.083062\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.05, NNZs: 44, Bias: -0.377001, T: 4480, Avg. loss: 6.074865\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.405743, T: 5120, Avg. loss: 5.408817\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.05, NNZs: 44, Bias: -0.434407, T: 5760, Avg. loss: 5.172337\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.07, NNZs: 44, Bias: -0.459415, T: 6400, Avg. loss: 4.729603\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.08, NNZs: 44, Bias: -0.484385, T: 7040, Avg. loss: 4.626073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.505227, T: 7680, Avg. loss: 4.504605\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.529476, T: 8320, Avg. loss: 3.886199\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.548966, T: 8960, Avg. loss: 4.488182\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.574013, T: 9600, Avg. loss: 4.301054\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1.06, NNZs: 44, Bias: -0.594354, T: 10240, Avg. loss: 3.785013\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.616599, T: 10880, Avg. loss: 3.399852\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.636243, T: 11520, Avg. loss: 3.280211\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.96, NNZs: 44, Bias: -0.654038, T: 12160, Avg. loss: 3.690596\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.671599, T: 12800, Avg. loss: 3.693993\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.689654, T: 13440, Avg. loss: 3.407431\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.705857, T: 14080, Avg. loss: 2.926440\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.720351, T: 14720, Avg. loss: 3.038130\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.736537, T: 15360, Avg. loss: 3.017863\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.751568, T: 16000, Avg. loss: 2.732331\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.766843, T: 16640, Avg. loss: 2.835467\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.779676, T: 17280, Avg. loss: 2.794700\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.795386, T: 17920, Avg. loss: 2.689158\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.809601, T: 18560, Avg. loss: 2.586526\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.06, NNZs: 44, Bias: -0.827178, T: 19200, Avg. loss: 2.624687\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.839258, T: 19840, Avg. loss: 2.743357\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.852483, T: 20480, Avg. loss: 2.547765\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.862580, T: 21120, Avg. loss: 2.184022\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.875723, T: 21760, Avg. loss: 2.496151\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.890938, T: 22400, Avg. loss: 2.564650\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.904156, T: 23040, Avg. loss: 2.505766\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.917612, T: 23680, Avg. loss: 2.671161\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.930996, T: 24320, Avg. loss: 2.351704\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 38 epochs took 0.01 seconds\n",
      "--- training time 0.015790224075317383 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 1.81, NNZs: 44, Bias: -0.132429, T: 640, Avg. loss: 30.907784\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.39, NNZs: 44, Bias: -0.188078, T: 1280, Avg. loss: 10.660232\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.25, NNZs: 44, Bias: -0.238202, T: 1920, Avg. loss: 9.212930\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.276557, T: 2560, Avg. loss: 9.238287\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.316699, T: 3200, Avg. loss: 7.258781\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.20, NNZs: 44, Bias: -0.346927, T: 3840, Avg. loss: 6.083062\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.05, NNZs: 44, Bias: -0.377001, T: 4480, Avg. loss: 6.074865\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.405743, T: 5120, Avg. loss: 5.408817\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.05, NNZs: 44, Bias: -0.434407, T: 5760, Avg. loss: 5.172337\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.07, NNZs: 44, Bias: -0.459415, T: 6400, Avg. loss: 4.729603\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.08, NNZs: 44, Bias: -0.484385, T: 7040, Avg. loss: 4.626073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.505227, T: 7680, Avg. loss: 4.504605\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.529476, T: 8320, Avg. loss: 3.886199\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.548966, T: 8960, Avg. loss: 4.488182\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.574013, T: 9600, Avg. loss: 4.301054\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1.06, NNZs: 44, Bias: -0.594354, T: 10240, Avg. loss: 3.785013\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.616599, T: 10880, Avg. loss: 3.399852\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.636243, T: 11520, Avg. loss: 3.280211\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.96, NNZs: 44, Bias: -0.654038, T: 12160, Avg. loss: 3.690596\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.671599, T: 12800, Avg. loss: 3.693993\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.689654, T: 13440, Avg. loss: 3.407431\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.705857, T: 14080, Avg. loss: 2.926440\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.720351, T: 14720, Avg. loss: 3.038130\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.736537, T: 15360, Avg. loss: 3.017863\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.751568, T: 16000, Avg. loss: 2.732331\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.766843, T: 16640, Avg. loss: 2.835467\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.779676, T: 17280, Avg. loss: 2.794700\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.795386, T: 17920, Avg. loss: 2.689158\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.809601, T: 18560, Avg. loss: 2.586526\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.06, NNZs: 44, Bias: -0.827178, T: 19200, Avg. loss: 2.624687\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.839258, T: 19840, Avg. loss: 2.743357\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.852483, T: 20480, Avg. loss: 2.547765\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.862580, T: 21120, Avg. loss: 2.184022\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.875723, T: 21760, Avg. loss: 2.496151\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.890938, T: 22400, Avg. loss: 2.564650\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.904156, T: 23040, Avg. loss: 2.505766\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.917612, T: 23680, Avg. loss: 2.671161\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.930996, T: 24320, Avg. loss: 2.351704\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 38 epochs took 0.01 seconds\n",
      "--- training time 0.01548004150390625 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 10.91, NNZs: 43, Bias: -2.550009, T: 640, Avg. loss: 402.389039\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.71, NNZs: 44, Bias: -5.050009, T: 1280, Avg. loss: 323.294791\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.46, NNZs: 44, Bias: -7.512515, T: 1920, Avg. loss: 359.311537\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.05, NNZs: 44, Bias: -10.201947, T: 2560, Avg. loss: 399.918189\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.69, NNZs: 44, Bias: -12.720222, T: 3200, Avg. loss: 361.718888\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.91, NNZs: 44, Bias: -14.880795, T: 3840, Avg. loss: 377.351976\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 19.10, NNZs: 44, Bias: -17.180424, T: 4480, Avg. loss: 376.820507\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 5.86, NNZs: 44, Bias: -17.603116, T: 5120, Avg. loss: 83.034376\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 9.02, NNZs: 44, Bias: -18.059716, T: 5760, Avg. loss: 72.589001\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 7.08, NNZs: 44, Bias: -18.459718, T: 6400, Avg. loss: 68.394544\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 7.82, NNZs: 44, Bias: -18.920503, T: 7040, Avg. loss: 75.816719\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 9.16, NNZs: 44, Bias: -19.338538, T: 7680, Avg. loss: 82.091663\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 6.28, NNZs: 44, Bias: -19.866070, T: 8320, Avg. loss: 80.338302\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 8.67, NNZs: 44, Bias: -20.249927, T: 8960, Avg. loss: 77.763763\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 6.72, NNZs: 44, Bias: -20.783372, T: 9600, Avg. loss: 84.528284\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 2.60, NNZs: 44, Bias: -20.831906, T: 10240, Avg. loss: 21.081200\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 2.52, NNZs: 44, Bias: -20.915984, T: 10880, Avg. loss: 13.879038\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 2.16, NNZs: 44, Bias: -20.997294, T: 11520, Avg. loss: 14.867438\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 1.96, NNZs: 44, Bias: -21.073347, T: 12160, Avg. loss: 15.247984\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.67, NNZs: 44, Bias: -21.147747, T: 12800, Avg. loss: 15.697421\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.95, NNZs: 44, Bias: -21.221151, T: 13440, Avg. loss: 15.912261\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 1.86, NNZs: 44, Bias: -21.289947, T: 14080, Avg. loss: 13.323098\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 2.05, NNZs: 44, Bias: -21.355879, T: 14720, Avg. loss: 15.670591\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 2.38, NNZs: 44, Bias: -21.439276, T: 15360, Avg. loss: 14.048558\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 2.40, NNZs: 44, Bias: -21.531538, T: 16000, Avg. loss: 15.405405\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 1.73, NNZs: 44, Bias: -21.595660, T: 16640, Avg. loss: 15.098512\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 2.46, NNZs: 44, Bias: -21.656147, T: 17280, Avg. loss: 14.324409\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1.48, NNZs: 44, Bias: -21.665591, T: 17920, Avg. loss: 5.804966\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.08, NNZs: 44, Bias: -21.673279, T: 18560, Avg. loss: 2.931253\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.02, NNZs: 44, Bias: -21.683801, T: 19200, Avg. loss: 2.375622\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.99, NNZs: 44, Bias: -21.692709, T: 19840, Avg. loss: 2.414061\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.95, NNZs: 44, Bias: -21.702718, T: 20480, Avg. loss: 2.667215\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.95, NNZs: 44, Bias: -21.708766, T: 21120, Avg. loss: 2.440674\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.720001, T: 21760, Avg. loss: 2.313048\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.732348, T: 22400, Avg. loss: 2.643310\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.742019, T: 23040, Avg. loss: 2.435969\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.90, NNZs: 44, Bias: -21.752661, T: 23680, Avg. loss: 2.758176\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.90, NNZs: 44, Bias: -21.763259, T: 24320, Avg. loss: 2.249982\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.91, NNZs: 44, Bias: -21.772147, T: 24960, Avg. loss: 2.264457\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.89, NNZs: 44, Bias: -21.780717, T: 25600, Avg. loss: 2.408183\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.87, NNZs: 44, Bias: -21.788835, T: 26240, Avg. loss: 2.288684\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.86, NNZs: 44, Bias: -21.796010, T: 26880, Avg. loss: 2.150486\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.88, NNZs: 44, Bias: -21.804099, T: 27520, Avg. loss: 2.213629\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.84, NNZs: 44, Bias: -21.813593, T: 28160, Avg. loss: 2.698464\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.85, NNZs: 44, Bias: -21.824923, T: 28800, Avg. loss: 2.531753\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.86, NNZs: 44, Bias: -21.835083, T: 29440, Avg. loss: 2.314919\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.87, NNZs: 44, Bias: -21.847257, T: 30080, Avg. loss: 2.572171\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.83, NNZs: 44, Bias: -21.847102, T: 30720, Avg. loss: 0.727465\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.81, NNZs: 44, Bias: -21.847476, T: 31360, Avg. loss: 0.394332\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.81, NNZs: 44, Bias: -21.847750, T: 32000, Avg. loss: 0.347348\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.80, NNZs: 44, Bias: -21.848207, T: 32640, Avg. loss: 0.294411\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.79, NNZs: 44, Bias: -21.848611, T: 33280, Avg. loss: 0.313080\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.78, NNZs: 44, Bias: -21.849179, T: 33920, Avg. loss: 0.338814\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.78, NNZs: 44, Bias: -21.849595, T: 34560, Avg. loss: 0.311426\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.77, NNZs: 44, Bias: -21.850114, T: 35200, Avg. loss: 0.278903\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.76, NNZs: 44, Bias: -21.850544, T: 35840, Avg. loss: 0.323347\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.76, NNZs: 44, Bias: -21.850999, T: 36480, Avg. loss: 0.285556\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.75, NNZs: 44, Bias: -21.851467, T: 37120, Avg. loss: 0.311541\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.75, NNZs: 44, Bias: -21.851826, T: 37760, Avg. loss: 0.333364\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.75, NNZs: 44, Bias: -21.852213, T: 38400, Avg. loss: 0.332154\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852266, T: 39040, Avg. loss: 0.133484\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852265, T: 39680, Avg. loss: 0.124933\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852264, T: 40320, Avg. loss: 0.134122\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852245, T: 40960, Avg. loss: 0.124002\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852247, T: 41600, Avg. loss: 0.126805\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852262, T: 42240, Avg. loss: 0.126852\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852263, T: 42880, Avg. loss: 0.125756\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852229, T: 43520, Avg. loss: 0.106021\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852226, T: 44160, Avg. loss: 0.103396\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852218, T: 44800, Avg. loss: 0.104170\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852229, T: 45440, Avg. loss: 0.105322\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852224, T: 46080, Avg. loss: 0.105754\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852236, T: 46720, Avg. loss: 0.101491\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852229, T: 47360, Avg. loss: 0.104941\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852214, T: 48000, Avg. loss: 0.105051\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852213, T: 48640, Avg. loss: 0.105558\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852203, T: 49280, Avg. loss: 0.104789\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852202, T: 49920, Avg. loss: 0.104441\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 50560, Avg. loss: 0.100782\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 51200, Avg. loss: 0.100245\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852208, T: 51840, Avg. loss: 0.100183\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 52480, Avg. loss: 0.100279\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852208, T: 53120, Avg. loss: 0.099715\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852208, T: 53760, Avg. loss: 0.099310\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 54400, Avg. loss: 0.099242\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 55040, Avg. loss: 0.099155\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852206, T: 55680, Avg. loss: 0.099177\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852206, T: 56320, Avg. loss: 0.099165\n",
      "Total training time: 0.06 seconds.\n",
      "Convergence after 88 epochs took 0.06 seconds\n",
      "--- training time 0.0633699893951416 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 10.91, NNZs: 43, Bias: -2.550009, T: 640, Avg. loss: 402.389039\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.71, NNZs: 44, Bias: -5.050009, T: 1280, Avg. loss: 323.294791\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.46, NNZs: 44, Bias: -7.512515, T: 1920, Avg. loss: 359.311537\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.05, NNZs: 44, Bias: -10.201947, T: 2560, Avg. loss: 399.918189\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.69, NNZs: 44, Bias: -12.720222, T: 3200, Avg. loss: 361.718888\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.91, NNZs: 44, Bias: -14.880795, T: 3840, Avg. loss: 377.351976\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 19.10, NNZs: 44, Bias: -17.180424, T: 4480, Avg. loss: 376.820507\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 5.86, NNZs: 44, Bias: -17.603116, T: 5120, Avg. loss: 83.034376\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 9.02, NNZs: 44, Bias: -18.059716, T: 5760, Avg. loss: 72.589001\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 7.08, NNZs: 44, Bias: -18.459718, T: 6400, Avg. loss: 68.394544\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 7.82, NNZs: 44, Bias: -18.920503, T: 7040, Avg. loss: 75.816719\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 9.16, NNZs: 44, Bias: -19.338538, T: 7680, Avg. loss: 82.091663\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 6.28, NNZs: 44, Bias: -19.866070, T: 8320, Avg. loss: 80.338302\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 8.67, NNZs: 44, Bias: -20.249927, T: 8960, Avg. loss: 77.763763\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 6.72, NNZs: 44, Bias: -20.783372, T: 9600, Avg. loss: 84.528284\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 2.60, NNZs: 44, Bias: -20.831906, T: 10240, Avg. loss: 21.081200\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 2.52, NNZs: 44, Bias: -20.915984, T: 10880, Avg. loss: 13.879038\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 2.16, NNZs: 44, Bias: -20.997294, T: 11520, Avg. loss: 14.867438\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 1.96, NNZs: 44, Bias: -21.073347, T: 12160, Avg. loss: 15.247984\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.67, NNZs: 44, Bias: -21.147747, T: 12800, Avg. loss: 15.697421\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.95, NNZs: 44, Bias: -21.221151, T: 13440, Avg. loss: 15.912261\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 1.86, NNZs: 44, Bias: -21.289947, T: 14080, Avg. loss: 13.323098\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 2.05, NNZs: 44, Bias: -21.355879, T: 14720, Avg. loss: 15.670591\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 2.38, NNZs: 44, Bias: -21.439276, T: 15360, Avg. loss: 14.048558\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 2.40, NNZs: 44, Bias: -21.531538, T: 16000, Avg. loss: 15.405405\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 1.73, NNZs: 44, Bias: -21.595660, T: 16640, Avg. loss: 15.098512\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 2.46, NNZs: 44, Bias: -21.656147, T: 17280, Avg. loss: 14.324409\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1.48, NNZs: 44, Bias: -21.665591, T: 17920, Avg. loss: 5.804966\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.08, NNZs: 44, Bias: -21.673279, T: 18560, Avg. loss: 2.931253\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.02, NNZs: 44, Bias: -21.683801, T: 19200, Avg. loss: 2.375622\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.99, NNZs: 44, Bias: -21.692709, T: 19840, Avg. loss: 2.414061\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.95, NNZs: 44, Bias: -21.702718, T: 20480, Avg. loss: 2.667215\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.95, NNZs: 44, Bias: -21.708766, T: 21120, Avg. loss: 2.440674\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.720001, T: 21760, Avg. loss: 2.313048\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.732348, T: 22400, Avg. loss: 2.643310\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.742019, T: 23040, Avg. loss: 2.435969\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.90, NNZs: 44, Bias: -21.752661, T: 23680, Avg. loss: 2.758176\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.90, NNZs: 44, Bias: -21.763259, T: 24320, Avg. loss: 2.249982\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.91, NNZs: 44, Bias: -21.772147, T: 24960, Avg. loss: 2.264457\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.89, NNZs: 44, Bias: -21.780717, T: 25600, Avg. loss: 2.408183\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.87, NNZs: 44, Bias: -21.788835, T: 26240, Avg. loss: 2.288684\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.86, NNZs: 44, Bias: -21.796010, T: 26880, Avg. loss: 2.150486\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.88, NNZs: 44, Bias: -21.804099, T: 27520, Avg. loss: 2.213629\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.84, NNZs: 44, Bias: -21.813593, T: 28160, Avg. loss: 2.698464\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.85, NNZs: 44, Bias: -21.824923, T: 28800, Avg. loss: 2.531753\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.86, NNZs: 44, Bias: -21.835083, T: 29440, Avg. loss: 2.314919\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.87, NNZs: 44, Bias: -21.847257, T: 30080, Avg. loss: 2.572171\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.83, NNZs: 44, Bias: -21.847102, T: 30720, Avg. loss: 0.727465\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.81, NNZs: 44, Bias: -21.847476, T: 31360, Avg. loss: 0.394332\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.81, NNZs: 44, Bias: -21.847750, T: 32000, Avg. loss: 0.347348\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.80, NNZs: 44, Bias: -21.848207, T: 32640, Avg. loss: 0.294411\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.79, NNZs: 44, Bias: -21.848611, T: 33280, Avg. loss: 0.313080\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.78, NNZs: 44, Bias: -21.849179, T: 33920, Avg. loss: 0.338814\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.78, NNZs: 44, Bias: -21.849595, T: 34560, Avg. loss: 0.311426\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.77, NNZs: 44, Bias: -21.850114, T: 35200, Avg. loss: 0.278903\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.76, NNZs: 44, Bias: -21.850544, T: 35840, Avg. loss: 0.323347\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.76, NNZs: 44, Bias: -21.850999, T: 36480, Avg. loss: 0.285556\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.75, NNZs: 44, Bias: -21.851467, T: 37120, Avg. loss: 0.311541\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.75, NNZs: 44, Bias: -21.851826, T: 37760, Avg. loss: 0.333364\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.75, NNZs: 44, Bias: -21.852213, T: 38400, Avg. loss: 0.332154\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852266, T: 39040, Avg. loss: 0.133484\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852265, T: 39680, Avg. loss: 0.124933\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852264, T: 40320, Avg. loss: 0.134122\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852245, T: 40960, Avg. loss: 0.124002\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852247, T: 41600, Avg. loss: 0.126805\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852262, T: 42240, Avg. loss: 0.126852\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852263, T: 42880, Avg. loss: 0.125756\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852229, T: 43520, Avg. loss: 0.106021\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852226, T: 44160, Avg. loss: 0.103396\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852218, T: 44800, Avg. loss: 0.104170\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852229, T: 45440, Avg. loss: 0.105322\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852224, T: 46080, Avg. loss: 0.105754\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852236, T: 46720, Avg. loss: 0.101491\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852229, T: 47360, Avg. loss: 0.104941\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852214, T: 48000, Avg. loss: 0.105051\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852213, T: 48640, Avg. loss: 0.105558\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852203, T: 49280, Avg. loss: 0.104789\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852202, T: 49920, Avg. loss: 0.104441\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 50560, Avg. loss: 0.100782\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 51200, Avg. loss: 0.100245\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852208, T: 51840, Avg. loss: 0.100183\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 52480, Avg. loss: 0.100279\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852208, T: 53120, Avg. loss: 0.099715\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852208, T: 53760, Avg. loss: 0.099310\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 54400, Avg. loss: 0.099242\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 55040, Avg. loss: 0.099155\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852206, T: 55680, Avg. loss: 0.099177\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852206, T: 56320, Avg. loss: 0.099165\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 88 epochs took 0.03 seconds\n",
      "--- training time 0.036850929260253906 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 10.91, NNZs: 43, Bias: -2.550009, T: 640, Avg. loss: 402.389039\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.71, NNZs: 44, Bias: -5.050009, T: 1280, Avg. loss: 323.294791\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.46, NNZs: 44, Bias: -7.512515, T: 1920, Avg. loss: 359.311537\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.05, NNZs: 44, Bias: -10.201947, T: 2560, Avg. loss: 399.918189\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.69, NNZs: 44, Bias: -12.720222, T: 3200, Avg. loss: 361.718888\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.91, NNZs: 44, Bias: -14.880795, T: 3840, Avg. loss: 377.351976\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 19.10, NNZs: 44, Bias: -17.180424, T: 4480, Avg. loss: 376.820507\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 5.86, NNZs: 44, Bias: -17.603116, T: 5120, Avg. loss: 83.034376\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 9.02, NNZs: 44, Bias: -18.059716, T: 5760, Avg. loss: 72.589001\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 7.08, NNZs: 44, Bias: -18.459718, T: 6400, Avg. loss: 68.394544\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 7.82, NNZs: 44, Bias: -18.920503, T: 7040, Avg. loss: 75.816719\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 9.16, NNZs: 44, Bias: -19.338538, T: 7680, Avg. loss: 82.091663\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 6.28, NNZs: 44, Bias: -19.866070, T: 8320, Avg. loss: 80.338302\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 8.67, NNZs: 44, Bias: -20.249927, T: 8960, Avg. loss: 77.763763\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 6.72, NNZs: 44, Bias: -20.783372, T: 9600, Avg. loss: 84.528284\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 2.60, NNZs: 44, Bias: -20.831906, T: 10240, Avg. loss: 21.081200\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 2.52, NNZs: 44, Bias: -20.915984, T: 10880, Avg. loss: 13.879038\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 2.16, NNZs: 44, Bias: -20.997294, T: 11520, Avg. loss: 14.867438\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 1.96, NNZs: 44, Bias: -21.073347, T: 12160, Avg. loss: 15.247984\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.67, NNZs: 44, Bias: -21.147747, T: 12800, Avg. loss: 15.697421\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.95, NNZs: 44, Bias: -21.221151, T: 13440, Avg. loss: 15.912261\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 1.86, NNZs: 44, Bias: -21.289947, T: 14080, Avg. loss: 13.323098\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 2.05, NNZs: 44, Bias: -21.355879, T: 14720, Avg. loss: 15.670591\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 2.38, NNZs: 44, Bias: -21.439276, T: 15360, Avg. loss: 14.048558\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 2.40, NNZs: 44, Bias: -21.531538, T: 16000, Avg. loss: 15.405405\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 1.73, NNZs: 44, Bias: -21.595660, T: 16640, Avg. loss: 15.098512\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 2.46, NNZs: 44, Bias: -21.656147, T: 17280, Avg. loss: 14.324409\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1.48, NNZs: 44, Bias: -21.665591, T: 17920, Avg. loss: 5.804966\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.08, NNZs: 44, Bias: -21.673279, T: 18560, Avg. loss: 2.931253\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.02, NNZs: 44, Bias: -21.683801, T: 19200, Avg. loss: 2.375622\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.99, NNZs: 44, Bias: -21.692709, T: 19840, Avg. loss: 2.414061\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.95, NNZs: 44, Bias: -21.702718, T: 20480, Avg. loss: 2.667215\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.95, NNZs: 44, Bias: -21.708766, T: 21120, Avg. loss: 2.440674\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.720001, T: 21760, Avg. loss: 2.313048\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.732348, T: 22400, Avg. loss: 2.643310\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.742019, T: 23040, Avg. loss: 2.435969\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.90, NNZs: 44, Bias: -21.752661, T: 23680, Avg. loss: 2.758176\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.90, NNZs: 44, Bias: -21.763259, T: 24320, Avg. loss: 2.249982\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.91, NNZs: 44, Bias: -21.772147, T: 24960, Avg. loss: 2.264457\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.89, NNZs: 44, Bias: -21.780717, T: 25600, Avg. loss: 2.408183\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.87, NNZs: 44, Bias: -21.788835, T: 26240, Avg. loss: 2.288684\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.86, NNZs: 44, Bias: -21.796010, T: 26880, Avg. loss: 2.150486\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.88, NNZs: 44, Bias: -21.804099, T: 27520, Avg. loss: 2.213629\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.84, NNZs: 44, Bias: -21.813593, T: 28160, Avg. loss: 2.698464\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.85, NNZs: 44, Bias: -21.824923, T: 28800, Avg. loss: 2.531753\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.86, NNZs: 44, Bias: -21.835083, T: 29440, Avg. loss: 2.314919\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.87, NNZs: 44, Bias: -21.847257, T: 30080, Avg. loss: 2.572171\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.83, NNZs: 44, Bias: -21.847102, T: 30720, Avg. loss: 0.727465\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.81, NNZs: 44, Bias: -21.847476, T: 31360, Avg. loss: 0.394332\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.81, NNZs: 44, Bias: -21.847750, T: 32000, Avg. loss: 0.347348\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.80, NNZs: 44, Bias: -21.848207, T: 32640, Avg. loss: 0.294411\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.79, NNZs: 44, Bias: -21.848611, T: 33280, Avg. loss: 0.313080\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.78, NNZs: 44, Bias: -21.849179, T: 33920, Avg. loss: 0.338814\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.78, NNZs: 44, Bias: -21.849595, T: 34560, Avg. loss: 0.311426\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.77, NNZs: 44, Bias: -21.850114, T: 35200, Avg. loss: 0.278903\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.76, NNZs: 44, Bias: -21.850544, T: 35840, Avg. loss: 0.323347\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.76, NNZs: 44, Bias: -21.850999, T: 36480, Avg. loss: 0.285556\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.75, NNZs: 44, Bias: -21.851467, T: 37120, Avg. loss: 0.311541\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.75, NNZs: 44, Bias: -21.851826, T: 37760, Avg. loss: 0.333364\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.75, NNZs: 44, Bias: -21.852213, T: 38400, Avg. loss: 0.332154\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852266, T: 39040, Avg. loss: 0.133484\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852265, T: 39680, Avg. loss: 0.124933\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852264, T: 40320, Avg. loss: 0.134122\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852245, T: 40960, Avg. loss: 0.124002\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852247, T: 41600, Avg. loss: 0.126805\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852262, T: 42240, Avg. loss: 0.126852\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852263, T: 42880, Avg. loss: 0.125756\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852229, T: 43520, Avg. loss: 0.106021\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852226, T: 44160, Avg. loss: 0.103396\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852218, T: 44800, Avg. loss: 0.104170\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852229, T: 45440, Avg. loss: 0.105322\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852224, T: 46080, Avg. loss: 0.105754\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852236, T: 46720, Avg. loss: 0.101491\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852229, T: 47360, Avg. loss: 0.104941\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852214, T: 48000, Avg. loss: 0.105051\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852213, T: 48640, Avg. loss: 0.105558\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852203, T: 49280, Avg. loss: 0.104789\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852202, T: 49920, Avg. loss: 0.104441\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 50560, Avg. loss: 0.100782\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 51200, Avg. loss: 0.100245\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852208, T: 51840, Avg. loss: 0.100183\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 52480, Avg. loss: 0.100279\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852208, T: 53120, Avg. loss: 0.099715\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852208, T: 53760, Avg. loss: 0.099310\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 54400, Avg. loss: 0.099242\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 55040, Avg. loss: 0.099155\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852206, T: 55680, Avg. loss: 0.099177\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852206, T: 56320, Avg. loss: 0.099165\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 88 epochs took 0.05 seconds\n",
      "--- training time 0.04933905601501465 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.002804, T: 640, Avg. loss: 0.530745\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.004999, T: 1280, Avg. loss: 0.473073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.007353, T: 1920, Avg. loss: 0.477698\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.009563, T: 2560, Avg. loss: 0.526879\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.012097, T: 3200, Avg. loss: 0.492399\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.014273, T: 3840, Avg. loss: 0.483501\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.016534, T: 4480, Avg. loss: 0.501115\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.006300926208496094 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.002804, T: 640, Avg. loss: 0.530745\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.004999, T: 1280, Avg. loss: 0.473073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.007353, T: 1920, Avg. loss: 0.477698\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.009563, T: 2560, Avg. loss: 0.526879\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.012097, T: 3200, Avg. loss: 0.492399\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.014273, T: 3840, Avg. loss: 0.483501\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.016534, T: 4480, Avg. loss: 0.501115\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.00644683837890625 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.002804, T: 640, Avg. loss: 0.530745\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.004999, T: 1280, Avg. loss: 0.473073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.007353, T: 1920, Avg. loss: 0.477698\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.009563, T: 2560, Avg. loss: 0.526879\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.012097, T: 3200, Avg. loss: 0.492399\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.014273, T: 3840, Avg. loss: 0.483501\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.016534, T: 4480, Avg. loss: 0.501115\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.006402730941772461 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 2495.55, NNZs: 40, Bias: -173.243886, T: 640, Avg. loss: 30801.248757\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2050.57, NNZs: 43, Bias: -287.332502, T: 1280, Avg. loss: 18969.702448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1652.84, NNZs: 43, Bias: -367.519263, T: 1920, Avg. loss: 14798.941977\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1456.19, NNZs: 43, Bias: -429.450141, T: 2560, Avg. loss: 13148.500053\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1381.34, NNZs: 43, Bias: -483.250401, T: 3200, Avg. loss: 10270.942512\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1567.17, NNZs: 43, Bias: -522.966221, T: 3840, Avg. loss: 8722.036104\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1079.76, NNZs: 43, Bias: -553.762673, T: 4480, Avg. loss: 7476.517176\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1214.10, NNZs: 43, Bias: -595.186474, T: 5120, Avg. loss: 6678.600067\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1278.12, NNZs: 44, Bias: -624.695637, T: 5760, Avg. loss: 5915.409154\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1285.32, NNZs: 44, Bias: -651.612881, T: 6400, Avg. loss: 5752.807953\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1139.73, NNZs: 44, Bias: -675.035744, T: 7040, Avg. loss: 4983.009927\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1112.20, NNZs: 44, Bias: -692.915017, T: 7680, Avg. loss: 4710.982586\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1033.57, NNZs: 44, Bias: -716.356350, T: 8320, Avg. loss: 4034.006958\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 949.86, NNZs: 44, Bias: -735.998619, T: 8960, Avg. loss: 4552.730168\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1030.75, NNZs: 44, Bias: -758.365883, T: 9600, Avg. loss: 4016.078415\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 988.92, NNZs: 44, Bias: -775.763258, T: 10240, Avg. loss: 3432.888311\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1039.65, NNZs: 44, Bias: -792.294392, T: 10880, Avg. loss: 2936.404461\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1010.74, NNZs: 44, Bias: -806.220773, T: 11520, Avg. loss: 2984.979803\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 974.24, NNZs: 44, Bias: -821.803321, T: 12160, Avg. loss: 3316.948645\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 963.70, NNZs: 44, Bias: -835.139095, T: 12800, Avg. loss: 2951.386082\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 970.55, NNZs: 44, Bias: -849.324160, T: 13440, Avg. loss: 2989.667011\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 988.25, NNZs: 44, Bias: -861.529135, T: 14080, Avg. loss: 2281.903736\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 987.73, NNZs: 44, Bias: -871.963436, T: 14720, Avg. loss: 2682.600205\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 976.90, NNZs: 44, Bias: -884.481374, T: 15360, Avg. loss: 2330.265429\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 974.74, NNZs: 44, Bias: -895.322019, T: 16000, Avg. loss: 2155.861475\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 950.52, NNZs: 44, Bias: -905.148129, T: 16640, Avg. loss: 2048.901443\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 961.11, NNZs: 44, Bias: -914.615551, T: 17280, Avg. loss: 2048.271031\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 957.22, NNZs: 44, Bias: -926.464267, T: 17920, Avg. loss: 1869.561717\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 950.08, NNZs: 44, Bias: -936.829761, T: 18560, Avg. loss: 1802.534811\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 980.53, NNZs: 44, Bias: -947.912722, T: 19200, Avg. loss: 1866.771309\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 957.39, NNZs: 44, Bias: -954.247734, T: 19840, Avg. loss: 1798.679859\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 950.76, NNZs: 44, Bias: -963.227196, T: 20480, Avg. loss: 1781.657030\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 945.74, NNZs: 44, Bias: -968.739841, T: 21120, Avg. loss: 1624.041529\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 945.61, NNZs: 44, Bias: -977.686627, T: 21760, Avg. loss: 1596.320191\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 954.60, NNZs: 44, Bias: -985.911547, T: 22400, Avg. loss: 1568.622498\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 945.79, NNZs: 44, Bias: -993.914015, T: 23040, Avg. loss: 1572.932396\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 942.78, NNZs: 44, Bias: -1001.726833, T: 23680, Avg. loss: 1601.846946\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 938.02, NNZs: 44, Bias: -1009.316532, T: 24320, Avg. loss: 1452.959411\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 934.07, NNZs: 44, Bias: -1016.737288, T: 24960, Avg. loss: 1278.891445\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 935.74, NNZs: 44, Bias: -1023.199696, T: 25600, Avg. loss: 1403.652975\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 922.73, NNZs: 44, Bias: -1028.397080, T: 26240, Avg. loss: 1359.303331\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 915.36, NNZs: 44, Bias: -1033.470784, T: 26880, Avg. loss: 1196.712144\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 916.26, NNZs: 44, Bias: -1038.435008, T: 27520, Avg. loss: 1333.135925\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 914.79, NNZs: 44, Bias: -1044.330947, T: 28160, Avg. loss: 1226.511264\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 918.79, NNZs: 44, Bias: -1051.136086, T: 28800, Avg. loss: 1205.729002\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 910.75, NNZs: 44, Bias: -1056.290764, T: 29440, Avg. loss: 1067.009941\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 926.65, NNZs: 44, Bias: -1063.128725, T: 30080, Avg. loss: 1190.628791\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 924.57, NNZs: 44, Bias: -1068.861692, T: 30720, Avg. loss: 1049.310080\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 925.09, NNZs: 44, Bias: -1074.160225, T: 31360, Avg. loss: 1110.357461\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 919.66, NNZs: 44, Bias: -1079.057770, T: 32000, Avg. loss: 1148.884431\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 916.19, NNZs: 44, Bias: -1083.860439, T: 32640, Avg. loss: 951.042110\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 904.96, NNZs: 44, Bias: -1088.282155, T: 33280, Avg. loss: 945.939081\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 902.75, NNZs: 44, Bias: -1092.744731, T: 33920, Avg. loss: 1033.170353\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 899.03, NNZs: 44, Bias: -1097.856195, T: 34560, Avg. loss: 979.107370\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 894.86, NNZs: 44, Bias: -1102.313042, T: 35200, Avg. loss: 996.605479\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 912.39, NNZs: 44, Bias: -1107.787375, T: 35840, Avg. loss: 935.173136\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 898.29, NNZs: 44, Bias: -1112.090240, T: 36480, Avg. loss: 923.409901\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 896.24, NNZs: 44, Bias: -1116.319380, T: 37120, Avg. loss: 907.743547\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 897.41, NNZs: 44, Bias: -1120.999807, T: 37760, Avg. loss: 974.755917\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 889.59, NNZs: 44, Bias: -1125.607573, T: 38400, Avg. loss: 903.230092\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 887.86, NNZs: 44, Bias: -1129.644132, T: 39040, Avg. loss: 840.587006\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 886.24, NNZs: 44, Bias: -1133.610148, T: 39680, Avg. loss: 744.851484\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 886.11, NNZs: 44, Bias: -1137.760367, T: 40320, Avg. loss: 794.789842\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 886.62, NNZs: 44, Bias: -1141.358172, T: 40960, Avg. loss: 911.947559\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 887.62, NNZs: 44, Bias: -1145.615043, T: 41600, Avg. loss: 714.642955\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 882.87, NNZs: 44, Bias: -1148.872796, T: 42240, Avg. loss: 762.570822\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 875.14, NNZs: 44, Bias: -1153.008843, T: 42880, Avg. loss: 726.207850\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 877.37, NNZs: 44, Bias: -1156.471768, T: 43520, Avg. loss: 775.719993\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 876.79, NNZs: 44, Bias: -1159.595838, T: 44160, Avg. loss: 707.479024\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 874.91, NNZs: 44, Bias: -1163.553259, T: 44800, Avg. loss: 777.630009\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 870.75, NNZs: 44, Bias: -1166.591431, T: 45440, Avg. loss: 757.268589\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 866.30, NNZs: 44, Bias: -1169.798316, T: 46080, Avg. loss: 758.242938\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 865.10, NNZs: 44, Bias: -1173.174130, T: 46720, Avg. loss: 703.222684\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 865.32, NNZs: 44, Bias: -1176.917043, T: 47360, Avg. loss: 734.025923\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 858.54, NNZs: 44, Bias: -1179.793455, T: 48000, Avg. loss: 695.823355\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 862.10, NNZs: 44, Bias: -1182.836877, T: 48640, Avg. loss: 591.220628\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 857.91, NNZs: 44, Bias: -1185.440426, T: 49280, Avg. loss: 783.068207\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 859.97, NNZs: 44, Bias: -1188.601682, T: 49920, Avg. loss: 626.584526\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 857.29, NNZs: 44, Bias: -1191.921791, T: 50560, Avg. loss: 623.839323\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 856.27, NNZs: 44, Bias: -1194.621243, T: 51200, Avg. loss: 646.226516\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 851.58, NNZs: 44, Bias: -1197.477257, T: 51840, Avg. loss: 640.572277\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 81 epochs took 0.04 seconds\n",
      "--- training time 0.039830923080444336 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 2495.55, NNZs: 40, Bias: -173.243886, T: 640, Avg. loss: 30801.248757\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2050.57, NNZs: 43, Bias: -287.332502, T: 1280, Avg. loss: 18969.702448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1652.84, NNZs: 43, Bias: -367.519263, T: 1920, Avg. loss: 14798.941977\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1456.19, NNZs: 43, Bias: -429.450141, T: 2560, Avg. loss: 13148.500053\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1381.34, NNZs: 43, Bias: -483.250401, T: 3200, Avg. loss: 10270.942512\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1567.17, NNZs: 43, Bias: -522.966221, T: 3840, Avg. loss: 8722.036104\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1079.76, NNZs: 43, Bias: -553.762673, T: 4480, Avg. loss: 7476.517176\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1214.10, NNZs: 43, Bias: -595.186474, T: 5120, Avg. loss: 6678.600067\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1278.12, NNZs: 44, Bias: -624.695637, T: 5760, Avg. loss: 5915.409154\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1285.32, NNZs: 44, Bias: -651.612881, T: 6400, Avg. loss: 5752.807953\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1139.73, NNZs: 44, Bias: -675.035744, T: 7040, Avg. loss: 4983.009927\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1112.20, NNZs: 44, Bias: -692.915017, T: 7680, Avg. loss: 4710.982586\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1033.57, NNZs: 44, Bias: -716.356350, T: 8320, Avg. loss: 4034.006958\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 949.86, NNZs: 44, Bias: -735.998619, T: 8960, Avg. loss: 4552.730168\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1030.75, NNZs: 44, Bias: -758.365883, T: 9600, Avg. loss: 4016.078415\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 988.92, NNZs: 44, Bias: -775.763258, T: 10240, Avg. loss: 3432.888311\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1039.65, NNZs: 44, Bias: -792.294392, T: 10880, Avg. loss: 2936.404461\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1010.74, NNZs: 44, Bias: -806.220773, T: 11520, Avg. loss: 2984.979803\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 974.24, NNZs: 44, Bias: -821.803321, T: 12160, Avg. loss: 3316.948645\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 963.70, NNZs: 44, Bias: -835.139095, T: 12800, Avg. loss: 2951.386082\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 970.55, NNZs: 44, Bias: -849.324160, T: 13440, Avg. loss: 2989.667011\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 988.25, NNZs: 44, Bias: -861.529135, T: 14080, Avg. loss: 2281.903736\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 987.73, NNZs: 44, Bias: -871.963436, T: 14720, Avg. loss: 2682.600205\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 976.90, NNZs: 44, Bias: -884.481374, T: 15360, Avg. loss: 2330.265429\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 974.74, NNZs: 44, Bias: -895.322019, T: 16000, Avg. loss: 2155.861475\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 950.52, NNZs: 44, Bias: -905.148129, T: 16640, Avg. loss: 2048.901443\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 961.11, NNZs: 44, Bias: -914.615551, T: 17280, Avg. loss: 2048.271031\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 957.22, NNZs: 44, Bias: -926.464267, T: 17920, Avg. loss: 1869.561717\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 950.08, NNZs: 44, Bias: -936.829761, T: 18560, Avg. loss: 1802.534811\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 980.53, NNZs: 44, Bias: -947.912722, T: 19200, Avg. loss: 1866.771309\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 957.39, NNZs: 44, Bias: -954.247734, T: 19840, Avg. loss: 1798.679859\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 950.76, NNZs: 44, Bias: -963.227196, T: 20480, Avg. loss: 1781.657030\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 945.74, NNZs: 44, Bias: -968.739841, T: 21120, Avg. loss: 1624.041529\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 945.61, NNZs: 44, Bias: -977.686627, T: 21760, Avg. loss: 1596.320191\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 954.60, NNZs: 44, Bias: -985.911547, T: 22400, Avg. loss: 1568.622498\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 945.79, NNZs: 44, Bias: -993.914015, T: 23040, Avg. loss: 1572.932396\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 942.78, NNZs: 44, Bias: -1001.726833, T: 23680, Avg. loss: 1601.846946\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 938.02, NNZs: 44, Bias: -1009.316532, T: 24320, Avg. loss: 1452.959411\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 934.07, NNZs: 44, Bias: -1016.737288, T: 24960, Avg. loss: 1278.891445\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 935.74, NNZs: 44, Bias: -1023.199696, T: 25600, Avg. loss: 1403.652975\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 922.73, NNZs: 44, Bias: -1028.397080, T: 26240, Avg. loss: 1359.303331\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 915.36, NNZs: 44, Bias: -1033.470784, T: 26880, Avg. loss: 1196.712144\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 916.26, NNZs: 44, Bias: -1038.435008, T: 27520, Avg. loss: 1333.135925\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 914.79, NNZs: 44, Bias: -1044.330947, T: 28160, Avg. loss: 1226.511264\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 918.79, NNZs: 44, Bias: -1051.136086, T: 28800, Avg. loss: 1205.729002\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 910.75, NNZs: 44, Bias: -1056.290764, T: 29440, Avg. loss: 1067.009941\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 926.65, NNZs: 44, Bias: -1063.128725, T: 30080, Avg. loss: 1190.628791\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 924.57, NNZs: 44, Bias: -1068.861692, T: 30720, Avg. loss: 1049.310080\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 925.09, NNZs: 44, Bias: -1074.160225, T: 31360, Avg. loss: 1110.357461\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 919.66, NNZs: 44, Bias: -1079.057770, T: 32000, Avg. loss: 1148.884431\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 916.19, NNZs: 44, Bias: -1083.860439, T: 32640, Avg. loss: 951.042110\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 904.96, NNZs: 44, Bias: -1088.282155, T: 33280, Avg. loss: 945.939081\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 902.75, NNZs: 44, Bias: -1092.744731, T: 33920, Avg. loss: 1033.170353\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 899.03, NNZs: 44, Bias: -1097.856195, T: 34560, Avg. loss: 979.107370\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 894.86, NNZs: 44, Bias: -1102.313042, T: 35200, Avg. loss: 996.605479\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 912.39, NNZs: 44, Bias: -1107.787375, T: 35840, Avg. loss: 935.173136\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 898.29, NNZs: 44, Bias: -1112.090240, T: 36480, Avg. loss: 923.409901\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 896.24, NNZs: 44, Bias: -1116.319380, T: 37120, Avg. loss: 907.743547\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 897.41, NNZs: 44, Bias: -1120.999807, T: 37760, Avg. loss: 974.755917\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 889.59, NNZs: 44, Bias: -1125.607573, T: 38400, Avg. loss: 903.230092\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 887.86, NNZs: 44, Bias: -1129.644132, T: 39040, Avg. loss: 840.587006\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 886.24, NNZs: 44, Bias: -1133.610148, T: 39680, Avg. loss: 744.851484\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 886.11, NNZs: 44, Bias: -1137.760367, T: 40320, Avg. loss: 794.789842\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 886.62, NNZs: 44, Bias: -1141.358172, T: 40960, Avg. loss: 911.947559\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 887.62, NNZs: 44, Bias: -1145.615043, T: 41600, Avg. loss: 714.642955\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 882.87, NNZs: 44, Bias: -1148.872796, T: 42240, Avg. loss: 762.570822\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 875.14, NNZs: 44, Bias: -1153.008843, T: 42880, Avg. loss: 726.207850\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 877.37, NNZs: 44, Bias: -1156.471768, T: 43520, Avg. loss: 775.719993\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 876.79, NNZs: 44, Bias: -1159.595838, T: 44160, Avg. loss: 707.479024\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 874.91, NNZs: 44, Bias: -1163.553259, T: 44800, Avg. loss: 777.630009\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 870.75, NNZs: 44, Bias: -1166.591431, T: 45440, Avg. loss: 757.268589\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 866.30, NNZs: 44, Bias: -1169.798316, T: 46080, Avg. loss: 758.242938\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 865.10, NNZs: 44, Bias: -1173.174130, T: 46720, Avg. loss: 703.222684\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 865.32, NNZs: 44, Bias: -1176.917043, T: 47360, Avg. loss: 734.025923\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 858.54, NNZs: 44, Bias: -1179.793455, T: 48000, Avg. loss: 695.823355\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 862.10, NNZs: 44, Bias: -1182.836877, T: 48640, Avg. loss: 591.220628\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 857.91, NNZs: 44, Bias: -1185.440426, T: 49280, Avg. loss: 783.068207\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 859.97, NNZs: 44, Bias: -1188.601682, T: 49920, Avg. loss: 626.584526\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 857.29, NNZs: 44, Bias: -1191.921791, T: 50560, Avg. loss: 623.839323\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 856.27, NNZs: 44, Bias: -1194.621243, T: 51200, Avg. loss: 646.226516\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 851.58, NNZs: 44, Bias: -1197.477257, T: 51840, Avg. loss: 640.572277\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 81 epochs took 0.03 seconds\n",
      "--- training time 0.03511381149291992 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 2495.55, NNZs: 40, Bias: -173.243886, T: 640, Avg. loss: 30801.248757\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2050.57, NNZs: 43, Bias: -287.332502, T: 1280, Avg. loss: 18969.702448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1652.84, NNZs: 43, Bias: -367.519263, T: 1920, Avg. loss: 14798.941977\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1456.19, NNZs: 43, Bias: -429.450141, T: 2560, Avg. loss: 13148.500053\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1381.34, NNZs: 43, Bias: -483.250401, T: 3200, Avg. loss: 10270.942512\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1567.17, NNZs: 43, Bias: -522.966221, T: 3840, Avg. loss: 8722.036104\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1079.76, NNZs: 43, Bias: -553.762673, T: 4480, Avg. loss: 7476.517176\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1214.10, NNZs: 43, Bias: -595.186474, T: 5120, Avg. loss: 6678.600067\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1278.12, NNZs: 44, Bias: -624.695637, T: 5760, Avg. loss: 5915.409154\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1285.32, NNZs: 44, Bias: -651.612881, T: 6400, Avg. loss: 5752.807953\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1139.73, NNZs: 44, Bias: -675.035744, T: 7040, Avg. loss: 4983.009927\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1112.20, NNZs: 44, Bias: -692.915017, T: 7680, Avg. loss: 4710.982586\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1033.57, NNZs: 44, Bias: -716.356350, T: 8320, Avg. loss: 4034.006958\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 949.86, NNZs: 44, Bias: -735.998619, T: 8960, Avg. loss: 4552.730168\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1030.75, NNZs: 44, Bias: -758.365883, T: 9600, Avg. loss: 4016.078415\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 988.92, NNZs: 44, Bias: -775.763258, T: 10240, Avg. loss: 3432.888311\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1039.65, NNZs: 44, Bias: -792.294392, T: 10880, Avg. loss: 2936.404461\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1010.74, NNZs: 44, Bias: -806.220773, T: 11520, Avg. loss: 2984.979803\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 974.24, NNZs: 44, Bias: -821.803321, T: 12160, Avg. loss: 3316.948645\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 963.70, NNZs: 44, Bias: -835.139095, T: 12800, Avg. loss: 2951.386082\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 970.55, NNZs: 44, Bias: -849.324160, T: 13440, Avg. loss: 2989.667011\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 988.25, NNZs: 44, Bias: -861.529135, T: 14080, Avg. loss: 2281.903736\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 987.73, NNZs: 44, Bias: -871.963436, T: 14720, Avg. loss: 2682.600205\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 976.90, NNZs: 44, Bias: -884.481374, T: 15360, Avg. loss: 2330.265429\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 974.74, NNZs: 44, Bias: -895.322019, T: 16000, Avg. loss: 2155.861475\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 950.52, NNZs: 44, Bias: -905.148129, T: 16640, Avg. loss: 2048.901443\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 961.11, NNZs: 44, Bias: -914.615551, T: 17280, Avg. loss: 2048.271031\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 957.22, NNZs: 44, Bias: -926.464267, T: 17920, Avg. loss: 1869.561717\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 950.08, NNZs: 44, Bias: -936.829761, T: 18560, Avg. loss: 1802.534811\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 980.53, NNZs: 44, Bias: -947.912722, T: 19200, Avg. loss: 1866.771309\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 957.39, NNZs: 44, Bias: -954.247734, T: 19840, Avg. loss: 1798.679859\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 950.76, NNZs: 44, Bias: -963.227196, T: 20480, Avg. loss: 1781.657030\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 945.74, NNZs: 44, Bias: -968.739841, T: 21120, Avg. loss: 1624.041529\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 945.61, NNZs: 44, Bias: -977.686627, T: 21760, Avg. loss: 1596.320191\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 954.60, NNZs: 44, Bias: -985.911547, T: 22400, Avg. loss: 1568.622498\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 945.79, NNZs: 44, Bias: -993.914015, T: 23040, Avg. loss: 1572.932396\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 942.78, NNZs: 44, Bias: -1001.726833, T: 23680, Avg. loss: 1601.846946\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 938.02, NNZs: 44, Bias: -1009.316532, T: 24320, Avg. loss: 1452.959411\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 934.07, NNZs: 44, Bias: -1016.737288, T: 24960, Avg. loss: 1278.891445\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 935.74, NNZs: 44, Bias: -1023.199696, T: 25600, Avg. loss: 1403.652975\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 922.73, NNZs: 44, Bias: -1028.397080, T: 26240, Avg. loss: 1359.303331\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 915.36, NNZs: 44, Bias: -1033.470784, T: 26880, Avg. loss: 1196.712144\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 916.26, NNZs: 44, Bias: -1038.435008, T: 27520, Avg. loss: 1333.135925\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 914.79, NNZs: 44, Bias: -1044.330947, T: 28160, Avg. loss: 1226.511264\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 918.79, NNZs: 44, Bias: -1051.136086, T: 28800, Avg. loss: 1205.729002\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 910.75, NNZs: 44, Bias: -1056.290764, T: 29440, Avg. loss: 1067.009941\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 926.65, NNZs: 44, Bias: -1063.128725, T: 30080, Avg. loss: 1190.628791\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 924.57, NNZs: 44, Bias: -1068.861692, T: 30720, Avg. loss: 1049.310080\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 925.09, NNZs: 44, Bias: -1074.160225, T: 31360, Avg. loss: 1110.357461\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 919.66, NNZs: 44, Bias: -1079.057770, T: 32000, Avg. loss: 1148.884431\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 916.19, NNZs: 44, Bias: -1083.860439, T: 32640, Avg. loss: 951.042110\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 904.96, NNZs: 44, Bias: -1088.282155, T: 33280, Avg. loss: 945.939081\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 902.75, NNZs: 44, Bias: -1092.744731, T: 33920, Avg. loss: 1033.170353\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 899.03, NNZs: 44, Bias: -1097.856195, T: 34560, Avg. loss: 979.107370\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 894.86, NNZs: 44, Bias: -1102.313042, T: 35200, Avg. loss: 996.605479\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 912.39, NNZs: 44, Bias: -1107.787375, T: 35840, Avg. loss: 935.173136\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 898.29, NNZs: 44, Bias: -1112.090240, T: 36480, Avg. loss: 923.409901\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 896.24, NNZs: 44, Bias: -1116.319380, T: 37120, Avg. loss: 907.743547\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 897.41, NNZs: 44, Bias: -1120.999807, T: 37760, Avg. loss: 974.755917\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 889.59, NNZs: 44, Bias: -1125.607573, T: 38400, Avg. loss: 903.230092\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 887.86, NNZs: 44, Bias: -1129.644132, T: 39040, Avg. loss: 840.587006\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 886.24, NNZs: 44, Bias: -1133.610148, T: 39680, Avg. loss: 744.851484\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 886.11, NNZs: 44, Bias: -1137.760367, T: 40320, Avg. loss: 794.789842\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 886.62, NNZs: 44, Bias: -1141.358172, T: 40960, Avg. loss: 911.947559\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 887.62, NNZs: 44, Bias: -1145.615043, T: 41600, Avg. loss: 714.642955\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 882.87, NNZs: 44, Bias: -1148.872796, T: 42240, Avg. loss: 762.570822\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 875.14, NNZs: 44, Bias: -1153.008843, T: 42880, Avg. loss: 726.207850\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 877.37, NNZs: 44, Bias: -1156.471768, T: 43520, Avg. loss: 775.719993\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 876.79, NNZs: 44, Bias: -1159.595838, T: 44160, Avg. loss: 707.479024\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 874.91, NNZs: 44, Bias: -1163.553259, T: 44800, Avg. loss: 777.630009\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 870.75, NNZs: 44, Bias: -1166.591431, T: 45440, Avg. loss: 757.268589\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 866.30, NNZs: 44, Bias: -1169.798316, T: 46080, Avg. loss: 758.242938\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 865.10, NNZs: 44, Bias: -1173.174130, T: 46720, Avg. loss: 703.222684\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 865.32, NNZs: 44, Bias: -1176.917043, T: 47360, Avg. loss: 734.025923\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 858.54, NNZs: 44, Bias: -1179.793455, T: 48000, Avg. loss: 695.823355\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 862.10, NNZs: 44, Bias: -1182.836877, T: 48640, Avg. loss: 591.220628\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 857.91, NNZs: 44, Bias: -1185.440426, T: 49280, Avg. loss: 783.068207\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 859.97, NNZs: 44, Bias: -1188.601682, T: 49920, Avg. loss: 626.584526\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 857.29, NNZs: 44, Bias: -1191.921791, T: 50560, Avg. loss: 623.839323\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 856.27, NNZs: 44, Bias: -1194.621243, T: 51200, Avg. loss: 646.226516\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 851.58, NNZs: 44, Bias: -1197.477257, T: 51840, Avg. loss: 640.572277\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 81 epochs took 0.04 seconds\n",
      "--- training time 0.04031109809875488 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000268, T: 640, Avg. loss: 0.365764\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000371, T: 1280, Avg. loss: 0.356616\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000440, T: 1920, Avg. loss: 0.351156\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000512, T: 2560, Avg. loss: 0.349170\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000571, T: 3200, Avg. loss: 0.344668\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000626, T: 3840, Avg. loss: 0.344730\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000670, T: 4480, Avg. loss: 0.341486\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000723, T: 5120, Avg. loss: 0.340767\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000765, T: 5760, Avg. loss: 0.340707\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000802, T: 6400, Avg. loss: 0.339845\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000839, T: 7040, Avg. loss: 0.338683\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000873, T: 7680, Avg. loss: 0.337827\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000916, T: 8320, Avg. loss: 0.336225\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000941, T: 8960, Avg. loss: 0.336617\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000975, T: 9600, Avg. loss: 0.336643\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001005, T: 10240, Avg. loss: 0.336029\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001040, T: 10880, Avg. loss: 0.334355\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001068, T: 11520, Avg. loss: 0.335234\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001097, T: 12160, Avg. loss: 0.334441\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001120, T: 12800, Avg. loss: 0.334514\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001147, T: 13440, Avg. loss: 0.334017\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001171, T: 14080, Avg. loss: 0.333580\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 22 epochs took 0.01 seconds\n",
      "--- training time 0.014168977737426758 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000268, T: 640, Avg. loss: 0.365764\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000371, T: 1280, Avg. loss: 0.356616\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000440, T: 1920, Avg. loss: 0.351156\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000512, T: 2560, Avg. loss: 0.349170\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000571, T: 3200, Avg. loss: 0.344668\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000626, T: 3840, Avg. loss: 0.344730\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000670, T: 4480, Avg. loss: 0.341486\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000723, T: 5120, Avg. loss: 0.340767\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000765, T: 5760, Avg. loss: 0.340707\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000802, T: 6400, Avg. loss: 0.339845\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000839, T: 7040, Avg. loss: 0.338683\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000873, T: 7680, Avg. loss: 0.337827\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000916, T: 8320, Avg. loss: 0.336225\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000941, T: 8960, Avg. loss: 0.336617\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000975, T: 9600, Avg. loss: 0.336643\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001005, T: 10240, Avg. loss: 0.336029\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001040, T: 10880, Avg. loss: 0.334355\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001068, T: 11520, Avg. loss: 0.335234\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001097, T: 12160, Avg. loss: 0.334441\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001120, T: 12800, Avg. loss: 0.334514\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001147, T: 13440, Avg. loss: 0.334017\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001171, T: 14080, Avg. loss: 0.333580\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 22 epochs took 0.01 seconds\n",
      "--- training time 0.013557910919189453 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000268, T: 640, Avg. loss: 0.365764\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000371, T: 1280, Avg. loss: 0.356616\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000440, T: 1920, Avg. loss: 0.351156\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000512, T: 2560, Avg. loss: 0.349170\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000571, T: 3200, Avg. loss: 0.344668\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000626, T: 3840, Avg. loss: 0.344730\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000670, T: 4480, Avg. loss: 0.341486\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000723, T: 5120, Avg. loss: 0.340767\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000765, T: 5760, Avg. loss: 0.340707\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000802, T: 6400, Avg. loss: 0.339845\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000839, T: 7040, Avg. loss: 0.338683\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000873, T: 7680, Avg. loss: 0.337827\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000916, T: 8320, Avg. loss: 0.336225\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000941, T: 8960, Avg. loss: 0.336617\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000975, T: 9600, Avg. loss: 0.336643\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001005, T: 10240, Avg. loss: 0.336029\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001040, T: 10880, Avg. loss: 0.334355\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001068, T: 11520, Avg. loss: 0.335234\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001097, T: 12160, Avg. loss: 0.334441\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001120, T: 12800, Avg. loss: 0.334514\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001147, T: 13440, Avg. loss: 0.334017\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001171, T: 14080, Avg. loss: 0.333580\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 22 epochs took 0.01 seconds\n",
      "--- training time 0.014646053314208984 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.002804, T: 640, Avg. loss: 0.530745\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.004999, T: 1280, Avg. loss: 0.473073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.007353, T: 1920, Avg. loss: 0.477698\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.009563, T: 2560, Avg. loss: 0.526879\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.012097, T: 3200, Avg. loss: 0.492399\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.014273, T: 3840, Avg. loss: 0.483501\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.016534, T: 4480, Avg. loss: 0.501115\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.016942, T: 5120, Avg. loss: 0.367130\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.017476, T: 5760, Avg. loss: 0.352643\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.017962, T: 6400, Avg. loss: 0.350942\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.018492, T: 7040, Avg. loss: 0.344682\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.018956, T: 7680, Avg. loss: 0.348603\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.019531, T: 8320, Avg. loss: 0.343703\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.019971, T: 8960, Avg. loss: 0.350367\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.020559, T: 9600, Avg. loss: 0.348111\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021010, T: 10240, Avg. loss: 0.348495\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021158, T: 10880, Avg. loss: 0.317506\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021251, T: 11520, Avg. loss: 0.324189\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021362, T: 12160, Avg. loss: 0.320888\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021453, T: 12800, Avg. loss: 0.324178\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021557, T: 13440, Avg. loss: 0.322479\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021656, T: 14080, Avg. loss: 0.321282\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021682, T: 14720, Avg. loss: 0.318814\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021707, T: 15360, Avg. loss: 0.317611\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021731, T: 16000, Avg. loss: 0.317027\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021748, T: 16640, Avg. loss: 0.318004\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021771, T: 17280, Avg. loss: 0.317610\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 27 epochs took 0.01 seconds\n",
      "--- training time 0.016543149948120117 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.002804, T: 640, Avg. loss: 0.530745\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.004999, T: 1280, Avg. loss: 0.473073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.007353, T: 1920, Avg. loss: 0.477698\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.009563, T: 2560, Avg. loss: 0.526879\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.012097, T: 3200, Avg. loss: 0.492399\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.014273, T: 3840, Avg. loss: 0.483501\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.016534, T: 4480, Avg. loss: 0.501115\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.016942, T: 5120, Avg. loss: 0.367130\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.017476, T: 5760, Avg. loss: 0.352643\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.017962, T: 6400, Avg. loss: 0.350942\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.018492, T: 7040, Avg. loss: 0.344682\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.018956, T: 7680, Avg. loss: 0.348603\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.019531, T: 8320, Avg. loss: 0.343703\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.019971, T: 8960, Avg. loss: 0.350367\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.020559, T: 9600, Avg. loss: 0.348111\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021010, T: 10240, Avg. loss: 0.348495\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021158, T: 10880, Avg. loss: 0.317506\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021251, T: 11520, Avg. loss: 0.324189\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021362, T: 12160, Avg. loss: 0.320888\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021453, T: 12800, Avg. loss: 0.324178\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021557, T: 13440, Avg. loss: 0.322479\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021656, T: 14080, Avg. loss: 0.321282\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021682, T: 14720, Avg. loss: 0.318814\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021707, T: 15360, Avg. loss: 0.317611\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021731, T: 16000, Avg. loss: 0.317027\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021748, T: 16640, Avg. loss: 0.318004\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021771, T: 17280, Avg. loss: 0.317610\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 27 epochs took 0.01 seconds\n",
      "--- training time 0.017236948013305664 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.002804, T: 640, Avg. loss: 0.530745\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.004999, T: 1280, Avg. loss: 0.473073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.007353, T: 1920, Avg. loss: 0.477698\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.009563, T: 2560, Avg. loss: 0.526879\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.012097, T: 3200, Avg. loss: 0.492399\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.014273, T: 3840, Avg. loss: 0.483501\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.016534, T: 4480, Avg. loss: 0.501115\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.016942, T: 5120, Avg. loss: 0.367130\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.017476, T: 5760, Avg. loss: 0.352643\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.017962, T: 6400, Avg. loss: 0.350942\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.018492, T: 7040, Avg. loss: 0.344682\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.018956, T: 7680, Avg. loss: 0.348603\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.019531, T: 8320, Avg. loss: 0.343703\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.019971, T: 8960, Avg. loss: 0.350367\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.020559, T: 9600, Avg. loss: 0.348111\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021010, T: 10240, Avg. loss: 0.348495\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021158, T: 10880, Avg. loss: 0.317506\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021251, T: 11520, Avg. loss: 0.324189\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021362, T: 12160, Avg. loss: 0.320888\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021453, T: 12800, Avg. loss: 0.324178\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021557, T: 13440, Avg. loss: 0.322479\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021656, T: 14080, Avg. loss: 0.321282\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021682, T: 14720, Avg. loss: 0.318814\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021707, T: 15360, Avg. loss: 0.317611\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021731, T: 16000, Avg. loss: 0.317027\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021748, T: 16640, Avg. loss: 0.318004\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021771, T: 17280, Avg. loss: 0.317610\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 27 epochs took 0.01 seconds\n",
      "--- training time 0.01568007469177246 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.021067, T: 640, Avg. loss: 3.984145\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.48, NNZs: 44, Bias: -0.040317, T: 1280, Avg. loss: 3.222851\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.059537, T: 1920, Avg. loss: 3.644051\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.50, NNZs: 44, Bias: -0.078804, T: 2560, Avg. loss: 4.137911\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.45, NNZs: 44, Bias: -0.098773, T: 3200, Avg. loss: 3.813206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.74, NNZs: 44, Bias: -0.116994, T: 3840, Avg. loss: 3.862541\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.70, NNZs: 44, Bias: -0.135162, T: 4480, Avg. loss: 3.740942\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.009501934051513672 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.021067, T: 640, Avg. loss: 3.984145\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.48, NNZs: 44, Bias: -0.040317, T: 1280, Avg. loss: 3.222851\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.059537, T: 1920, Avg. loss: 3.644051\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.50, NNZs: 44, Bias: -0.078804, T: 2560, Avg. loss: 4.137911\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.45, NNZs: 44, Bias: -0.098773, T: 3200, Avg. loss: 3.813206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.74, NNZs: 44, Bias: -0.116994, T: 3840, Avg. loss: 3.862541\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.70, NNZs: 44, Bias: -0.135162, T: 4480, Avg. loss: 3.740942\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.008306026458740234 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.021067, T: 640, Avg. loss: 3.984145\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.48, NNZs: 44, Bias: -0.040317, T: 1280, Avg. loss: 3.222851\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.059537, T: 1920, Avg. loss: 3.644051\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.50, NNZs: 44, Bias: -0.078804, T: 2560, Avg. loss: 4.137911\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.45, NNZs: 44, Bias: -0.098773, T: 3200, Avg. loss: 3.813206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.74, NNZs: 44, Bias: -0.116994, T: 3840, Avg. loss: 3.862541\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.70, NNZs: 44, Bias: -0.135162, T: 4480, Avg. loss: 3.740942\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.0071010589599609375 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 500.74, NNZs: 40, Bias: -52.512065, T: 640, Avg. loss: 8966.903966\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 320.78, NNZs: 43, Bias: -72.608925, T: 1280, Avg. loss: 3357.209314\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 230.09, NNZs: 43, Bias: -84.340473, T: 1920, Avg. loss: 2166.524856\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 189.36, NNZs: 43, Bias: -92.661941, T: 2560, Avg. loss: 1764.310331\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 168.40, NNZs: 44, Bias: -99.779847, T: 3200, Avg. loss: 1306.004672\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 202.15, NNZs: 44, Bias: -104.232835, T: 3840, Avg. loss: 995.721480\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 137.92, NNZs: 44, Bias: -108.116835, T: 4480, Avg. loss: 926.979040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 151.23, NNZs: 44, Bias: -112.749757, T: 5120, Avg. loss: 746.909156\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 148.27, NNZs: 44, Bias: -116.665804, T: 5760, Avg. loss: 699.113288\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 153.32, NNZs: 44, Bias: -119.708379, T: 6400, Avg. loss: 599.858419\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 133.29, NNZs: 44, Bias: -122.480550, T: 7040, Avg. loss: 555.386621\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 126.49, NNZs: 44, Bias: -124.739493, T: 7680, Avg. loss: 528.065646\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 117.66, NNZs: 44, Bias: -127.544830, T: 8320, Avg. loss: 475.009744\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 109.57, NNZs: 44, Bias: -129.587971, T: 8960, Avg. loss: 491.862829\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 106.81, NNZs: 44, Bias: -131.703656, T: 9600, Avg. loss: 446.339582\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 112.49, NNZs: 44, Bias: -133.685142, T: 10240, Avg. loss: 363.660773\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 115.80, NNZs: 44, Bias: -135.462435, T: 10880, Avg. loss: 317.797125\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 114.90, NNZs: 44, Bias: -137.127378, T: 11520, Avg. loss: 313.789935\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 105.54, NNZs: 44, Bias: -138.791050, T: 12160, Avg. loss: 348.313547\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 104.84, NNZs: 44, Bias: -140.210565, T: 12800, Avg. loss: 334.727113\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 107.89, NNZs: 44, Bias: -141.560703, T: 13440, Avg. loss: 298.511347\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 100.53, NNZs: 44, Bias: -142.568970, T: 14080, Avg. loss: 257.251948\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 104.61, NNZs: 44, Bias: -143.586413, T: 14720, Avg. loss: 250.219567\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 105.06, NNZs: 44, Bias: -144.970692, T: 15360, Avg. loss: 247.542619\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 100.92, NNZs: 44, Bias: -146.237201, T: 16000, Avg. loss: 248.501058\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 100.15, NNZs: 44, Bias: -147.451414, T: 16640, Avg. loss: 225.751338\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 103.35, NNZs: 44, Bias: -148.561394, T: 17280, Avg. loss: 212.981286\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 100.88, NNZs: 44, Bias: -149.463165, T: 17920, Avg. loss: 191.596918\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 101.96, NNZs: 44, Bias: -150.548571, T: 18560, Avg. loss: 189.725798\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 103.52, NNZs: 44, Bias: -151.611007, T: 19200, Avg. loss: 183.233201\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 102.28, NNZs: 44, Bias: -152.380246, T: 19840, Avg. loss: 201.349287\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 101.43, NNZs: 44, Bias: -153.315040, T: 20480, Avg. loss: 194.863840\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 98.98, NNZs: 44, Bias: -153.983702, T: 21120, Avg. loss: 169.953737\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 98.06, NNZs: 44, Bias: -154.831632, T: 21760, Avg. loss: 173.155293\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 99.43, NNZs: 44, Bias: -155.729074, T: 22400, Avg. loss: 155.416821\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 100.79, NNZs: 44, Bias: -156.597047, T: 23040, Avg. loss: 153.429602\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 97.84, NNZs: 44, Bias: -157.191383, T: 23680, Avg. loss: 159.924902\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 97.13, NNZs: 44, Bias: -157.891737, T: 24320, Avg. loss: 148.308670\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 97.03, NNZs: 44, Bias: -158.613327, T: 24960, Avg. loss: 133.659802\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 96.85, NNZs: 44, Bias: -159.227607, T: 25600, Avg. loss: 145.577644\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 95.71, NNZs: 44, Bias: -159.751561, T: 26240, Avg. loss: 132.080117\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 95.59, NNZs: 44, Bias: -160.375331, T: 26880, Avg. loss: 117.890443\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 96.42, NNZs: 44, Bias: -160.953157, T: 27520, Avg. loss: 134.577507\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 95.09, NNZs: 44, Bias: -161.520962, T: 28160, Avg. loss: 136.019925\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 94.90, NNZs: 44, Bias: -162.150253, T: 28800, Avg. loss: 127.672971\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 94.33, NNZs: 44, Bias: -162.662278, T: 29440, Avg. loss: 127.475931\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 95.54, NNZs: 44, Bias: -163.365363, T: 30080, Avg. loss: 123.089532\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 47 epochs took 0.02 seconds\n",
      "--- training time 0.027438879013061523 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 500.74, NNZs: 40, Bias: -52.512065, T: 640, Avg. loss: 8966.903966\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 320.78, NNZs: 43, Bias: -72.608925, T: 1280, Avg. loss: 3357.209314\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 230.09, NNZs: 43, Bias: -84.340473, T: 1920, Avg. loss: 2166.524856\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 189.36, NNZs: 43, Bias: -92.661941, T: 2560, Avg. loss: 1764.310331\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 168.40, NNZs: 44, Bias: -99.779847, T: 3200, Avg. loss: 1306.004672\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 202.15, NNZs: 44, Bias: -104.232835, T: 3840, Avg. loss: 995.721480\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 137.92, NNZs: 44, Bias: -108.116835, T: 4480, Avg. loss: 926.979040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 151.23, NNZs: 44, Bias: -112.749757, T: 5120, Avg. loss: 746.909156\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 148.27, NNZs: 44, Bias: -116.665804, T: 5760, Avg. loss: 699.113288\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 153.32, NNZs: 44, Bias: -119.708379, T: 6400, Avg. loss: 599.858419\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 133.29, NNZs: 44, Bias: -122.480550, T: 7040, Avg. loss: 555.386621\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 126.49, NNZs: 44, Bias: -124.739493, T: 7680, Avg. loss: 528.065646\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 117.66, NNZs: 44, Bias: -127.544830, T: 8320, Avg. loss: 475.009744\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 109.57, NNZs: 44, Bias: -129.587971, T: 8960, Avg. loss: 491.862829\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 106.81, NNZs: 44, Bias: -131.703656, T: 9600, Avg. loss: 446.339582\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 112.49, NNZs: 44, Bias: -133.685142, T: 10240, Avg. loss: 363.660773\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 115.80, NNZs: 44, Bias: -135.462435, T: 10880, Avg. loss: 317.797125\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 114.90, NNZs: 44, Bias: -137.127378, T: 11520, Avg. loss: 313.789935\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 105.54, NNZs: 44, Bias: -138.791050, T: 12160, Avg. loss: 348.313547\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 104.84, NNZs: 44, Bias: -140.210565, T: 12800, Avg. loss: 334.727113\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 107.89, NNZs: 44, Bias: -141.560703, T: 13440, Avg. loss: 298.511347\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 100.53, NNZs: 44, Bias: -142.568970, T: 14080, Avg. loss: 257.251948\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 104.61, NNZs: 44, Bias: -143.586413, T: 14720, Avg. loss: 250.219567\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 105.06, NNZs: 44, Bias: -144.970692, T: 15360, Avg. loss: 247.542619\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 100.92, NNZs: 44, Bias: -146.237201, T: 16000, Avg. loss: 248.501058\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 100.15, NNZs: 44, Bias: -147.451414, T: 16640, Avg. loss: 225.751338\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 103.35, NNZs: 44, Bias: -148.561394, T: 17280, Avg. loss: 212.981286\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 100.88, NNZs: 44, Bias: -149.463165, T: 17920, Avg. loss: 191.596918\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 101.96, NNZs: 44, Bias: -150.548571, T: 18560, Avg. loss: 189.725798\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 103.52, NNZs: 44, Bias: -151.611007, T: 19200, Avg. loss: 183.233201\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 102.28, NNZs: 44, Bias: -152.380246, T: 19840, Avg. loss: 201.349287\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 101.43, NNZs: 44, Bias: -153.315040, T: 20480, Avg. loss: 194.863840\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 98.98, NNZs: 44, Bias: -153.983702, T: 21120, Avg. loss: 169.953737\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 98.06, NNZs: 44, Bias: -154.831632, T: 21760, Avg. loss: 173.155293\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 99.43, NNZs: 44, Bias: -155.729074, T: 22400, Avg. loss: 155.416821\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 100.79, NNZs: 44, Bias: -156.597047, T: 23040, Avg. loss: 153.429602\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 97.84, NNZs: 44, Bias: -157.191383, T: 23680, Avg. loss: 159.924902\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 97.13, NNZs: 44, Bias: -157.891737, T: 24320, Avg. loss: 148.308670\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 97.03, NNZs: 44, Bias: -158.613327, T: 24960, Avg. loss: 133.659802\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 96.85, NNZs: 44, Bias: -159.227607, T: 25600, Avg. loss: 145.577644\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 95.71, NNZs: 44, Bias: -159.751561, T: 26240, Avg. loss: 132.080117\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 95.59, NNZs: 44, Bias: -160.375331, T: 26880, Avg. loss: 117.890443\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 96.42, NNZs: 44, Bias: -160.953157, T: 27520, Avg. loss: 134.577507\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 95.09, NNZs: 44, Bias: -161.520962, T: 28160, Avg. loss: 136.019925\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 94.90, NNZs: 44, Bias: -162.150253, T: 28800, Avg. loss: 127.672971\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 94.33, NNZs: 44, Bias: -162.662278, T: 29440, Avg. loss: 127.475931\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 95.54, NNZs: 44, Bias: -163.365363, T: 30080, Avg. loss: 123.089532\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 47 epochs took 0.03 seconds\n",
      "--- training time 0.03388786315917969 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 500.74, NNZs: 40, Bias: -52.512065, T: 640, Avg. loss: 8966.903966\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 320.78, NNZs: 43, Bias: -72.608925, T: 1280, Avg. loss: 3357.209314\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 230.09, NNZs: 43, Bias: -84.340473, T: 1920, Avg. loss: 2166.524856\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 189.36, NNZs: 43, Bias: -92.661941, T: 2560, Avg. loss: 1764.310331\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 168.40, NNZs: 44, Bias: -99.779847, T: 3200, Avg. loss: 1306.004672\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 202.15, NNZs: 44, Bias: -104.232835, T: 3840, Avg. loss: 995.721480\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 137.92, NNZs: 44, Bias: -108.116835, T: 4480, Avg. loss: 926.979040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 151.23, NNZs: 44, Bias: -112.749757, T: 5120, Avg. loss: 746.909156\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 148.27, NNZs: 44, Bias: -116.665804, T: 5760, Avg. loss: 699.113288\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 153.32, NNZs: 44, Bias: -119.708379, T: 6400, Avg. loss: 599.858419\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 133.29, NNZs: 44, Bias: -122.480550, T: 7040, Avg. loss: 555.386621\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 126.49, NNZs: 44, Bias: -124.739493, T: 7680, Avg. loss: 528.065646\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 117.66, NNZs: 44, Bias: -127.544830, T: 8320, Avg. loss: 475.009744\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 109.57, NNZs: 44, Bias: -129.587971, T: 8960, Avg. loss: 491.862829\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 106.81, NNZs: 44, Bias: -131.703656, T: 9600, Avg. loss: 446.339582\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 112.49, NNZs: 44, Bias: -133.685142, T: 10240, Avg. loss: 363.660773\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 115.80, NNZs: 44, Bias: -135.462435, T: 10880, Avg. loss: 317.797125\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 114.90, NNZs: 44, Bias: -137.127378, T: 11520, Avg. loss: 313.789935\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 105.54, NNZs: 44, Bias: -138.791050, T: 12160, Avg. loss: 348.313547\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 104.84, NNZs: 44, Bias: -140.210565, T: 12800, Avg. loss: 334.727113\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 107.89, NNZs: 44, Bias: -141.560703, T: 13440, Avg. loss: 298.511347\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 100.53, NNZs: 44, Bias: -142.568970, T: 14080, Avg. loss: 257.251948\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 104.61, NNZs: 44, Bias: -143.586413, T: 14720, Avg. loss: 250.219567\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 105.06, NNZs: 44, Bias: -144.970692, T: 15360, Avg. loss: 247.542619\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 100.92, NNZs: 44, Bias: -146.237201, T: 16000, Avg. loss: 248.501058\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 100.15, NNZs: 44, Bias: -147.451414, T: 16640, Avg. loss: 225.751338\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 103.35, NNZs: 44, Bias: -148.561394, T: 17280, Avg. loss: 212.981286\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 100.88, NNZs: 44, Bias: -149.463165, T: 17920, Avg. loss: 191.596918\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 101.96, NNZs: 44, Bias: -150.548571, T: 18560, Avg. loss: 189.725798\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 103.52, NNZs: 44, Bias: -151.611007, T: 19200, Avg. loss: 183.233201\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 102.28, NNZs: 44, Bias: -152.380246, T: 19840, Avg. loss: 201.349287\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 101.43, NNZs: 44, Bias: -153.315040, T: 20480, Avg. loss: 194.863840\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 98.98, NNZs: 44, Bias: -153.983702, T: 21120, Avg. loss: 169.953737\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 98.06, NNZs: 44, Bias: -154.831632, T: 21760, Avg. loss: 173.155293\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 99.43, NNZs: 44, Bias: -155.729074, T: 22400, Avg. loss: 155.416821\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 100.79, NNZs: 44, Bias: -156.597047, T: 23040, Avg. loss: 153.429602\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 97.84, NNZs: 44, Bias: -157.191383, T: 23680, Avg. loss: 159.924902\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 97.13, NNZs: 44, Bias: -157.891737, T: 24320, Avg. loss: 148.308670\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 97.03, NNZs: 44, Bias: -158.613327, T: 24960, Avg. loss: 133.659802\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 96.85, NNZs: 44, Bias: -159.227607, T: 25600, Avg. loss: 145.577644\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 95.71, NNZs: 44, Bias: -159.751561, T: 26240, Avg. loss: 132.080117\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 95.59, NNZs: 44, Bias: -160.375331, T: 26880, Avg. loss: 117.890443\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 96.42, NNZs: 44, Bias: -160.953157, T: 27520, Avg. loss: 134.577507\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 95.09, NNZs: 44, Bias: -161.520962, T: 28160, Avg. loss: 136.019925\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 94.90, NNZs: 44, Bias: -162.150253, T: 28800, Avg. loss: 127.672971\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 94.33, NNZs: 44, Bias: -162.662278, T: 29440, Avg. loss: 127.475931\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 95.54, NNZs: 44, Bias: -163.365363, T: 30080, Avg. loss: 123.089532\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 47 epochs took 0.03 seconds\n",
      "--- training time 0.03116011619567871 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.04, NNZs: 44, Bias: -0.001716, T: 640, Avg. loss: 0.494289\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.04, NNZs: 44, Bias: -0.002572, T: 1280, Avg. loss: 0.364677\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.003237, T: 1920, Avg. loss: 0.349521\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.003750, T: 2560, Avg. loss: 0.365191\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.004277, T: 3200, Avg. loss: 0.343723\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.004730, T: 3840, Avg. loss: 0.350922\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005132, T: 4480, Avg. loss: 0.338571\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005522, T: 5120, Avg. loss: 0.343426\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005915, T: 5760, Avg. loss: 0.344485\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006246, T: 6400, Avg. loss: 0.344850\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006582, T: 7040, Avg. loss: 0.339307\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006865, T: 7680, Avg. loss: 0.340507\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 12 epochs took 0.01 seconds\n",
      "--- training time 0.015002012252807617 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.04, NNZs: 44, Bias: -0.001716, T: 640, Avg. loss: 0.494289\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.04, NNZs: 44, Bias: -0.002572, T: 1280, Avg. loss: 0.364677\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.003237, T: 1920, Avg. loss: 0.349521\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.003750, T: 2560, Avg. loss: 0.365191\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.004277, T: 3200, Avg. loss: 0.343723\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.004730, T: 3840, Avg. loss: 0.350922\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005132, T: 4480, Avg. loss: 0.338571\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005522, T: 5120, Avg. loss: 0.343426\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005915, T: 5760, Avg. loss: 0.344485\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006246, T: 6400, Avg. loss: 0.344850\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006582, T: 7040, Avg. loss: 0.339307\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006865, T: 7680, Avg. loss: 0.340507\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 12 epochs took 0.01 seconds\n",
      "--- training time 0.014667034149169922 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.04, NNZs: 44, Bias: -0.001716, T: 640, Avg. loss: 0.494289\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.04, NNZs: 44, Bias: -0.002572, T: 1280, Avg. loss: 0.364677\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.003237, T: 1920, Avg. loss: 0.349521\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.003750, T: 2560, Avg. loss: 0.365191\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.004277, T: 3200, Avg. loss: 0.343723\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.004730, T: 3840, Avg. loss: 0.350922\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005132, T: 4480, Avg. loss: 0.338571\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005522, T: 5120, Avg. loss: 0.343426\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005915, T: 5760, Avg. loss: 0.344485\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006246, T: 6400, Avg. loss: 0.344850\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006582, T: 7040, Avg. loss: 0.339307\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006865, T: 7680, Avg. loss: 0.340507\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 12 epochs took 0.01 seconds\n",
      "--- training time 0.009219884872436523 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.021067, T: 640, Avg. loss: 3.984145\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.48, NNZs: 44, Bias: -0.040317, T: 1280, Avg. loss: 3.222851\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.059537, T: 1920, Avg. loss: 3.644051\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.50, NNZs: 44, Bias: -0.078804, T: 2560, Avg. loss: 4.137911\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.45, NNZs: 44, Bias: -0.098773, T: 3200, Avg. loss: 3.813206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.74, NNZs: 44, Bias: -0.116994, T: 3840, Avg. loss: 3.862541\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.70, NNZs: 44, Bias: -0.135162, T: 4480, Avg. loss: 3.740942\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.138026, T: 5120, Avg. loss: 1.398175\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.51, NNZs: 44, Bias: -0.141678, T: 5760, Avg. loss: 0.953206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.52, NNZs: 44, Bias: -0.145249, T: 6400, Avg. loss: 0.784679\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.52, NNZs: 44, Bias: -0.149089, T: 7040, Avg. loss: 0.727688\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.53, NNZs: 44, Bias: -0.152845, T: 7680, Avg. loss: 0.727317\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.54, NNZs: 44, Bias: -0.156963, T: 8320, Avg. loss: 0.685719\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.55, NNZs: 44, Bias: -0.160600, T: 8960, Avg. loss: 0.805217\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.165141, T: 9600, Avg. loss: 0.780246\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.57, NNZs: 44, Bias: -0.168779, T: 10240, Avg. loss: 0.745140\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.59, NNZs: 44, Bias: -0.173353, T: 10880, Avg. loss: 0.668678\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.60, NNZs: 44, Bias: -0.177487, T: 11520, Avg. loss: 0.741204\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.61, NNZs: 44, Bias: -0.181503, T: 12160, Avg. loss: 0.770187\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.62, NNZs: 44, Bias: -0.185364, T: 12800, Avg. loss: 0.800654\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.63, NNZs: 44, Bias: -0.189288, T: 13440, Avg. loss: 0.788337\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.193096, T: 14080, Avg. loss: 0.677807\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.193678, T: 14720, Avg. loss: 0.353993\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.194425, T: 15360, Avg. loss: 0.313918\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.195239, T: 16000, Avg. loss: 0.305386\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.195940, T: 16640, Avg. loss: 0.306292\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.196674, T: 17280, Avg. loss: 0.298847\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.197423, T: 17920, Avg. loss: 0.304501\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.198198, T: 18560, Avg. loss: 0.304672\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.199014, T: 19200, Avg. loss: 0.298193\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.199779, T: 19840, Avg. loss: 0.313134\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200556, T: 20480, Avg. loss: 0.311360\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200677, T: 21120, Avg. loss: 0.266225\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200840, T: 21760, Avg. loss: 0.258514\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200990, T: 22400, Avg. loss: 0.262786\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.201148, T: 23040, Avg. loss: 0.263645\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.201312, T: 23680, Avg. loss: 0.266481\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201486, T: 24320, Avg. loss: 0.261895\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201651, T: 24960, Avg. loss: 0.259777\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201667, T: 25600, Avg. loss: 0.260109\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201695, T: 26240, Avg. loss: 0.254555\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201730, T: 26880, Avg. loss: 0.254708\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201758, T: 27520, Avg. loss: 0.254875\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201796, T: 28160, Avg. loss: 0.254540\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201830, T: 28800, Avg. loss: 0.254008\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201855, T: 29440, Avg. loss: 0.255364\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201862, T: 30080, Avg. loss: 0.252925\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201869, T: 30720, Avg. loss: 0.252909\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201875, T: 31360, Avg. loss: 0.252805\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201882, T: 32000, Avg. loss: 0.252968\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201888, T: 32640, Avg. loss: 0.252887\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201895, T: 33280, Avg. loss: 0.252886\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 52 epochs took 0.02 seconds\n",
      "--- training time 0.029298782348632812 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.021067, T: 640, Avg. loss: 3.984145\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.48, NNZs: 44, Bias: -0.040317, T: 1280, Avg. loss: 3.222851\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.059537, T: 1920, Avg. loss: 3.644051\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.50, NNZs: 44, Bias: -0.078804, T: 2560, Avg. loss: 4.137911\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.45, NNZs: 44, Bias: -0.098773, T: 3200, Avg. loss: 3.813206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.74, NNZs: 44, Bias: -0.116994, T: 3840, Avg. loss: 3.862541\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.70, NNZs: 44, Bias: -0.135162, T: 4480, Avg. loss: 3.740942\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.138026, T: 5120, Avg. loss: 1.398175\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.51, NNZs: 44, Bias: -0.141678, T: 5760, Avg. loss: 0.953206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.52, NNZs: 44, Bias: -0.145249, T: 6400, Avg. loss: 0.784679\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.52, NNZs: 44, Bias: -0.149089, T: 7040, Avg. loss: 0.727688\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.53, NNZs: 44, Bias: -0.152845, T: 7680, Avg. loss: 0.727317\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.54, NNZs: 44, Bias: -0.156963, T: 8320, Avg. loss: 0.685719\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.55, NNZs: 44, Bias: -0.160600, T: 8960, Avg. loss: 0.805217\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.165141, T: 9600, Avg. loss: 0.780246\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.57, NNZs: 44, Bias: -0.168779, T: 10240, Avg. loss: 0.745140\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.59, NNZs: 44, Bias: -0.173353, T: 10880, Avg. loss: 0.668678\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.60, NNZs: 44, Bias: -0.177487, T: 11520, Avg. loss: 0.741204\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.61, NNZs: 44, Bias: -0.181503, T: 12160, Avg. loss: 0.770187\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.62, NNZs: 44, Bias: -0.185364, T: 12800, Avg. loss: 0.800654\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.63, NNZs: 44, Bias: -0.189288, T: 13440, Avg. loss: 0.788337\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.193096, T: 14080, Avg. loss: 0.677807\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.193678, T: 14720, Avg. loss: 0.353993\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.194425, T: 15360, Avg. loss: 0.313918\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.195239, T: 16000, Avg. loss: 0.305386\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.195940, T: 16640, Avg. loss: 0.306292\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.196674, T: 17280, Avg. loss: 0.298847\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.197423, T: 17920, Avg. loss: 0.304501\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.198198, T: 18560, Avg. loss: 0.304672\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.199014, T: 19200, Avg. loss: 0.298193\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.199779, T: 19840, Avg. loss: 0.313134\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200556, T: 20480, Avg. loss: 0.311360\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200677, T: 21120, Avg. loss: 0.266225\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200840, T: 21760, Avg. loss: 0.258514\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200990, T: 22400, Avg. loss: 0.262786\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.201148, T: 23040, Avg. loss: 0.263645\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.201312, T: 23680, Avg. loss: 0.266481\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201486, T: 24320, Avg. loss: 0.261895\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201651, T: 24960, Avg. loss: 0.259777\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201667, T: 25600, Avg. loss: 0.260109\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201695, T: 26240, Avg. loss: 0.254555\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201730, T: 26880, Avg. loss: 0.254708\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201758, T: 27520, Avg. loss: 0.254875\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201796, T: 28160, Avg. loss: 0.254540\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201830, T: 28800, Avg. loss: 0.254008\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201855, T: 29440, Avg. loss: 0.255364\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201862, T: 30080, Avg. loss: 0.252925\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201869, T: 30720, Avg. loss: 0.252909\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201875, T: 31360, Avg. loss: 0.252805\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201882, T: 32000, Avg. loss: 0.252968\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201888, T: 32640, Avg. loss: 0.252887\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201895, T: 33280, Avg. loss: 0.252886\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 52 epochs took 0.01 seconds\n",
      "--- training time 0.014687061309814453 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.021067, T: 640, Avg. loss: 3.984145\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.48, NNZs: 44, Bias: -0.040317, T: 1280, Avg. loss: 3.222851\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.059537, T: 1920, Avg. loss: 3.644051\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.50, NNZs: 44, Bias: -0.078804, T: 2560, Avg. loss: 4.137911\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.45, NNZs: 44, Bias: -0.098773, T: 3200, Avg. loss: 3.813206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.74, NNZs: 44, Bias: -0.116994, T: 3840, Avg. loss: 3.862541\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.70, NNZs: 44, Bias: -0.135162, T: 4480, Avg. loss: 3.740942\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.138026, T: 5120, Avg. loss: 1.398175\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.51, NNZs: 44, Bias: -0.141678, T: 5760, Avg. loss: 0.953206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.52, NNZs: 44, Bias: -0.145249, T: 6400, Avg. loss: 0.784679\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.52, NNZs: 44, Bias: -0.149089, T: 7040, Avg. loss: 0.727688\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.53, NNZs: 44, Bias: -0.152845, T: 7680, Avg. loss: 0.727317\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.54, NNZs: 44, Bias: -0.156963, T: 8320, Avg. loss: 0.685719\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.55, NNZs: 44, Bias: -0.160600, T: 8960, Avg. loss: 0.805217\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.165141, T: 9600, Avg. loss: 0.780246\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.57, NNZs: 44, Bias: -0.168779, T: 10240, Avg. loss: 0.745140\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.59, NNZs: 44, Bias: -0.173353, T: 10880, Avg. loss: 0.668678\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.60, NNZs: 44, Bias: -0.177487, T: 11520, Avg. loss: 0.741204\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.61, NNZs: 44, Bias: -0.181503, T: 12160, Avg. loss: 0.770187\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.62, NNZs: 44, Bias: -0.185364, T: 12800, Avg. loss: 0.800654\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.63, NNZs: 44, Bias: -0.189288, T: 13440, Avg. loss: 0.788337\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.193096, T: 14080, Avg. loss: 0.677807\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.193678, T: 14720, Avg. loss: 0.353993\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.194425, T: 15360, Avg. loss: 0.313918\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.195239, T: 16000, Avg. loss: 0.305386\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.195940, T: 16640, Avg. loss: 0.306292\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.196674, T: 17280, Avg. loss: 0.298847\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.197423, T: 17920, Avg. loss: 0.304501\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.198198, T: 18560, Avg. loss: 0.304672\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.199014, T: 19200, Avg. loss: 0.298193\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.199779, T: 19840, Avg. loss: 0.313134\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200556, T: 20480, Avg. loss: 0.311360\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200677, T: 21120, Avg. loss: 0.266225\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200840, T: 21760, Avg. loss: 0.258514\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200990, T: 22400, Avg. loss: 0.262786\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.201148, T: 23040, Avg. loss: 0.263645\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.201312, T: 23680, Avg. loss: 0.266481\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201486, T: 24320, Avg. loss: 0.261895\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201651, T: 24960, Avg. loss: 0.259777\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201667, T: 25600, Avg. loss: 0.260109\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201695, T: 26240, Avg. loss: 0.254555\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201730, T: 26880, Avg. loss: 0.254708\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201758, T: 27520, Avg. loss: 0.254875\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201796, T: 28160, Avg. loss: 0.254540\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201830, T: 28800, Avg. loss: 0.254008\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201855, T: 29440, Avg. loss: 0.255364\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201862, T: 30080, Avg. loss: 0.252925\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201869, T: 30720, Avg. loss: 0.252909\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201875, T: 31360, Avg. loss: 0.252805\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201882, T: 32000, Avg. loss: 0.252968\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201888, T: 32640, Avg. loss: 0.252887\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201895, T: 33280, Avg. loss: 0.252886\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 52 epochs took 0.01 seconds\n",
      "--- training time 0.013663768768310547 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 3.92, NNZs: 44, Bias: -0.229017, T: 640, Avg. loss: 39.588520\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.22, NNZs: 44, Bias: -0.412678, T: 1280, Avg. loss: 36.358448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.77, NNZs: 44, Bias: -0.608724, T: 1920, Avg. loss: 37.326056\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.16, NNZs: 44, Bias: -0.820996, T: 2560, Avg. loss: 41.772040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.046754, T: 3200, Avg. loss: 40.525607\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.70, NNZs: 44, Bias: -1.233228, T: 3840, Avg. loss: 39.758304\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 6.79, NNZs: 44, Bias: -1.422213, T: 4480, Avg. loss: 39.742680\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.00533294677734375 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 3.92, NNZs: 44, Bias: -0.229017, T: 640, Avg. loss: 39.588520\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.22, NNZs: 44, Bias: -0.412678, T: 1280, Avg. loss: 36.358448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.77, NNZs: 44, Bias: -0.608724, T: 1920, Avg. loss: 37.326056\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.16, NNZs: 44, Bias: -0.820996, T: 2560, Avg. loss: 41.772040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.046754, T: 3200, Avg. loss: 40.525607\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.70, NNZs: 44, Bias: -1.233228, T: 3840, Avg. loss: 39.758304\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 6.79, NNZs: 44, Bias: -1.422213, T: 4480, Avg. loss: 39.742680\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.005021095275878906 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 3.92, NNZs: 44, Bias: -0.229017, T: 640, Avg. loss: 39.588520\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.22, NNZs: 44, Bias: -0.412678, T: 1280, Avg. loss: 36.358448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.77, NNZs: 44, Bias: -0.608724, T: 1920, Avg. loss: 37.326056\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.16, NNZs: 44, Bias: -0.820996, T: 2560, Avg. loss: 41.772040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.046754, T: 3200, Avg. loss: 40.525607\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.70, NNZs: 44, Bias: -1.233228, T: 3840, Avg. loss: 39.758304\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 6.79, NNZs: 44, Bias: -1.422213, T: 4480, Avg. loss: 39.742680\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.004945993423461914 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 60.99, NNZs: 42, Bias: -10.453885, T: 640, Avg. loss: 1552.509515\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 35.66, NNZs: 43, Bias: -12.783554, T: 1280, Avg. loss: 389.856725\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24.73, NNZs: 43, Bias: -14.062543, T: 1920, Avg. loss: 236.101649\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 20.01, NNZs: 44, Bias: -14.948544, T: 2560, Avg. loss: 187.732636\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 18.39, NNZs: 44, Bias: -15.671130, T: 3200, Avg. loss: 136.399263\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.70, NNZs: 44, Bias: -16.116936, T: 3840, Avg. loss: 111.364907\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 15.98, NNZs: 44, Bias: -16.589929, T: 4480, Avg. loss: 97.613050\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 14.31, NNZs: 44, Bias: -16.987956, T: 5120, Avg. loss: 74.871437\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 15.61, NNZs: 44, Bias: -17.388014, T: 5760, Avg. loss: 67.966306\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 13.92, NNZs: 44, Bias: -17.682240, T: 6400, Avg. loss: 61.636073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 11.86, NNZs: 44, Bias: -17.950590, T: 7040, Avg. loss: 55.904815\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 12.77, NNZs: 44, Bias: -18.208976, T: 7680, Avg. loss: 46.708359\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 11.33, NNZs: 44, Bias: -18.482606, T: 8320, Avg. loss: 45.033947\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 11.24, NNZs: 44, Bias: -18.677592, T: 8960, Avg. loss: 44.011195\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 11.42, NNZs: 44, Bias: -18.902786, T: 9600, Avg. loss: 43.701096\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 11.15, NNZs: 44, Bias: -19.059339, T: 10240, Avg. loss: 36.234746\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 11.28, NNZs: 44, Bias: -19.274144, T: 10880, Avg. loss: 33.412584\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 11.10, NNZs: 44, Bias: -19.442793, T: 11520, Avg. loss: 33.555258\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 10.71, NNZs: 44, Bias: -19.610984, T: 12160, Avg. loss: 34.817090\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 10.65, NNZs: 44, Bias: -19.756785, T: 12800, Avg. loss: 33.258951\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 11.12, NNZs: 44, Bias: -19.904638, T: 13440, Avg. loss: 30.816617\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 10.41, NNZs: 44, Bias: -20.032428, T: 14080, Avg. loss: 25.012433\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 10.57, NNZs: 44, Bias: -20.137965, T: 14720, Avg. loss: 28.452017\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 10.37, NNZs: 44, Bias: -20.251578, T: 15360, Avg. loss: 21.674290\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 10.47, NNZs: 44, Bias: -20.372988, T: 16000, Avg. loss: 22.736932\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 10.00, NNZs: 44, Bias: -20.472535, T: 16640, Avg. loss: 22.318439\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 10.02, NNZs: 44, Bias: -20.558950, T: 17280, Avg. loss: 20.445041\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 9.96, NNZs: 44, Bias: -20.664347, T: 17920, Avg. loss: 19.539886\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 9.83, NNZs: 44, Bias: -20.762185, T: 18560, Avg. loss: 19.285078\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 10.04, NNZs: 44, Bias: -20.861298, T: 19200, Avg. loss: 18.476698\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 10.05, NNZs: 44, Bias: -20.937798, T: 19840, Avg. loss: 19.100710\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 9.78, NNZs: 44, Bias: -21.031560, T: 20480, Avg. loss: 19.932161\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 9.73, NNZs: 44, Bias: -21.091787, T: 21120, Avg. loss: 16.569235\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 9.61, NNZs: 44, Bias: -21.180585, T: 21760, Avg. loss: 17.286220\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 9.71, NNZs: 44, Bias: -21.269395, T: 22400, Avg. loss: 16.595709\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 9.69, NNZs: 44, Bias: -21.341714, T: 23040, Avg. loss: 15.801840\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 9.62, NNZs: 44, Bias: -21.409972, T: 23680, Avg. loss: 15.241195\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 9.56, NNZs: 44, Bias: -21.492169, T: 24320, Avg. loss: 14.953152\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 9.59, NNZs: 44, Bias: -21.566195, T: 24960, Avg. loss: 13.076712\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 9.55, NNZs: 44, Bias: -21.629678, T: 25600, Avg. loss: 14.345237\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 9.57, NNZs: 44, Bias: -21.692393, T: 26240, Avg. loss: 13.411980\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 9.47, NNZs: 44, Bias: -21.744887, T: 26880, Avg. loss: 12.224874\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 9.46, NNZs: 44, Bias: -21.804454, T: 27520, Avg. loss: 12.965197\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 9.36, NNZs: 44, Bias: -21.862684, T: 28160, Avg. loss: 13.809267\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 9.37, NNZs: 44, Bias: -21.925840, T: 28800, Avg. loss: 11.215663\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 9.29, NNZs: 44, Bias: -21.977134, T: 29440, Avg. loss: 10.919410\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 9.44, NNZs: 44, Bias: -22.046628, T: 30080, Avg. loss: 11.670287\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 9.33, NNZs: 44, Bias: -22.098766, T: 30720, Avg. loss: 10.678681\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 9.37, NNZs: 44, Bias: -22.149601, T: 31360, Avg. loss: 11.416260\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 9.30, NNZs: 44, Bias: -22.196523, T: 32000, Avg. loss: 11.358393\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 9.26, NNZs: 44, Bias: -22.242260, T: 32640, Avg. loss: 9.731031\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 9.12, NNZs: 44, Bias: -22.280656, T: 33280, Avg. loss: 9.006451\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 9.22, NNZs: 44, Bias: -22.328328, T: 33920, Avg. loss: 9.207657\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 9.12, NNZs: 44, Bias: -22.374595, T: 34560, Avg. loss: 9.882925\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 9.09, NNZs: 44, Bias: -22.421797, T: 35200, Avg. loss: 9.979394\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 9.11, NNZs: 44, Bias: -22.466248, T: 35840, Avg. loss: 8.893490\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 9.06, NNZs: 44, Bias: -22.513793, T: 36480, Avg. loss: 8.991318\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 9.03, NNZs: 44, Bias: -22.553100, T: 37120, Avg. loss: 8.224942\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 9.07, NNZs: 44, Bias: -22.589988, T: 37760, Avg. loss: 8.861412\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 9.01, NNZs: 44, Bias: -22.640601, T: 38400, Avg. loss: 8.698771\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 9.01, NNZs: 44, Bias: -22.685427, T: 39040, Avg. loss: 8.509588\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 8.98, NNZs: 44, Bias: -22.722693, T: 39680, Avg. loss: 7.738338\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 8.93, NNZs: 44, Bias: -22.760115, T: 40320, Avg. loss: 8.054029\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 8.93, NNZs: 44, Bias: -22.797019, T: 40960, Avg. loss: 8.500504\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 8.93, NNZs: 44, Bias: -22.838322, T: 41600, Avg. loss: 6.743084\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 8.90, NNZs: 44, Bias: -22.869848, T: 42240, Avg. loss: 7.161529\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 8.83, NNZs: 44, Bias: -22.908464, T: 42880, Avg. loss: 6.941667\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 8.84, NNZs: 44, Bias: -22.948904, T: 43520, Avg. loss: 9.023189\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 8.83, NNZs: 44, Bias: -22.979528, T: 44160, Avg. loss: 6.340707\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 8.79, NNZs: 44, Bias: -23.009289, T: 44800, Avg. loss: 7.420992\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 8.77, NNZs: 44, Bias: -23.043158, T: 45440, Avg. loss: 6.921390\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 8.71, NNZs: 44, Bias: -23.073129, T: 46080, Avg. loss: 7.010272\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 8.69, NNZs: 44, Bias: -23.106556, T: 46720, Avg. loss: 6.390169\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 8.68, NNZs: 44, Bias: -23.137707, T: 47360, Avg. loss: 6.870737\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 74 epochs took 0.02 seconds\n",
      "--- training time 0.01855325698852539 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 60.99, NNZs: 42, Bias: -10.453885, T: 640, Avg. loss: 1552.509515\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 35.66, NNZs: 43, Bias: -12.783554, T: 1280, Avg. loss: 389.856725\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24.73, NNZs: 43, Bias: -14.062543, T: 1920, Avg. loss: 236.101649\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 20.01, NNZs: 44, Bias: -14.948544, T: 2560, Avg. loss: 187.732636\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 18.39, NNZs: 44, Bias: -15.671130, T: 3200, Avg. loss: 136.399263\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.70, NNZs: 44, Bias: -16.116936, T: 3840, Avg. loss: 111.364907\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 15.98, NNZs: 44, Bias: -16.589929, T: 4480, Avg. loss: 97.613050\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 14.31, NNZs: 44, Bias: -16.987956, T: 5120, Avg. loss: 74.871437\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 15.61, NNZs: 44, Bias: -17.388014, T: 5760, Avg. loss: 67.966306\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 13.92, NNZs: 44, Bias: -17.682240, T: 6400, Avg. loss: 61.636073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 11.86, NNZs: 44, Bias: -17.950590, T: 7040, Avg. loss: 55.904815\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 12.77, NNZs: 44, Bias: -18.208976, T: 7680, Avg. loss: 46.708359\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 11.33, NNZs: 44, Bias: -18.482606, T: 8320, Avg. loss: 45.033947\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 11.24, NNZs: 44, Bias: -18.677592, T: 8960, Avg. loss: 44.011195\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 11.42, NNZs: 44, Bias: -18.902786, T: 9600, Avg. loss: 43.701096\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 11.15, NNZs: 44, Bias: -19.059339, T: 10240, Avg. loss: 36.234746\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 11.28, NNZs: 44, Bias: -19.274144, T: 10880, Avg. loss: 33.412584\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 11.10, NNZs: 44, Bias: -19.442793, T: 11520, Avg. loss: 33.555258\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 10.71, NNZs: 44, Bias: -19.610984, T: 12160, Avg. loss: 34.817090\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 10.65, NNZs: 44, Bias: -19.756785, T: 12800, Avg. loss: 33.258951\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 11.12, NNZs: 44, Bias: -19.904638, T: 13440, Avg. loss: 30.816617\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 10.41, NNZs: 44, Bias: -20.032428, T: 14080, Avg. loss: 25.012433\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 10.57, NNZs: 44, Bias: -20.137965, T: 14720, Avg. loss: 28.452017\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 10.37, NNZs: 44, Bias: -20.251578, T: 15360, Avg. loss: 21.674290\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 10.47, NNZs: 44, Bias: -20.372988, T: 16000, Avg. loss: 22.736932\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 10.00, NNZs: 44, Bias: -20.472535, T: 16640, Avg. loss: 22.318439\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 10.02, NNZs: 44, Bias: -20.558950, T: 17280, Avg. loss: 20.445041\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 9.96, NNZs: 44, Bias: -20.664347, T: 17920, Avg. loss: 19.539886\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 9.83, NNZs: 44, Bias: -20.762185, T: 18560, Avg. loss: 19.285078\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 10.04, NNZs: 44, Bias: -20.861298, T: 19200, Avg. loss: 18.476698\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 10.05, NNZs: 44, Bias: -20.937798, T: 19840, Avg. loss: 19.100710\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 9.78, NNZs: 44, Bias: -21.031560, T: 20480, Avg. loss: 19.932161\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 9.73, NNZs: 44, Bias: -21.091787, T: 21120, Avg. loss: 16.569235\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 9.61, NNZs: 44, Bias: -21.180585, T: 21760, Avg. loss: 17.286220\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 9.71, NNZs: 44, Bias: -21.269395, T: 22400, Avg. loss: 16.595709\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 9.69, NNZs: 44, Bias: -21.341714, T: 23040, Avg. loss: 15.801840\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 9.62, NNZs: 44, Bias: -21.409972, T: 23680, Avg. loss: 15.241195\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 9.56, NNZs: 44, Bias: -21.492169, T: 24320, Avg. loss: 14.953152\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 9.59, NNZs: 44, Bias: -21.566195, T: 24960, Avg. loss: 13.076712\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 9.55, NNZs: 44, Bias: -21.629678, T: 25600, Avg. loss: 14.345237\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 9.57, NNZs: 44, Bias: -21.692393, T: 26240, Avg. loss: 13.411980\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 9.47, NNZs: 44, Bias: -21.744887, T: 26880, Avg. loss: 12.224874\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 9.46, NNZs: 44, Bias: -21.804454, T: 27520, Avg. loss: 12.965197\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 9.36, NNZs: 44, Bias: -21.862684, T: 28160, Avg. loss: 13.809267\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 9.37, NNZs: 44, Bias: -21.925840, T: 28800, Avg. loss: 11.215663\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 9.29, NNZs: 44, Bias: -21.977134, T: 29440, Avg. loss: 10.919410\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 9.44, NNZs: 44, Bias: -22.046628, T: 30080, Avg. loss: 11.670287\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 9.33, NNZs: 44, Bias: -22.098766, T: 30720, Avg. loss: 10.678681\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 9.37, NNZs: 44, Bias: -22.149601, T: 31360, Avg. loss: 11.416260\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 9.30, NNZs: 44, Bias: -22.196523, T: 32000, Avg. loss: 11.358393\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 9.26, NNZs: 44, Bias: -22.242260, T: 32640, Avg. loss: 9.731031\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 9.12, NNZs: 44, Bias: -22.280656, T: 33280, Avg. loss: 9.006451\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 9.22, NNZs: 44, Bias: -22.328328, T: 33920, Avg. loss: 9.207657\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 9.12, NNZs: 44, Bias: -22.374595, T: 34560, Avg. loss: 9.882925\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 9.09, NNZs: 44, Bias: -22.421797, T: 35200, Avg. loss: 9.979394\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 9.11, NNZs: 44, Bias: -22.466248, T: 35840, Avg. loss: 8.893490\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 9.06, NNZs: 44, Bias: -22.513793, T: 36480, Avg. loss: 8.991318\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 9.03, NNZs: 44, Bias: -22.553100, T: 37120, Avg. loss: 8.224942\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 9.07, NNZs: 44, Bias: -22.589988, T: 37760, Avg. loss: 8.861412\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 9.01, NNZs: 44, Bias: -22.640601, T: 38400, Avg. loss: 8.698771\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 9.01, NNZs: 44, Bias: -22.685427, T: 39040, Avg. loss: 8.509588\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 8.98, NNZs: 44, Bias: -22.722693, T: 39680, Avg. loss: 7.738338\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 8.93, NNZs: 44, Bias: -22.760115, T: 40320, Avg. loss: 8.054029\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 8.93, NNZs: 44, Bias: -22.797019, T: 40960, Avg. loss: 8.500504\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 8.93, NNZs: 44, Bias: -22.838322, T: 41600, Avg. loss: 6.743084\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 8.90, NNZs: 44, Bias: -22.869848, T: 42240, Avg. loss: 7.161529\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 8.83, NNZs: 44, Bias: -22.908464, T: 42880, Avg. loss: 6.941667\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 8.84, NNZs: 44, Bias: -22.948904, T: 43520, Avg. loss: 9.023189\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 8.83, NNZs: 44, Bias: -22.979528, T: 44160, Avg. loss: 6.340707\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 8.79, NNZs: 44, Bias: -23.009289, T: 44800, Avg. loss: 7.420992\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 8.77, NNZs: 44, Bias: -23.043158, T: 45440, Avg. loss: 6.921390\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 8.71, NNZs: 44, Bias: -23.073129, T: 46080, Avg. loss: 7.010272\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 8.69, NNZs: 44, Bias: -23.106556, T: 46720, Avg. loss: 6.390169\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 8.68, NNZs: 44, Bias: -23.137707, T: 47360, Avg. loss: 6.870737\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 74 epochs took 0.02 seconds\n",
      "--- training time 0.021111249923706055 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 60.99, NNZs: 42, Bias: -10.453885, T: 640, Avg. loss: 1552.509515\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 35.66, NNZs: 43, Bias: -12.783554, T: 1280, Avg. loss: 389.856725\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24.73, NNZs: 43, Bias: -14.062543, T: 1920, Avg. loss: 236.101649\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 20.01, NNZs: 44, Bias: -14.948544, T: 2560, Avg. loss: 187.732636\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 18.39, NNZs: 44, Bias: -15.671130, T: 3200, Avg. loss: 136.399263\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.70, NNZs: 44, Bias: -16.116936, T: 3840, Avg. loss: 111.364907\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 15.98, NNZs: 44, Bias: -16.589929, T: 4480, Avg. loss: 97.613050\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 14.31, NNZs: 44, Bias: -16.987956, T: 5120, Avg. loss: 74.871437\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 15.61, NNZs: 44, Bias: -17.388014, T: 5760, Avg. loss: 67.966306\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 13.92, NNZs: 44, Bias: -17.682240, T: 6400, Avg. loss: 61.636073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 11.86, NNZs: 44, Bias: -17.950590, T: 7040, Avg. loss: 55.904815\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 12.77, NNZs: 44, Bias: -18.208976, T: 7680, Avg. loss: 46.708359\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 11.33, NNZs: 44, Bias: -18.482606, T: 8320, Avg. loss: 45.033947\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 11.24, NNZs: 44, Bias: -18.677592, T: 8960, Avg. loss: 44.011195\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 11.42, NNZs: 44, Bias: -18.902786, T: 9600, Avg. loss: 43.701096\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 11.15, NNZs: 44, Bias: -19.059339, T: 10240, Avg. loss: 36.234746\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 11.28, NNZs: 44, Bias: -19.274144, T: 10880, Avg. loss: 33.412584\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 11.10, NNZs: 44, Bias: -19.442793, T: 11520, Avg. loss: 33.555258\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 10.71, NNZs: 44, Bias: -19.610984, T: 12160, Avg. loss: 34.817090\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 10.65, NNZs: 44, Bias: -19.756785, T: 12800, Avg. loss: 33.258951\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 11.12, NNZs: 44, Bias: -19.904638, T: 13440, Avg. loss: 30.816617\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 10.41, NNZs: 44, Bias: -20.032428, T: 14080, Avg. loss: 25.012433\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 10.57, NNZs: 44, Bias: -20.137965, T: 14720, Avg. loss: 28.452017\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 10.37, NNZs: 44, Bias: -20.251578, T: 15360, Avg. loss: 21.674290\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 10.47, NNZs: 44, Bias: -20.372988, T: 16000, Avg. loss: 22.736932\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 10.00, NNZs: 44, Bias: -20.472535, T: 16640, Avg. loss: 22.318439\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 10.02, NNZs: 44, Bias: -20.558950, T: 17280, Avg. loss: 20.445041\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 9.96, NNZs: 44, Bias: -20.664347, T: 17920, Avg. loss: 19.539886\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 9.83, NNZs: 44, Bias: -20.762185, T: 18560, Avg. loss: 19.285078\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 10.04, NNZs: 44, Bias: -20.861298, T: 19200, Avg. loss: 18.476698\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 10.05, NNZs: 44, Bias: -20.937798, T: 19840, Avg. loss: 19.100710\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 9.78, NNZs: 44, Bias: -21.031560, T: 20480, Avg. loss: 19.932161\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 9.73, NNZs: 44, Bias: -21.091787, T: 21120, Avg. loss: 16.569235\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 9.61, NNZs: 44, Bias: -21.180585, T: 21760, Avg. loss: 17.286220\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 9.71, NNZs: 44, Bias: -21.269395, T: 22400, Avg. loss: 16.595709\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 9.69, NNZs: 44, Bias: -21.341714, T: 23040, Avg. loss: 15.801840\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 9.62, NNZs: 44, Bias: -21.409972, T: 23680, Avg. loss: 15.241195\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 9.56, NNZs: 44, Bias: -21.492169, T: 24320, Avg. loss: 14.953152\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 9.59, NNZs: 44, Bias: -21.566195, T: 24960, Avg. loss: 13.076712\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 9.55, NNZs: 44, Bias: -21.629678, T: 25600, Avg. loss: 14.345237\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 9.57, NNZs: 44, Bias: -21.692393, T: 26240, Avg. loss: 13.411980\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 9.47, NNZs: 44, Bias: -21.744887, T: 26880, Avg. loss: 12.224874\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 9.46, NNZs: 44, Bias: -21.804454, T: 27520, Avg. loss: 12.965197\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 9.36, NNZs: 44, Bias: -21.862684, T: 28160, Avg. loss: 13.809267\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 9.37, NNZs: 44, Bias: -21.925840, T: 28800, Avg. loss: 11.215663\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 9.29, NNZs: 44, Bias: -21.977134, T: 29440, Avg. loss: 10.919410\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 9.44, NNZs: 44, Bias: -22.046628, T: 30080, Avg. loss: 11.670287\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 9.33, NNZs: 44, Bias: -22.098766, T: 30720, Avg. loss: 10.678681\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 9.37, NNZs: 44, Bias: -22.149601, T: 31360, Avg. loss: 11.416260\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 9.30, NNZs: 44, Bias: -22.196523, T: 32000, Avg. loss: 11.358393\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 9.26, NNZs: 44, Bias: -22.242260, T: 32640, Avg. loss: 9.731031\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 9.12, NNZs: 44, Bias: -22.280656, T: 33280, Avg. loss: 9.006451\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 9.22, NNZs: 44, Bias: -22.328328, T: 33920, Avg. loss: 9.207657\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 9.12, NNZs: 44, Bias: -22.374595, T: 34560, Avg. loss: 9.882925\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 9.09, NNZs: 44, Bias: -22.421797, T: 35200, Avg. loss: 9.979394\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 9.11, NNZs: 44, Bias: -22.466248, T: 35840, Avg. loss: 8.893490\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 9.06, NNZs: 44, Bias: -22.513793, T: 36480, Avg. loss: 8.991318\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 9.03, NNZs: 44, Bias: -22.553100, T: 37120, Avg. loss: 8.224942\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 9.07, NNZs: 44, Bias: -22.589988, T: 37760, Avg. loss: 8.861412\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 9.01, NNZs: 44, Bias: -22.640601, T: 38400, Avg. loss: 8.698771\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 9.01, NNZs: 44, Bias: -22.685427, T: 39040, Avg. loss: 8.509588\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 8.98, NNZs: 44, Bias: -22.722693, T: 39680, Avg. loss: 7.738338\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 8.93, NNZs: 44, Bias: -22.760115, T: 40320, Avg. loss: 8.054029\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 8.93, NNZs: 44, Bias: -22.797019, T: 40960, Avg. loss: 8.500504\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 8.93, NNZs: 44, Bias: -22.838322, T: 41600, Avg. loss: 6.743084\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 8.90, NNZs: 44, Bias: -22.869848, T: 42240, Avg. loss: 7.161529\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 8.83, NNZs: 44, Bias: -22.908464, T: 42880, Avg. loss: 6.941667\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 8.84, NNZs: 44, Bias: -22.948904, T: 43520, Avg. loss: 9.023189\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 8.83, NNZs: 44, Bias: -22.979528, T: 44160, Avg. loss: 6.340707\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 8.79, NNZs: 44, Bias: -23.009289, T: 44800, Avg. loss: 7.420992\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 8.77, NNZs: 44, Bias: -23.043158, T: 45440, Avg. loss: 6.921390\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 8.71, NNZs: 44, Bias: -23.073129, T: 46080, Avg. loss: 7.010272\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 8.69, NNZs: 44, Bias: -23.106556, T: 46720, Avg. loss: 6.390169\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 8.68, NNZs: 44, Bias: -23.137707, T: 47360, Avg. loss: 6.870737\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 74 epochs took 0.02 seconds\n",
      "--- training time 0.019553661346435547 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.28, NNZs: 44, Bias: -0.013512, T: 640, Avg. loss: 3.020409\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.018760, T: 1280, Avg. loss: 1.296850\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.023565, T: 1920, Avg. loss: 0.963469\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.15, NNZs: 44, Bias: -0.027589, T: 2560, Avg. loss: 0.921900\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.14, NNZs: 44, Bias: -0.031779, T: 3200, Avg. loss: 0.737516\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.034975, T: 3840, Avg. loss: 0.649676\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.038168, T: 4480, Avg. loss: 0.654734\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.041333, T: 5120, Avg. loss: 0.612543\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.044426, T: 5760, Avg. loss: 0.567650\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.047042, T: 6400, Avg. loss: 0.558362\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.19, NNZs: 44, Bias: -0.049740, T: 7040, Avg. loss: 0.546509\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.19, NNZs: 44, Bias: -0.052214, T: 7680, Avg. loss: 0.536491\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.20, NNZs: 44, Bias: -0.054853, T: 8320, Avg. loss: 0.494764\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.20, NNZs: 44, Bias: -0.056945, T: 8960, Avg. loss: 0.522660\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.21, NNZs: 44, Bias: -0.059607, T: 9600, Avg. loss: 0.512106\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.21, NNZs: 44, Bias: -0.061642, T: 10240, Avg. loss: 0.487472\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.22, NNZs: 44, Bias: -0.064052, T: 10880, Avg. loss: 0.448072\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.066284, T: 11520, Avg. loss: 0.466046\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.068396, T: 12160, Avg. loss: 0.460946\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.070376, T: 12800, Avg. loss: 0.473061\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.24, NNZs: 44, Bias: -0.072256, T: 13440, Avg. loss: 0.466358\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.24, NNZs: 44, Bias: -0.074107, T: 14080, Avg. loss: 0.420802\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.25, NNZs: 44, Bias: -0.075874, T: 14720, Avg. loss: 0.437950\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.077713, T: 15360, Avg. loss: 0.414708\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.079615, T: 16000, Avg. loss: 0.419000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.081175, T: 16640, Avg. loss: 0.416462\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.27, NNZs: 44, Bias: -0.082705, T: 17280, Avg. loss: 0.399610\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.27, NNZs: 44, Bias: -0.084400, T: 17920, Avg. loss: 0.406214\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.28, NNZs: 44, Bias: -0.086092, T: 18560, Avg. loss: 0.404670\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.087828, T: 19200, Avg. loss: 0.393779\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.089294, T: 19840, Avg. loss: 0.408178\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.090851, T: 20480, Avg. loss: 0.415089\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.092223, T: 21120, Avg. loss: 0.385259\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.30, NNZs: 44, Bias: -0.093777, T: 21760, Avg. loss: 0.389855\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.30, NNZs: 44, Bias: -0.095357, T: 22400, Avg. loss: 0.395306\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.31, NNZs: 44, Bias: -0.096812, T: 23040, Avg. loss: 0.398555\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.31, NNZs: 44, Bias: -0.098326, T: 23680, Avg. loss: 0.403534\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.099797, T: 24320, Avg. loss: 0.395906\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 38 epochs took 0.01 seconds\n",
      "--- training time 0.016707897186279297 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.28, NNZs: 44, Bias: -0.013512, T: 640, Avg. loss: 3.020409\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.018760, T: 1280, Avg. loss: 1.296850\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.023565, T: 1920, Avg. loss: 0.963469\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.15, NNZs: 44, Bias: -0.027589, T: 2560, Avg. loss: 0.921900\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.14, NNZs: 44, Bias: -0.031779, T: 3200, Avg. loss: 0.737516\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.034975, T: 3840, Avg. loss: 0.649676\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.038168, T: 4480, Avg. loss: 0.654734\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.041333, T: 5120, Avg. loss: 0.612543\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.044426, T: 5760, Avg. loss: 0.567650\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.047042, T: 6400, Avg. loss: 0.558362\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.19, NNZs: 44, Bias: -0.049740, T: 7040, Avg. loss: 0.546509\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.19, NNZs: 44, Bias: -0.052214, T: 7680, Avg. loss: 0.536491\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.20, NNZs: 44, Bias: -0.054853, T: 8320, Avg. loss: 0.494764\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.20, NNZs: 44, Bias: -0.056945, T: 8960, Avg. loss: 0.522660\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.21, NNZs: 44, Bias: -0.059607, T: 9600, Avg. loss: 0.512106\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.21, NNZs: 44, Bias: -0.061642, T: 10240, Avg. loss: 0.487472\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.22, NNZs: 44, Bias: -0.064052, T: 10880, Avg. loss: 0.448072\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.066284, T: 11520, Avg. loss: 0.466046\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.068396, T: 12160, Avg. loss: 0.460946\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.070376, T: 12800, Avg. loss: 0.473061\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.24, NNZs: 44, Bias: -0.072256, T: 13440, Avg. loss: 0.466358\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.24, NNZs: 44, Bias: -0.074107, T: 14080, Avg. loss: 0.420802\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.25, NNZs: 44, Bias: -0.075874, T: 14720, Avg. loss: 0.437950\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.077713, T: 15360, Avg. loss: 0.414708\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.079615, T: 16000, Avg. loss: 0.419000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.081175, T: 16640, Avg. loss: 0.416462\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.27, NNZs: 44, Bias: -0.082705, T: 17280, Avg. loss: 0.399610\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.27, NNZs: 44, Bias: -0.084400, T: 17920, Avg. loss: 0.406214\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.28, NNZs: 44, Bias: -0.086092, T: 18560, Avg. loss: 0.404670\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.087828, T: 19200, Avg. loss: 0.393779\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.089294, T: 19840, Avg. loss: 0.408178\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.090851, T: 20480, Avg. loss: 0.415089\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.092223, T: 21120, Avg. loss: 0.385259\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.30, NNZs: 44, Bias: -0.093777, T: 21760, Avg. loss: 0.389855\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.30, NNZs: 44, Bias: -0.095357, T: 22400, Avg. loss: 0.395306\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.31, NNZs: 44, Bias: -0.096812, T: 23040, Avg. loss: 0.398555\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.31, NNZs: 44, Bias: -0.098326, T: 23680, Avg. loss: 0.403534\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.099797, T: 24320, Avg. loss: 0.395906\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 38 epochs took 0.04 seconds\n",
      "--- training time 0.040779829025268555 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.28, NNZs: 44, Bias: -0.013512, T: 640, Avg. loss: 3.020409\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.018760, T: 1280, Avg. loss: 1.296850\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.023565, T: 1920, Avg. loss: 0.963469\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.15, NNZs: 44, Bias: -0.027589, T: 2560, Avg. loss: 0.921900\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.14, NNZs: 44, Bias: -0.031779, T: 3200, Avg. loss: 0.737516\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.034975, T: 3840, Avg. loss: 0.649676\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.038168, T: 4480, Avg. loss: 0.654734\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.041333, T: 5120, Avg. loss: 0.612543\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.044426, T: 5760, Avg. loss: 0.567650\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.047042, T: 6400, Avg. loss: 0.558362\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.19, NNZs: 44, Bias: -0.049740, T: 7040, Avg. loss: 0.546509\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.19, NNZs: 44, Bias: -0.052214, T: 7680, Avg. loss: 0.536491\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.20, NNZs: 44, Bias: -0.054853, T: 8320, Avg. loss: 0.494764\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.20, NNZs: 44, Bias: -0.056945, T: 8960, Avg. loss: 0.522660\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.21, NNZs: 44, Bias: -0.059607, T: 9600, Avg. loss: 0.512106\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.21, NNZs: 44, Bias: -0.061642, T: 10240, Avg. loss: 0.487472\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.22, NNZs: 44, Bias: -0.064052, T: 10880, Avg. loss: 0.448072\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.066284, T: 11520, Avg. loss: 0.466046\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.068396, T: 12160, Avg. loss: 0.460946\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.070376, T: 12800, Avg. loss: 0.473061\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.24, NNZs: 44, Bias: -0.072256, T: 13440, Avg. loss: 0.466358\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.24, NNZs: 44, Bias: -0.074107, T: 14080, Avg. loss: 0.420802\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.25, NNZs: 44, Bias: -0.075874, T: 14720, Avg. loss: 0.437950\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.077713, T: 15360, Avg. loss: 0.414708\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.079615, T: 16000, Avg. loss: 0.419000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.081175, T: 16640, Avg. loss: 0.416462\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.27, NNZs: 44, Bias: -0.082705, T: 17280, Avg. loss: 0.399610\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.27, NNZs: 44, Bias: -0.084400, T: 17920, Avg. loss: 0.406214\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.28, NNZs: 44, Bias: -0.086092, T: 18560, Avg. loss: 0.404670\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.087828, T: 19200, Avg. loss: 0.393779\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.089294, T: 19840, Avg. loss: 0.408178\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.090851, T: 20480, Avg. loss: 0.415089\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.092223, T: 21120, Avg. loss: 0.385259\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.30, NNZs: 44, Bias: -0.093777, T: 21760, Avg. loss: 0.389855\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.30, NNZs: 44, Bias: -0.095357, T: 22400, Avg. loss: 0.395306\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.31, NNZs: 44, Bias: -0.096812, T: 23040, Avg. loss: 0.398555\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.31, NNZs: 44, Bias: -0.098326, T: 23680, Avg. loss: 0.403534\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.099797, T: 24320, Avg. loss: 0.395906\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 38 epochs took 0.01 seconds\n",
      "--- training time 0.014549970626831055 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 3.92, NNZs: 44, Bias: -0.229017, T: 640, Avg. loss: 39.588520\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.22, NNZs: 44, Bias: -0.412678, T: 1280, Avg. loss: 36.358448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.77, NNZs: 44, Bias: -0.608724, T: 1920, Avg. loss: 37.326056\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.16, NNZs: 44, Bias: -0.820996, T: 2560, Avg. loss: 41.772040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.046754, T: 3200, Avg. loss: 40.525607\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.70, NNZs: 44, Bias: -1.233228, T: 3840, Avg. loss: 39.758304\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 6.79, NNZs: 44, Bias: -1.422213, T: 4480, Avg. loss: 39.742680\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 4.53, NNZs: 44, Bias: -1.450692, T: 5120, Avg. loss: 16.560021\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 4.10, NNZs: 44, Bias: -1.488961, T: 5760, Avg. loss: 9.079159\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 4.12, NNZs: 44, Bias: -1.526367, T: 6400, Avg. loss: 7.795266\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 4.13, NNZs: 44, Bias: -1.563871, T: 7040, Avg. loss: 7.278739\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 4.18, NNZs: 44, Bias: -1.597494, T: 7680, Avg. loss: 7.476793\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 4.20, NNZs: 44, Bias: -1.635171, T: 8320, Avg. loss: 6.880366\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 4.23, NNZs: 44, Bias: -1.670875, T: 8960, Avg. loss: 8.182257\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 4.29, NNZs: 44, Bias: -1.708758, T: 9600, Avg. loss: 7.790961\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 4.42, NNZs: 44, Bias: -1.745993, T: 10240, Avg. loss: 6.813259\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 4.53, NNZs: 44, Bias: -1.787712, T: 10880, Avg. loss: 6.377116\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 4.54, NNZs: 44, Bias: -1.826082, T: 11520, Avg. loss: 7.133107\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 4.61, NNZs: 44, Bias: -1.865045, T: 12160, Avg. loss: 7.854998\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 4.62, NNZs: 44, Bias: -1.900519, T: 12800, Avg. loss: 8.339434\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 4.69, NNZs: 44, Bias: -1.938469, T: 13440, Avg. loss: 7.971242\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 4.70, NNZs: 44, Bias: -1.971390, T: 14080, Avg. loss: 6.846766\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.975878, T: 14720, Avg. loss: 1.909502\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 4.65, NNZs: 44, Bias: -1.981030, T: 15360, Avg. loss: 1.337327\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 4.64, NNZs: 44, Bias: -1.986973, T: 16000, Avg. loss: 1.095216\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 4.64, NNZs: 44, Bias: -1.991376, T: 16640, Avg. loss: 1.240920\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 4.63, NNZs: 44, Bias: -1.995282, T: 17280, Avg. loss: 1.152731\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.000016, T: 17920, Avg. loss: 1.129366\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.005264, T: 18560, Avg. loss: 1.114322\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.010318, T: 19200, Avg. loss: 1.112498\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 4.62, NNZs: 44, Bias: -2.010732, T: 19840, Avg. loss: 0.529010\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 4.62, NNZs: 44, Bias: -2.011248, T: 20480, Avg. loss: 0.383808\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.011636, T: 21120, Avg. loss: 0.347171\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.012246, T: 21760, Avg. loss: 0.332399\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.012706, T: 22400, Avg. loss: 0.351599\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.013156, T: 23040, Avg. loss: 0.337051\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.013751, T: 23680, Avg. loss: 0.323753\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.014291, T: 24320, Avg. loss: 0.316370\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.014850, T: 24960, Avg. loss: 0.306305\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.015305, T: 25600, Avg. loss: 0.349897\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.015810, T: 26240, Avg. loss: 0.322652\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.016303, T: 26880, Avg. loss: 0.284620\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.016802, T: 27520, Avg. loss: 0.341514\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.017296, T: 28160, Avg. loss: 0.334507\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.017880, T: 28800, Avg. loss: 0.307931\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.018483, T: 29440, Avg. loss: 0.334228\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019125, T: 30080, Avg. loss: 0.296572\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019163, T: 30720, Avg. loss: 0.224531\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019239, T: 31360, Avg. loss: 0.215501\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019339, T: 32000, Avg. loss: 0.227935\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019387, T: 32640, Avg. loss: 0.213606\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019489, T: 33280, Avg. loss: 0.218986\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019590, T: 33920, Avg. loss: 0.228519\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019696, T: 34560, Avg. loss: 0.219427\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019733, T: 35200, Avg. loss: 0.221081\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019877, T: 35840, Avg. loss: 0.221838\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019869, T: 36480, Avg. loss: 0.214944\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019888, T: 37120, Avg. loss: 0.209974\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019906, T: 37760, Avg. loss: 0.209764\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019922, T: 38400, Avg. loss: 0.207634\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019936, T: 39040, Avg. loss: 0.209592\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019947, T: 39680, Avg. loss: 0.208848\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019974, T: 40320, Avg. loss: 0.210157\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019986, T: 40960, Avg. loss: 0.208959\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020005, T: 41600, Avg. loss: 0.209884\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020008, T: 42240, Avg. loss: 0.205329\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020012, T: 42880, Avg. loss: 0.205593\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020015, T: 43520, Avg. loss: 0.205441\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020019, T: 44160, Avg. loss: 0.205546\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020022, T: 44800, Avg. loss: 0.205484\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020026, T: 45440, Avg. loss: 0.205467\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 71 epochs took 0.02 seconds\n",
      "--- training time 0.022979021072387695 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 3.92, NNZs: 44, Bias: -0.229017, T: 640, Avg. loss: 39.588520\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.22, NNZs: 44, Bias: -0.412678, T: 1280, Avg. loss: 36.358448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.77, NNZs: 44, Bias: -0.608724, T: 1920, Avg. loss: 37.326056\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.16, NNZs: 44, Bias: -0.820996, T: 2560, Avg. loss: 41.772040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.046754, T: 3200, Avg. loss: 40.525607\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.70, NNZs: 44, Bias: -1.233228, T: 3840, Avg. loss: 39.758304\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 6.79, NNZs: 44, Bias: -1.422213, T: 4480, Avg. loss: 39.742680\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 4.53, NNZs: 44, Bias: -1.450692, T: 5120, Avg. loss: 16.560021\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 4.10, NNZs: 44, Bias: -1.488961, T: 5760, Avg. loss: 9.079159\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 4.12, NNZs: 44, Bias: -1.526367, T: 6400, Avg. loss: 7.795266\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 4.13, NNZs: 44, Bias: -1.563871, T: 7040, Avg. loss: 7.278739\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 4.18, NNZs: 44, Bias: -1.597494, T: 7680, Avg. loss: 7.476793\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 4.20, NNZs: 44, Bias: -1.635171, T: 8320, Avg. loss: 6.880366\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 4.23, NNZs: 44, Bias: -1.670875, T: 8960, Avg. loss: 8.182257\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 4.29, NNZs: 44, Bias: -1.708758, T: 9600, Avg. loss: 7.790961\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 4.42, NNZs: 44, Bias: -1.745993, T: 10240, Avg. loss: 6.813259\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 4.53, NNZs: 44, Bias: -1.787712, T: 10880, Avg. loss: 6.377116\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 4.54, NNZs: 44, Bias: -1.826082, T: 11520, Avg. loss: 7.133107\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 4.61, NNZs: 44, Bias: -1.865045, T: 12160, Avg. loss: 7.854998\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 4.62, NNZs: 44, Bias: -1.900519, T: 12800, Avg. loss: 8.339434\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 4.69, NNZs: 44, Bias: -1.938469, T: 13440, Avg. loss: 7.971242\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 4.70, NNZs: 44, Bias: -1.971390, T: 14080, Avg. loss: 6.846766\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.975878, T: 14720, Avg. loss: 1.909502\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 4.65, NNZs: 44, Bias: -1.981030, T: 15360, Avg. loss: 1.337327\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 4.64, NNZs: 44, Bias: -1.986973, T: 16000, Avg. loss: 1.095216\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 4.64, NNZs: 44, Bias: -1.991376, T: 16640, Avg. loss: 1.240920\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 4.63, NNZs: 44, Bias: -1.995282, T: 17280, Avg. loss: 1.152731\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.000016, T: 17920, Avg. loss: 1.129366\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.005264, T: 18560, Avg. loss: 1.114322\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.010318, T: 19200, Avg. loss: 1.112498\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 4.62, NNZs: 44, Bias: -2.010732, T: 19840, Avg. loss: 0.529010\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 4.62, NNZs: 44, Bias: -2.011248, T: 20480, Avg. loss: 0.383808\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.011636, T: 21120, Avg. loss: 0.347171\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.012246, T: 21760, Avg. loss: 0.332399\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.012706, T: 22400, Avg. loss: 0.351599\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.013156, T: 23040, Avg. loss: 0.337051\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.013751, T: 23680, Avg. loss: 0.323753\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.014291, T: 24320, Avg. loss: 0.316370\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.014850, T: 24960, Avg. loss: 0.306305\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.015305, T: 25600, Avg. loss: 0.349897\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.015810, T: 26240, Avg. loss: 0.322652\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.016303, T: 26880, Avg. loss: 0.284620\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.016802, T: 27520, Avg. loss: 0.341514\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.017296, T: 28160, Avg. loss: 0.334507\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.017880, T: 28800, Avg. loss: 0.307931\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.018483, T: 29440, Avg. loss: 0.334228\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019125, T: 30080, Avg. loss: 0.296572\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019163, T: 30720, Avg. loss: 0.224531\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019239, T: 31360, Avg. loss: 0.215501\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019339, T: 32000, Avg. loss: 0.227935\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019387, T: 32640, Avg. loss: 0.213606\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019489, T: 33280, Avg. loss: 0.218986\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019590, T: 33920, Avg. loss: 0.228519\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019696, T: 34560, Avg. loss: 0.219427\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019733, T: 35200, Avg. loss: 0.221081\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019877, T: 35840, Avg. loss: 0.221838\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019869, T: 36480, Avg. loss: 0.214944\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019888, T: 37120, Avg. loss: 0.209974\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019906, T: 37760, Avg. loss: 0.209764\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019922, T: 38400, Avg. loss: 0.207634\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019936, T: 39040, Avg. loss: 0.209592\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019947, T: 39680, Avg. loss: 0.208848\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019974, T: 40320, Avg. loss: 0.210157\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019986, T: 40960, Avg. loss: 0.208959\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020005, T: 41600, Avg. loss: 0.209884\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020008, T: 42240, Avg. loss: 0.205329\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020012, T: 42880, Avg. loss: 0.205593\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020015, T: 43520, Avg. loss: 0.205441\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020019, T: 44160, Avg. loss: 0.205546\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020022, T: 44800, Avg. loss: 0.205484\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020026, T: 45440, Avg. loss: 0.205467\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 71 epochs took 0.05 seconds\n",
      "--- training time 0.05745196342468262 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 3.92, NNZs: 44, Bias: -0.229017, T: 640, Avg. loss: 39.588520\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.22, NNZs: 44, Bias: -0.412678, T: 1280, Avg. loss: 36.358448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.77, NNZs: 44, Bias: -0.608724, T: 1920, Avg. loss: 37.326056\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.16, NNZs: 44, Bias: -0.820996, T: 2560, Avg. loss: 41.772040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.046754, T: 3200, Avg. loss: 40.525607\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.70, NNZs: 44, Bias: -1.233228, T: 3840, Avg. loss: 39.758304\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 6.79, NNZs: 44, Bias: -1.422213, T: 4480, Avg. loss: 39.742680\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 4.53, NNZs: 44, Bias: -1.450692, T: 5120, Avg. loss: 16.560021\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 4.10, NNZs: 44, Bias: -1.488961, T: 5760, Avg. loss: 9.079159\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 4.12, NNZs: 44, Bias: -1.526367, T: 6400, Avg. loss: 7.795266\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 4.13, NNZs: 44, Bias: -1.563871, T: 7040, Avg. loss: 7.278739\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 4.18, NNZs: 44, Bias: -1.597494, T: 7680, Avg. loss: 7.476793\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 4.20, NNZs: 44, Bias: -1.635171, T: 8320, Avg. loss: 6.880366\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 4.23, NNZs: 44, Bias: -1.670875, T: 8960, Avg. loss: 8.182257\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 4.29, NNZs: 44, Bias: -1.708758, T: 9600, Avg. loss: 7.790961\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 4.42, NNZs: 44, Bias: -1.745993, T: 10240, Avg. loss: 6.813259\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 4.53, NNZs: 44, Bias: -1.787712, T: 10880, Avg. loss: 6.377116\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 4.54, NNZs: 44, Bias: -1.826082, T: 11520, Avg. loss: 7.133107\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 4.61, NNZs: 44, Bias: -1.865045, T: 12160, Avg. loss: 7.854998\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 4.62, NNZs: 44, Bias: -1.900519, T: 12800, Avg. loss: 8.339434\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 4.69, NNZs: 44, Bias: -1.938469, T: 13440, Avg. loss: 7.971242\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 4.70, NNZs: 44, Bias: -1.971390, T: 14080, Avg. loss: 6.846766\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.975878, T: 14720, Avg. loss: 1.909502\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 4.65, NNZs: 44, Bias: -1.981030, T: 15360, Avg. loss: 1.337327\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 4.64, NNZs: 44, Bias: -1.986973, T: 16000, Avg. loss: 1.095216\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 4.64, NNZs: 44, Bias: -1.991376, T: 16640, Avg. loss: 1.240920\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 4.63, NNZs: 44, Bias: -1.995282, T: 17280, Avg. loss: 1.152731\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.000016, T: 17920, Avg. loss: 1.129366\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.005264, T: 18560, Avg. loss: 1.114322\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.010318, T: 19200, Avg. loss: 1.112498\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 4.62, NNZs: 44, Bias: -2.010732, T: 19840, Avg. loss: 0.529010\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 4.62, NNZs: 44, Bias: -2.011248, T: 20480, Avg. loss: 0.383808\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.011636, T: 21120, Avg. loss: 0.347171\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.012246, T: 21760, Avg. loss: 0.332399\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.012706, T: 22400, Avg. loss: 0.351599\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.013156, T: 23040, Avg. loss: 0.337051\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.013751, T: 23680, Avg. loss: 0.323753\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.014291, T: 24320, Avg. loss: 0.316370\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.014850, T: 24960, Avg. loss: 0.306305\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.015305, T: 25600, Avg. loss: 0.349897\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.015810, T: 26240, Avg. loss: 0.322652\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.016303, T: 26880, Avg. loss: 0.284620\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.016802, T: 27520, Avg. loss: 0.341514\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.017296, T: 28160, Avg. loss: 0.334507\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.017880, T: 28800, Avg. loss: 0.307931\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.018483, T: 29440, Avg. loss: 0.334228\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019125, T: 30080, Avg. loss: 0.296572\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019163, T: 30720, Avg. loss: 0.224531\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019239, T: 31360, Avg. loss: 0.215501\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019339, T: 32000, Avg. loss: 0.227935\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019387, T: 32640, Avg. loss: 0.213606\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019489, T: 33280, Avg. loss: 0.218986\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019590, T: 33920, Avg. loss: 0.228519\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019696, T: 34560, Avg. loss: 0.219427\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019733, T: 35200, Avg. loss: 0.221081\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019877, T: 35840, Avg. loss: 0.221838\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019869, T: 36480, Avg. loss: 0.214944\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019888, T: 37120, Avg. loss: 0.209974\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019906, T: 37760, Avg. loss: 0.209764\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019922, T: 38400, Avg. loss: 0.207634\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019936, T: 39040, Avg. loss: 0.209592\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019947, T: 39680, Avg. loss: 0.208848\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019974, T: 40320, Avg. loss: 0.210157\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019986, T: 40960, Avg. loss: 0.208959\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020005, T: 41600, Avg. loss: 0.209884\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020008, T: 42240, Avg. loss: 0.205329\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020012, T: 42880, Avg. loss: 0.205593\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020015, T: 43520, Avg. loss: 0.205441\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020019, T: 44160, Avg. loss: 0.205546\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020022, T: 44800, Avg. loss: 0.205484\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020026, T: 45440, Avg. loss: 0.205467\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 71 epochs took 0.02 seconds\n",
      "--- training time 0.02803802490234375 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 10.91, NNZs: 43, Bias: -2.550009, T: 640, Avg. loss: 402.389039\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.71, NNZs: 44, Bias: -5.050009, T: 1280, Avg. loss: 323.294791\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.46, NNZs: 44, Bias: -7.512515, T: 1920, Avg. loss: 359.311537\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.05, NNZs: 44, Bias: -10.201947, T: 2560, Avg. loss: 399.918189\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.69, NNZs: 44, Bias: -12.720222, T: 3200, Avg. loss: 361.718888\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.91, NNZs: 44, Bias: -14.880795, T: 3840, Avg. loss: 377.351976\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 19.10, NNZs: 44, Bias: -17.180424, T: 4480, Avg. loss: 376.820507\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.006345987319946289 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 10.91, NNZs: 43, Bias: -2.550009, T: 640, Avg. loss: 402.389039\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.71, NNZs: 44, Bias: -5.050009, T: 1280, Avg. loss: 323.294791\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.46, NNZs: 44, Bias: -7.512515, T: 1920, Avg. loss: 359.311537\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.05, NNZs: 44, Bias: -10.201947, T: 2560, Avg. loss: 399.918189\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.69, NNZs: 44, Bias: -12.720222, T: 3200, Avg. loss: 361.718888\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.91, NNZs: 44, Bias: -14.880795, T: 3840, Avg. loss: 377.351976\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 19.10, NNZs: 44, Bias: -17.180424, T: 4480, Avg. loss: 376.820507\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.006839275360107422 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 10.91, NNZs: 43, Bias: -2.550009, T: 640, Avg. loss: 402.389039\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.71, NNZs: 44, Bias: -5.050009, T: 1280, Avg. loss: 323.294791\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.46, NNZs: 44, Bias: -7.512515, T: 1920, Avg. loss: 359.311537\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.05, NNZs: 44, Bias: -10.201947, T: 2560, Avg. loss: 399.918189\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.69, NNZs: 44, Bias: -12.720222, T: 3200, Avg. loss: 361.718888\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.91, NNZs: 44, Bias: -14.880795, T: 3840, Avg. loss: 377.351976\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 19.10, NNZs: 44, Bias: -17.180424, T: 4480, Avg. loss: 376.820507\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.0068018436431884766 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 6.35, NNZs: 44, Bias: -1.994673, T: 640, Avg. loss: 189.614785\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.05, NNZs: 44, Bias: -2.217508, T: 1280, Avg. loss: 40.077763\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3.12, NNZs: 44, Bias: -2.340662, T: 1920, Avg. loss: 23.614151\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.03, NNZs: 44, Bias: -2.422736, T: 2560, Avg. loss: 19.441969\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.59, NNZs: 44, Bias: -2.496541, T: 3200, Avg. loss: 13.700437\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.98, NNZs: 44, Bias: -2.541821, T: 3840, Avg. loss: 10.579633\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.45, NNZs: 44, Bias: -2.583415, T: 4480, Avg. loss: 9.411084\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.40, NNZs: 44, Bias: -2.630032, T: 5120, Avg. loss: 8.216800\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.50, NNZs: 44, Bias: -2.663326, T: 5760, Avg. loss: 7.242535\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.36, NNZs: 44, Bias: -2.692023, T: 6400, Avg. loss: 5.980278\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.29, NNZs: 44, Bias: -2.721187, T: 7040, Avg. loss: 5.348994\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.22, NNZs: 44, Bias: -2.743549, T: 7680, Avg. loss: 4.803177\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1.12, NNZs: 44, Bias: -2.768479, T: 8320, Avg. loss: 4.859873\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1.13, NNZs: 44, Bias: -2.788927, T: 8960, Avg. loss: 4.464438\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1.08, NNZs: 44, Bias: -2.811251, T: 9600, Avg. loss: 4.280645\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1.15, NNZs: 44, Bias: -2.830171, T: 10240, Avg. loss: 3.587939\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1.08, NNZs: 44, Bias: -2.848824, T: 10880, Avg. loss: 2.990107\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1.10, NNZs: 44, Bias: -2.867765, T: 11520, Avg. loss: 3.350379\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 1.05, NNZs: 44, Bias: -2.884974, T: 12160, Avg. loss: 3.444854\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.04, NNZs: 44, Bias: -2.900045, T: 12800, Avg. loss: 2.998987\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.10, NNZs: 44, Bias: -2.915230, T: 13440, Avg. loss: 2.910877\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 1.03, NNZs: 44, Bias: -2.927017, T: 14080, Avg. loss: 2.422828\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 1.07, NNZs: 44, Bias: -2.937955, T: 14720, Avg. loss: 2.621666\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 1.04, NNZs: 44, Bias: -2.950331, T: 15360, Avg. loss: 2.301741\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 1.05, NNZs: 44, Bias: -2.963537, T: 16000, Avg. loss: 2.276732\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 1.01, NNZs: 44, Bias: -2.972981, T: 16640, Avg. loss: 1.978905\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 1.03, NNZs: 44, Bias: -2.980866, T: 17280, Avg. loss: 2.065030\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.99, NNZs: 44, Bias: -2.991051, T: 17920, Avg. loss: 1.902420\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.00, NNZs: 44, Bias: -3.000799, T: 18560, Avg. loss: 1.688780\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.00, NNZs: 44, Bias: -3.010344, T: 19200, Avg. loss: 1.746155\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1.01, NNZs: 44, Bias: -3.018024, T: 19840, Avg. loss: 1.738377\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.026440, T: 20480, Avg. loss: 1.826953\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.032298, T: 21120, Avg. loss: 1.469212\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.041144, T: 21760, Avg. loss: 1.603329\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.049891, T: 22400, Avg. loss: 1.556712\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.99, NNZs: 44, Bias: -3.057867, T: 23040, Avg. loss: 1.499409\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.065866, T: 23680, Avg. loss: 1.552223\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.073255, T: 24320, Avg. loss: 1.350029\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.079636, T: 24960, Avg. loss: 1.202499\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.96, NNZs: 44, Bias: -3.085880, T: 25600, Avg. loss: 1.325216\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.96, NNZs: 44, Bias: -3.091427, T: 26240, Avg. loss: 1.228914\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.096794, T: 26880, Avg. loss: 1.123186\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.102410, T: 27520, Avg. loss: 1.207042\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.108396, T: 28160, Avg. loss: 1.183111\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.115113, T: 28800, Avg. loss: 1.183820\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.120594, T: 29440, Avg. loss: 1.158029\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.127762, T: 30080, Avg. loss: 1.112647\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.132704, T: 30720, Avg. loss: 0.996212\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.137911, T: 31360, Avg. loss: 0.994590\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.93, NNZs: 44, Bias: -3.142994, T: 32000, Avg. loss: 1.090287\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.93, NNZs: 44, Bias: -3.147777, T: 32640, Avg. loss: 0.860229\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.151914, T: 33280, Avg. loss: 0.912170\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.93, NNZs: 44, Bias: -3.157041, T: 33920, Avg. loss: 0.980728\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.161423, T: 34560, Avg. loss: 0.904690\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.165488, T: 35200, Avg. loss: 0.944352\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.170430, T: 35840, Avg. loss: 0.842694\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.174331, T: 36480, Avg. loss: 0.944322\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.178124, T: 37120, Avg. loss: 0.781941\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.181930, T: 37760, Avg. loss: 0.884373\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.187088, T: 38400, Avg. loss: 0.870619\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.90, NNZs: 44, Bias: -3.190889, T: 39040, Avg. loss: 0.779619\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.90, NNZs: 44, Bias: -3.194808, T: 39680, Avg. loss: 0.654711\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.90, NNZs: 44, Bias: -3.198546, T: 40320, Avg. loss: 0.780250\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.89, NNZs: 44, Bias: -3.201925, T: 40960, Avg. loss: 0.800828\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.89, NNZs: 44, Bias: -3.205871, T: 41600, Avg. loss: 0.675419\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.89, NNZs: 44, Bias: -3.209167, T: 42240, Avg. loss: 0.707917\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.213082, T: 42880, Avg. loss: 0.645659\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.216838, T: 43520, Avg. loss: 0.806701\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.219861, T: 44160, Avg. loss: 0.591332\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.223250, T: 44800, Avg. loss: 0.737523\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.226684, T: 45440, Avg. loss: 0.697447\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.87, NNZs: 44, Bias: -3.229653, T: 46080, Avg. loss: 0.670614\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.87, NNZs: 44, Bias: -3.232981, T: 46720, Avg. loss: 0.653457\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.87, NNZs: 44, Bias: -3.236241, T: 47360, Avg. loss: 0.691059\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 74 epochs took 0.05 seconds\n",
      "--- training time 0.0535123348236084 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 6.35, NNZs: 44, Bias: -1.994673, T: 640, Avg. loss: 189.614785\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.05, NNZs: 44, Bias: -2.217508, T: 1280, Avg. loss: 40.077763\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3.12, NNZs: 44, Bias: -2.340662, T: 1920, Avg. loss: 23.614151\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.03, NNZs: 44, Bias: -2.422736, T: 2560, Avg. loss: 19.441969\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.59, NNZs: 44, Bias: -2.496541, T: 3200, Avg. loss: 13.700437\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.98, NNZs: 44, Bias: -2.541821, T: 3840, Avg. loss: 10.579633\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.45, NNZs: 44, Bias: -2.583415, T: 4480, Avg. loss: 9.411084\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.40, NNZs: 44, Bias: -2.630032, T: 5120, Avg. loss: 8.216800\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.50, NNZs: 44, Bias: -2.663326, T: 5760, Avg. loss: 7.242535\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.36, NNZs: 44, Bias: -2.692023, T: 6400, Avg. loss: 5.980278\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.29, NNZs: 44, Bias: -2.721187, T: 7040, Avg. loss: 5.348994\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.22, NNZs: 44, Bias: -2.743549, T: 7680, Avg. loss: 4.803177\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1.12, NNZs: 44, Bias: -2.768479, T: 8320, Avg. loss: 4.859873\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1.13, NNZs: 44, Bias: -2.788927, T: 8960, Avg. loss: 4.464438\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1.08, NNZs: 44, Bias: -2.811251, T: 9600, Avg. loss: 4.280645\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1.15, NNZs: 44, Bias: -2.830171, T: 10240, Avg. loss: 3.587939\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1.08, NNZs: 44, Bias: -2.848824, T: 10880, Avg. loss: 2.990107\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1.10, NNZs: 44, Bias: -2.867765, T: 11520, Avg. loss: 3.350379\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 1.05, NNZs: 44, Bias: -2.884974, T: 12160, Avg. loss: 3.444854\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.04, NNZs: 44, Bias: -2.900045, T: 12800, Avg. loss: 2.998987\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.10, NNZs: 44, Bias: -2.915230, T: 13440, Avg. loss: 2.910877\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 1.03, NNZs: 44, Bias: -2.927017, T: 14080, Avg. loss: 2.422828\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 1.07, NNZs: 44, Bias: -2.937955, T: 14720, Avg. loss: 2.621666\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 1.04, NNZs: 44, Bias: -2.950331, T: 15360, Avg. loss: 2.301741\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 1.05, NNZs: 44, Bias: -2.963537, T: 16000, Avg. loss: 2.276732\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 1.01, NNZs: 44, Bias: -2.972981, T: 16640, Avg. loss: 1.978905\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 1.03, NNZs: 44, Bias: -2.980866, T: 17280, Avg. loss: 2.065030\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.99, NNZs: 44, Bias: -2.991051, T: 17920, Avg. loss: 1.902420\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.00, NNZs: 44, Bias: -3.000799, T: 18560, Avg. loss: 1.688780\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.00, NNZs: 44, Bias: -3.010344, T: 19200, Avg. loss: 1.746155\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1.01, NNZs: 44, Bias: -3.018024, T: 19840, Avg. loss: 1.738377\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.026440, T: 20480, Avg. loss: 1.826953\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.032298, T: 21120, Avg. loss: 1.469212\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.041144, T: 21760, Avg. loss: 1.603329\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.049891, T: 22400, Avg. loss: 1.556712\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.99, NNZs: 44, Bias: -3.057867, T: 23040, Avg. loss: 1.499409\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.065866, T: 23680, Avg. loss: 1.552223\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.073255, T: 24320, Avg. loss: 1.350029\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.079636, T: 24960, Avg. loss: 1.202499\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.96, NNZs: 44, Bias: -3.085880, T: 25600, Avg. loss: 1.325216\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.96, NNZs: 44, Bias: -3.091427, T: 26240, Avg. loss: 1.228914\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.096794, T: 26880, Avg. loss: 1.123186\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.102410, T: 27520, Avg. loss: 1.207042\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.108396, T: 28160, Avg. loss: 1.183111\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.115113, T: 28800, Avg. loss: 1.183820\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.120594, T: 29440, Avg. loss: 1.158029\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.127762, T: 30080, Avg. loss: 1.112647\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.132704, T: 30720, Avg. loss: 0.996212\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.137911, T: 31360, Avg. loss: 0.994590\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.93, NNZs: 44, Bias: -3.142994, T: 32000, Avg. loss: 1.090287\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.93, NNZs: 44, Bias: -3.147777, T: 32640, Avg. loss: 0.860229\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.151914, T: 33280, Avg. loss: 0.912170\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.93, NNZs: 44, Bias: -3.157041, T: 33920, Avg. loss: 0.980728\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.161423, T: 34560, Avg. loss: 0.904690\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.165488, T: 35200, Avg. loss: 0.944352\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.170430, T: 35840, Avg. loss: 0.842694\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.174331, T: 36480, Avg. loss: 0.944322\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.178124, T: 37120, Avg. loss: 0.781941\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.181930, T: 37760, Avg. loss: 0.884373\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.187088, T: 38400, Avg. loss: 0.870619\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.90, NNZs: 44, Bias: -3.190889, T: 39040, Avg. loss: 0.779619\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.90, NNZs: 44, Bias: -3.194808, T: 39680, Avg. loss: 0.654711\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.90, NNZs: 44, Bias: -3.198546, T: 40320, Avg. loss: 0.780250\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.89, NNZs: 44, Bias: -3.201925, T: 40960, Avg. loss: 0.800828\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.89, NNZs: 44, Bias: -3.205871, T: 41600, Avg. loss: 0.675419\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.89, NNZs: 44, Bias: -3.209167, T: 42240, Avg. loss: 0.707917\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.213082, T: 42880, Avg. loss: 0.645659\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.216838, T: 43520, Avg. loss: 0.806701\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.219861, T: 44160, Avg. loss: 0.591332\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.223250, T: 44800, Avg. loss: 0.737523\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.226684, T: 45440, Avg. loss: 0.697447\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.87, NNZs: 44, Bias: -3.229653, T: 46080, Avg. loss: 0.670614\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.87, NNZs: 44, Bias: -3.232981, T: 46720, Avg. loss: 0.653457\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.87, NNZs: 44, Bias: -3.236241, T: 47360, Avg. loss: 0.691059\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 74 epochs took 0.02 seconds\n",
      "--- training time 0.02651381492614746 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 6.35, NNZs: 44, Bias: -1.994673, T: 640, Avg. loss: 189.614785\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.05, NNZs: 44, Bias: -2.217508, T: 1280, Avg. loss: 40.077763\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3.12, NNZs: 44, Bias: -2.340662, T: 1920, Avg. loss: 23.614151\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.03, NNZs: 44, Bias: -2.422736, T: 2560, Avg. loss: 19.441969\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.59, NNZs: 44, Bias: -2.496541, T: 3200, Avg. loss: 13.700437\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.98, NNZs: 44, Bias: -2.541821, T: 3840, Avg. loss: 10.579633\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.45, NNZs: 44, Bias: -2.583415, T: 4480, Avg. loss: 9.411084\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.40, NNZs: 44, Bias: -2.630032, T: 5120, Avg. loss: 8.216800\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.50, NNZs: 44, Bias: -2.663326, T: 5760, Avg. loss: 7.242535\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.36, NNZs: 44, Bias: -2.692023, T: 6400, Avg. loss: 5.980278\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.29, NNZs: 44, Bias: -2.721187, T: 7040, Avg. loss: 5.348994\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.22, NNZs: 44, Bias: -2.743549, T: 7680, Avg. loss: 4.803177\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1.12, NNZs: 44, Bias: -2.768479, T: 8320, Avg. loss: 4.859873\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1.13, NNZs: 44, Bias: -2.788927, T: 8960, Avg. loss: 4.464438\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1.08, NNZs: 44, Bias: -2.811251, T: 9600, Avg. loss: 4.280645\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1.15, NNZs: 44, Bias: -2.830171, T: 10240, Avg. loss: 3.587939\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1.08, NNZs: 44, Bias: -2.848824, T: 10880, Avg. loss: 2.990107\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1.10, NNZs: 44, Bias: -2.867765, T: 11520, Avg. loss: 3.350379\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 1.05, NNZs: 44, Bias: -2.884974, T: 12160, Avg. loss: 3.444854\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.04, NNZs: 44, Bias: -2.900045, T: 12800, Avg. loss: 2.998987\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.10, NNZs: 44, Bias: -2.915230, T: 13440, Avg. loss: 2.910877\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 1.03, NNZs: 44, Bias: -2.927017, T: 14080, Avg. loss: 2.422828\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 1.07, NNZs: 44, Bias: -2.937955, T: 14720, Avg. loss: 2.621666\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 1.04, NNZs: 44, Bias: -2.950331, T: 15360, Avg. loss: 2.301741\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 1.05, NNZs: 44, Bias: -2.963537, T: 16000, Avg. loss: 2.276732\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 1.01, NNZs: 44, Bias: -2.972981, T: 16640, Avg. loss: 1.978905\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 1.03, NNZs: 44, Bias: -2.980866, T: 17280, Avg. loss: 2.065030\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.99, NNZs: 44, Bias: -2.991051, T: 17920, Avg. loss: 1.902420\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.00, NNZs: 44, Bias: -3.000799, T: 18560, Avg. loss: 1.688780\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.00, NNZs: 44, Bias: -3.010344, T: 19200, Avg. loss: 1.746155\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1.01, NNZs: 44, Bias: -3.018024, T: 19840, Avg. loss: 1.738377\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.026440, T: 20480, Avg. loss: 1.826953\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.032298, T: 21120, Avg. loss: 1.469212\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.041144, T: 21760, Avg. loss: 1.603329\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.049891, T: 22400, Avg. loss: 1.556712\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.99, NNZs: 44, Bias: -3.057867, T: 23040, Avg. loss: 1.499409\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.065866, T: 23680, Avg. loss: 1.552223\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.073255, T: 24320, Avg. loss: 1.350029\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.079636, T: 24960, Avg. loss: 1.202499\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.96, NNZs: 44, Bias: -3.085880, T: 25600, Avg. loss: 1.325216\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.96, NNZs: 44, Bias: -3.091427, T: 26240, Avg. loss: 1.228914\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.096794, T: 26880, Avg. loss: 1.123186\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.102410, T: 27520, Avg. loss: 1.207042\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.108396, T: 28160, Avg. loss: 1.183111\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.115113, T: 28800, Avg. loss: 1.183820\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.120594, T: 29440, Avg. loss: 1.158029\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.127762, T: 30080, Avg. loss: 1.112647\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.132704, T: 30720, Avg. loss: 0.996212\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.137911, T: 31360, Avg. loss: 0.994590\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.93, NNZs: 44, Bias: -3.142994, T: 32000, Avg. loss: 1.090287\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.93, NNZs: 44, Bias: -3.147777, T: 32640, Avg. loss: 0.860229\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.151914, T: 33280, Avg. loss: 0.912170\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.93, NNZs: 44, Bias: -3.157041, T: 33920, Avg. loss: 0.980728\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.161423, T: 34560, Avg. loss: 0.904690\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.165488, T: 35200, Avg. loss: 0.944352\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.170430, T: 35840, Avg. loss: 0.842694\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.174331, T: 36480, Avg. loss: 0.944322\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.178124, T: 37120, Avg. loss: 0.781941\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.181930, T: 37760, Avg. loss: 0.884373\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.187088, T: 38400, Avg. loss: 0.870619\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.90, NNZs: 44, Bias: -3.190889, T: 39040, Avg. loss: 0.779619\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.90, NNZs: 44, Bias: -3.194808, T: 39680, Avg. loss: 0.654711\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.90, NNZs: 44, Bias: -3.198546, T: 40320, Avg. loss: 0.780250\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.89, NNZs: 44, Bias: -3.201925, T: 40960, Avg. loss: 0.800828\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.89, NNZs: 44, Bias: -3.205871, T: 41600, Avg. loss: 0.675419\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.89, NNZs: 44, Bias: -3.209167, T: 42240, Avg. loss: 0.707917\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.213082, T: 42880, Avg. loss: 0.645659\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.216838, T: 43520, Avg. loss: 0.806701\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.219861, T: 44160, Avg. loss: 0.591332\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.223250, T: 44800, Avg. loss: 0.737523\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.226684, T: 45440, Avg. loss: 0.697447\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.87, NNZs: 44, Bias: -3.229653, T: 46080, Avg. loss: 0.670614\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.87, NNZs: 44, Bias: -3.232981, T: 46720, Avg. loss: 0.653457\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.87, NNZs: 44, Bias: -3.236241, T: 47360, Avg. loss: 0.691059\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 74 epochs took 0.04 seconds\n",
      "--- training time 0.047477006912231445 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 1.81, NNZs: 44, Bias: -0.132429, T: 640, Avg. loss: 30.907784\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.39, NNZs: 44, Bias: -0.188078, T: 1280, Avg. loss: 10.660232\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.25, NNZs: 44, Bias: -0.238202, T: 1920, Avg. loss: 9.212930\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.276557, T: 2560, Avg. loss: 9.238287\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.316699, T: 3200, Avg. loss: 7.258781\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.20, NNZs: 44, Bias: -0.346927, T: 3840, Avg. loss: 6.083062\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.05, NNZs: 44, Bias: -0.377001, T: 4480, Avg. loss: 6.074865\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.405743, T: 5120, Avg. loss: 5.408817\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.05, NNZs: 44, Bias: -0.434407, T: 5760, Avg. loss: 5.172337\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.07, NNZs: 44, Bias: -0.459415, T: 6400, Avg. loss: 4.729603\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.08, NNZs: 44, Bias: -0.484385, T: 7040, Avg. loss: 4.626073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.505227, T: 7680, Avg. loss: 4.504605\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.529476, T: 8320, Avg. loss: 3.886199\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.548966, T: 8960, Avg. loss: 4.488182\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.574013, T: 9600, Avg. loss: 4.301054\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1.06, NNZs: 44, Bias: -0.594354, T: 10240, Avg. loss: 3.785013\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.616599, T: 10880, Avg. loss: 3.399852\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.636243, T: 11520, Avg. loss: 3.280211\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.96, NNZs: 44, Bias: -0.654038, T: 12160, Avg. loss: 3.690596\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.671599, T: 12800, Avg. loss: 3.693993\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.689654, T: 13440, Avg. loss: 3.407431\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.705857, T: 14080, Avg. loss: 2.926440\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.720351, T: 14720, Avg. loss: 3.038130\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.736537, T: 15360, Avg. loss: 3.017863\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.751568, T: 16000, Avg. loss: 2.732331\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.766843, T: 16640, Avg. loss: 2.835467\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.779676, T: 17280, Avg. loss: 2.794700\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.795386, T: 17920, Avg. loss: 2.689158\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.809601, T: 18560, Avg. loss: 2.586526\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.06, NNZs: 44, Bias: -0.827178, T: 19200, Avg. loss: 2.624687\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.839258, T: 19840, Avg. loss: 2.743357\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.852483, T: 20480, Avg. loss: 2.547765\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.862580, T: 21120, Avg. loss: 2.184022\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.875723, T: 21760, Avg. loss: 2.496151\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.890938, T: 22400, Avg. loss: 2.564650\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.904156, T: 23040, Avg. loss: 2.505766\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.917612, T: 23680, Avg. loss: 2.671161\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.930996, T: 24320, Avg. loss: 2.351704\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 38 epochs took 0.01 seconds\n",
      "--- training time 0.01464700698852539 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 1.81, NNZs: 44, Bias: -0.132429, T: 640, Avg. loss: 30.907784\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.39, NNZs: 44, Bias: -0.188078, T: 1280, Avg. loss: 10.660232\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.25, NNZs: 44, Bias: -0.238202, T: 1920, Avg. loss: 9.212930\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.276557, T: 2560, Avg. loss: 9.238287\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.316699, T: 3200, Avg. loss: 7.258781\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.20, NNZs: 44, Bias: -0.346927, T: 3840, Avg. loss: 6.083062\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.05, NNZs: 44, Bias: -0.377001, T: 4480, Avg. loss: 6.074865\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.405743, T: 5120, Avg. loss: 5.408817\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.05, NNZs: 44, Bias: -0.434407, T: 5760, Avg. loss: 5.172337\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.07, NNZs: 44, Bias: -0.459415, T: 6400, Avg. loss: 4.729603\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.08, NNZs: 44, Bias: -0.484385, T: 7040, Avg. loss: 4.626073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.505227, T: 7680, Avg. loss: 4.504605\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.529476, T: 8320, Avg. loss: 3.886199\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.548966, T: 8960, Avg. loss: 4.488182\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.574013, T: 9600, Avg. loss: 4.301054\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1.06, NNZs: 44, Bias: -0.594354, T: 10240, Avg. loss: 3.785013\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.616599, T: 10880, Avg. loss: 3.399852\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.636243, T: 11520, Avg. loss: 3.280211\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.96, NNZs: 44, Bias: -0.654038, T: 12160, Avg. loss: 3.690596\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.671599, T: 12800, Avg. loss: 3.693993\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.689654, T: 13440, Avg. loss: 3.407431\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.705857, T: 14080, Avg. loss: 2.926440\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.720351, T: 14720, Avg. loss: 3.038130\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.736537, T: 15360, Avg. loss: 3.017863\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.751568, T: 16000, Avg. loss: 2.732331\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.766843, T: 16640, Avg. loss: 2.835467\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.779676, T: 17280, Avg. loss: 2.794700\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.795386, T: 17920, Avg. loss: 2.689158\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.809601, T: 18560, Avg. loss: 2.586526\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.06, NNZs: 44, Bias: -0.827178, T: 19200, Avg. loss: 2.624687\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.839258, T: 19840, Avg. loss: 2.743357\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.852483, T: 20480, Avg. loss: 2.547765\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.862580, T: 21120, Avg. loss: 2.184022\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.875723, T: 21760, Avg. loss: 2.496151\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.890938, T: 22400, Avg. loss: 2.564650\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.904156, T: 23040, Avg. loss: 2.505766\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.917612, T: 23680, Avg. loss: 2.671161\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.930996, T: 24320, Avg. loss: 2.351704\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 38 epochs took 0.01 seconds\n",
      "--- training time 0.015801191329956055 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 1.81, NNZs: 44, Bias: -0.132429, T: 640, Avg. loss: 30.907784\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.39, NNZs: 44, Bias: -0.188078, T: 1280, Avg. loss: 10.660232\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.25, NNZs: 44, Bias: -0.238202, T: 1920, Avg. loss: 9.212930\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.276557, T: 2560, Avg. loss: 9.238287\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.316699, T: 3200, Avg. loss: 7.258781\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.20, NNZs: 44, Bias: -0.346927, T: 3840, Avg. loss: 6.083062\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.05, NNZs: 44, Bias: -0.377001, T: 4480, Avg. loss: 6.074865\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.405743, T: 5120, Avg. loss: 5.408817\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.05, NNZs: 44, Bias: -0.434407, T: 5760, Avg. loss: 5.172337\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.07, NNZs: 44, Bias: -0.459415, T: 6400, Avg. loss: 4.729603\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.08, NNZs: 44, Bias: -0.484385, T: 7040, Avg. loss: 4.626073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.505227, T: 7680, Avg. loss: 4.504605\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.529476, T: 8320, Avg. loss: 3.886199\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.548966, T: 8960, Avg. loss: 4.488182\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.574013, T: 9600, Avg. loss: 4.301054\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1.06, NNZs: 44, Bias: -0.594354, T: 10240, Avg. loss: 3.785013\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.616599, T: 10880, Avg. loss: 3.399852\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.636243, T: 11520, Avg. loss: 3.280211\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.96, NNZs: 44, Bias: -0.654038, T: 12160, Avg. loss: 3.690596\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.671599, T: 12800, Avg. loss: 3.693993\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.689654, T: 13440, Avg. loss: 3.407431\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.705857, T: 14080, Avg. loss: 2.926440\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.720351, T: 14720, Avg. loss: 3.038130\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.736537, T: 15360, Avg. loss: 3.017863\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.751568, T: 16000, Avg. loss: 2.732331\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.766843, T: 16640, Avg. loss: 2.835467\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.779676, T: 17280, Avg. loss: 2.794700\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.795386, T: 17920, Avg. loss: 2.689158\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.809601, T: 18560, Avg. loss: 2.586526\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.06, NNZs: 44, Bias: -0.827178, T: 19200, Avg. loss: 2.624687\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.839258, T: 19840, Avg. loss: 2.743357\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.852483, T: 20480, Avg. loss: 2.547765\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.862580, T: 21120, Avg. loss: 2.184022\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.875723, T: 21760, Avg. loss: 2.496151\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.890938, T: 22400, Avg. loss: 2.564650\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.904156, T: 23040, Avg. loss: 2.505766\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.917612, T: 23680, Avg. loss: 2.671161\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.930996, T: 24320, Avg. loss: 2.351704\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 38 epochs took 0.01 seconds\n",
      "--- training time 0.018957853317260742 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 10.91, NNZs: 43, Bias: -2.550009, T: 640, Avg. loss: 402.389039\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.71, NNZs: 44, Bias: -5.050009, T: 1280, Avg. loss: 323.294791\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.46, NNZs: 44, Bias: -7.512515, T: 1920, Avg. loss: 359.311537\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.05, NNZs: 44, Bias: -10.201947, T: 2560, Avg. loss: 399.918189\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.69, NNZs: 44, Bias: -12.720222, T: 3200, Avg. loss: 361.718888\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.91, NNZs: 44, Bias: -14.880795, T: 3840, Avg. loss: 377.351976\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 19.10, NNZs: 44, Bias: -17.180424, T: 4480, Avg. loss: 376.820507\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 5.86, NNZs: 44, Bias: -17.603116, T: 5120, Avg. loss: 83.034376\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 9.02, NNZs: 44, Bias: -18.059716, T: 5760, Avg. loss: 72.589001\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 7.08, NNZs: 44, Bias: -18.459718, T: 6400, Avg. loss: 68.394544\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 7.82, NNZs: 44, Bias: -18.920503, T: 7040, Avg. loss: 75.816719\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 9.16, NNZs: 44, Bias: -19.338538, T: 7680, Avg. loss: 82.091663\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 6.28, NNZs: 44, Bias: -19.866070, T: 8320, Avg. loss: 80.338302\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 8.67, NNZs: 44, Bias: -20.249927, T: 8960, Avg. loss: 77.763763\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 6.72, NNZs: 44, Bias: -20.783372, T: 9600, Avg. loss: 84.528284\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 2.60, NNZs: 44, Bias: -20.831906, T: 10240, Avg. loss: 21.081200\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 2.52, NNZs: 44, Bias: -20.915984, T: 10880, Avg. loss: 13.879038\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 2.16, NNZs: 44, Bias: -20.997294, T: 11520, Avg. loss: 14.867438\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 1.96, NNZs: 44, Bias: -21.073347, T: 12160, Avg. loss: 15.247984\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.67, NNZs: 44, Bias: -21.147747, T: 12800, Avg. loss: 15.697421\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.95, NNZs: 44, Bias: -21.221151, T: 13440, Avg. loss: 15.912261\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 1.86, NNZs: 44, Bias: -21.289947, T: 14080, Avg. loss: 13.323098\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 2.05, NNZs: 44, Bias: -21.355879, T: 14720, Avg. loss: 15.670591\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 2.38, NNZs: 44, Bias: -21.439276, T: 15360, Avg. loss: 14.048558\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 2.40, NNZs: 44, Bias: -21.531538, T: 16000, Avg. loss: 15.405405\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 1.73, NNZs: 44, Bias: -21.595660, T: 16640, Avg. loss: 15.098512\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 2.46, NNZs: 44, Bias: -21.656147, T: 17280, Avg. loss: 14.324409\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1.48, NNZs: 44, Bias: -21.665591, T: 17920, Avg. loss: 5.804966\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.08, NNZs: 44, Bias: -21.673279, T: 18560, Avg. loss: 2.931253\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.02, NNZs: 44, Bias: -21.683801, T: 19200, Avg. loss: 2.375622\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.99, NNZs: 44, Bias: -21.692709, T: 19840, Avg. loss: 2.414061\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.95, NNZs: 44, Bias: -21.702718, T: 20480, Avg. loss: 2.667215\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.95, NNZs: 44, Bias: -21.708766, T: 21120, Avg. loss: 2.440674\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.720001, T: 21760, Avg. loss: 2.313048\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.732348, T: 22400, Avg. loss: 2.643310\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.742019, T: 23040, Avg. loss: 2.435969\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.90, NNZs: 44, Bias: -21.752661, T: 23680, Avg. loss: 2.758176\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.90, NNZs: 44, Bias: -21.763259, T: 24320, Avg. loss: 2.249982\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.91, NNZs: 44, Bias: -21.772147, T: 24960, Avg. loss: 2.264457\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.89, NNZs: 44, Bias: -21.780717, T: 25600, Avg. loss: 2.408183\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.87, NNZs: 44, Bias: -21.788835, T: 26240, Avg. loss: 2.288684\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.86, NNZs: 44, Bias: -21.796010, T: 26880, Avg. loss: 2.150486\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.88, NNZs: 44, Bias: -21.804099, T: 27520, Avg. loss: 2.213629\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.84, NNZs: 44, Bias: -21.813593, T: 28160, Avg. loss: 2.698464\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.85, NNZs: 44, Bias: -21.824923, T: 28800, Avg. loss: 2.531753\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.86, NNZs: 44, Bias: -21.835083, T: 29440, Avg. loss: 2.314919\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.87, NNZs: 44, Bias: -21.847257, T: 30080, Avg. loss: 2.572171\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.83, NNZs: 44, Bias: -21.847102, T: 30720, Avg. loss: 0.727465\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.81, NNZs: 44, Bias: -21.847476, T: 31360, Avg. loss: 0.394332\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.81, NNZs: 44, Bias: -21.847750, T: 32000, Avg. loss: 0.347348\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.80, NNZs: 44, Bias: -21.848207, T: 32640, Avg. loss: 0.294411\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.79, NNZs: 44, Bias: -21.848611, T: 33280, Avg. loss: 0.313080\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.78, NNZs: 44, Bias: -21.849179, T: 33920, Avg. loss: 0.338814\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.78, NNZs: 44, Bias: -21.849595, T: 34560, Avg. loss: 0.311426\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.77, NNZs: 44, Bias: -21.850114, T: 35200, Avg. loss: 0.278903\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.76, NNZs: 44, Bias: -21.850544, T: 35840, Avg. loss: 0.323347\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.76, NNZs: 44, Bias: -21.850999, T: 36480, Avg. loss: 0.285556\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.75, NNZs: 44, Bias: -21.851467, T: 37120, Avg. loss: 0.311541\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.75, NNZs: 44, Bias: -21.851826, T: 37760, Avg. loss: 0.333364\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.75, NNZs: 44, Bias: -21.852213, T: 38400, Avg. loss: 0.332154\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852266, T: 39040, Avg. loss: 0.133484\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852265, T: 39680, Avg. loss: 0.124933\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852264, T: 40320, Avg. loss: 0.134122\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852245, T: 40960, Avg. loss: 0.124002\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852247, T: 41600, Avg. loss: 0.126805\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852262, T: 42240, Avg. loss: 0.126852\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852263, T: 42880, Avg. loss: 0.125756\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852229, T: 43520, Avg. loss: 0.106021\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852226, T: 44160, Avg. loss: 0.103396\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852218, T: 44800, Avg. loss: 0.104170\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852229, T: 45440, Avg. loss: 0.105322\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852224, T: 46080, Avg. loss: 0.105754\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852236, T: 46720, Avg. loss: 0.101491\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852229, T: 47360, Avg. loss: 0.104941\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852214, T: 48000, Avg. loss: 0.105051\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852213, T: 48640, Avg. loss: 0.105558\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852203, T: 49280, Avg. loss: 0.104789\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852202, T: 49920, Avg. loss: 0.104441\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 50560, Avg. loss: 0.100782\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 51200, Avg. loss: 0.100245\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852208, T: 51840, Avg. loss: 0.100183\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 52480, Avg. loss: 0.100279\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852208, T: 53120, Avg. loss: 0.099715\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852208, T: 53760, Avg. loss: 0.099310\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 54400, Avg. loss: 0.099242\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 55040, Avg. loss: 0.099155\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852206, T: 55680, Avg. loss: 0.099177\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852206, T: 56320, Avg. loss: 0.099165\n",
      "Total training time: 0.05 seconds.\n",
      "Convergence after 88 epochs took 0.05 seconds\n",
      "--- training time 0.05376577377319336 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 10.91, NNZs: 43, Bias: -2.550009, T: 640, Avg. loss: 402.389039\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.71, NNZs: 44, Bias: -5.050009, T: 1280, Avg. loss: 323.294791\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.46, NNZs: 44, Bias: -7.512515, T: 1920, Avg. loss: 359.311537\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.05, NNZs: 44, Bias: -10.201947, T: 2560, Avg. loss: 399.918189\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.69, NNZs: 44, Bias: -12.720222, T: 3200, Avg. loss: 361.718888\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.91, NNZs: 44, Bias: -14.880795, T: 3840, Avg. loss: 377.351976\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 19.10, NNZs: 44, Bias: -17.180424, T: 4480, Avg. loss: 376.820507\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 5.86, NNZs: 44, Bias: -17.603116, T: 5120, Avg. loss: 83.034376\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 9.02, NNZs: 44, Bias: -18.059716, T: 5760, Avg. loss: 72.589001\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 7.08, NNZs: 44, Bias: -18.459718, T: 6400, Avg. loss: 68.394544\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 7.82, NNZs: 44, Bias: -18.920503, T: 7040, Avg. loss: 75.816719\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 9.16, NNZs: 44, Bias: -19.338538, T: 7680, Avg. loss: 82.091663\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 6.28, NNZs: 44, Bias: -19.866070, T: 8320, Avg. loss: 80.338302\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 8.67, NNZs: 44, Bias: -20.249927, T: 8960, Avg. loss: 77.763763\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 6.72, NNZs: 44, Bias: -20.783372, T: 9600, Avg. loss: 84.528284\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 2.60, NNZs: 44, Bias: -20.831906, T: 10240, Avg. loss: 21.081200\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 2.52, NNZs: 44, Bias: -20.915984, T: 10880, Avg. loss: 13.879038\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 2.16, NNZs: 44, Bias: -20.997294, T: 11520, Avg. loss: 14.867438\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 1.96, NNZs: 44, Bias: -21.073347, T: 12160, Avg. loss: 15.247984\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.67, NNZs: 44, Bias: -21.147747, T: 12800, Avg. loss: 15.697421\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.95, NNZs: 44, Bias: -21.221151, T: 13440, Avg. loss: 15.912261\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 1.86, NNZs: 44, Bias: -21.289947, T: 14080, Avg. loss: 13.323098\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 2.05, NNZs: 44, Bias: -21.355879, T: 14720, Avg. loss: 15.670591\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 2.38, NNZs: 44, Bias: -21.439276, T: 15360, Avg. loss: 14.048558\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 2.40, NNZs: 44, Bias: -21.531538, T: 16000, Avg. loss: 15.405405\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 1.73, NNZs: 44, Bias: -21.595660, T: 16640, Avg. loss: 15.098512\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 2.46, NNZs: 44, Bias: -21.656147, T: 17280, Avg. loss: 14.324409\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1.48, NNZs: 44, Bias: -21.665591, T: 17920, Avg. loss: 5.804966\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.08, NNZs: 44, Bias: -21.673279, T: 18560, Avg. loss: 2.931253\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.02, NNZs: 44, Bias: -21.683801, T: 19200, Avg. loss: 2.375622\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.99, NNZs: 44, Bias: -21.692709, T: 19840, Avg. loss: 2.414061\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.95, NNZs: 44, Bias: -21.702718, T: 20480, Avg. loss: 2.667215\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.95, NNZs: 44, Bias: -21.708766, T: 21120, Avg. loss: 2.440674\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.720001, T: 21760, Avg. loss: 2.313048\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.732348, T: 22400, Avg. loss: 2.643310\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.742019, T: 23040, Avg. loss: 2.435969\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.90, NNZs: 44, Bias: -21.752661, T: 23680, Avg. loss: 2.758176\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.90, NNZs: 44, Bias: -21.763259, T: 24320, Avg. loss: 2.249982\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.91, NNZs: 44, Bias: -21.772147, T: 24960, Avg. loss: 2.264457\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.89, NNZs: 44, Bias: -21.780717, T: 25600, Avg. loss: 2.408183\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.87, NNZs: 44, Bias: -21.788835, T: 26240, Avg. loss: 2.288684\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.86, NNZs: 44, Bias: -21.796010, T: 26880, Avg. loss: 2.150486\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.88, NNZs: 44, Bias: -21.804099, T: 27520, Avg. loss: 2.213629\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.84, NNZs: 44, Bias: -21.813593, T: 28160, Avg. loss: 2.698464\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.85, NNZs: 44, Bias: -21.824923, T: 28800, Avg. loss: 2.531753\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.86, NNZs: 44, Bias: -21.835083, T: 29440, Avg. loss: 2.314919\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.87, NNZs: 44, Bias: -21.847257, T: 30080, Avg. loss: 2.572171\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.83, NNZs: 44, Bias: -21.847102, T: 30720, Avg. loss: 0.727465\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.81, NNZs: 44, Bias: -21.847476, T: 31360, Avg. loss: 0.394332\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.81, NNZs: 44, Bias: -21.847750, T: 32000, Avg. loss: 0.347348\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.80, NNZs: 44, Bias: -21.848207, T: 32640, Avg. loss: 0.294411\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.79, NNZs: 44, Bias: -21.848611, T: 33280, Avg. loss: 0.313080\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.78, NNZs: 44, Bias: -21.849179, T: 33920, Avg. loss: 0.338814\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.78, NNZs: 44, Bias: -21.849595, T: 34560, Avg. loss: 0.311426\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.77, NNZs: 44, Bias: -21.850114, T: 35200, Avg. loss: 0.278903\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.76, NNZs: 44, Bias: -21.850544, T: 35840, Avg. loss: 0.323347\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.76, NNZs: 44, Bias: -21.850999, T: 36480, Avg. loss: 0.285556\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.75, NNZs: 44, Bias: -21.851467, T: 37120, Avg. loss: 0.311541\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.75, NNZs: 44, Bias: -21.851826, T: 37760, Avg. loss: 0.333364\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.75, NNZs: 44, Bias: -21.852213, T: 38400, Avg. loss: 0.332154\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852266, T: 39040, Avg. loss: 0.133484\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852265, T: 39680, Avg. loss: 0.124933\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852264, T: 40320, Avg. loss: 0.134122\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852245, T: 40960, Avg. loss: 0.124002\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852247, T: 41600, Avg. loss: 0.126805\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852262, T: 42240, Avg. loss: 0.126852\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852263, T: 42880, Avg. loss: 0.125756\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852229, T: 43520, Avg. loss: 0.106021\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852226, T: 44160, Avg. loss: 0.103396\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852218, T: 44800, Avg. loss: 0.104170\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852229, T: 45440, Avg. loss: 0.105322\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852224, T: 46080, Avg. loss: 0.105754\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852236, T: 46720, Avg. loss: 0.101491\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852229, T: 47360, Avg. loss: 0.104941\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852214, T: 48000, Avg. loss: 0.105051\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852213, T: 48640, Avg. loss: 0.105558\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852203, T: 49280, Avg. loss: 0.104789\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852202, T: 49920, Avg. loss: 0.104441\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 50560, Avg. loss: 0.100782\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 51200, Avg. loss: 0.100245\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852208, T: 51840, Avg. loss: 0.100183\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 52480, Avg. loss: 0.100279\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852208, T: 53120, Avg. loss: 0.099715\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852208, T: 53760, Avg. loss: 0.099310\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 54400, Avg. loss: 0.099242\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 55040, Avg. loss: 0.099155\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852206, T: 55680, Avg. loss: 0.099177\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852206, T: 56320, Avg. loss: 0.099165\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 88 epochs took 0.03 seconds\n",
      "--- training time 0.03826498985290527 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 10.91, NNZs: 43, Bias: -2.550009, T: 640, Avg. loss: 402.389039\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.71, NNZs: 44, Bias: -5.050009, T: 1280, Avg. loss: 323.294791\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.46, NNZs: 44, Bias: -7.512515, T: 1920, Avg. loss: 359.311537\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.05, NNZs: 44, Bias: -10.201947, T: 2560, Avg. loss: 399.918189\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.69, NNZs: 44, Bias: -12.720222, T: 3200, Avg. loss: 361.718888\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.91, NNZs: 44, Bias: -14.880795, T: 3840, Avg. loss: 377.351976\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 19.10, NNZs: 44, Bias: -17.180424, T: 4480, Avg. loss: 376.820507\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 5.86, NNZs: 44, Bias: -17.603116, T: 5120, Avg. loss: 83.034376\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 9.02, NNZs: 44, Bias: -18.059716, T: 5760, Avg. loss: 72.589001\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 7.08, NNZs: 44, Bias: -18.459718, T: 6400, Avg. loss: 68.394544\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 7.82, NNZs: 44, Bias: -18.920503, T: 7040, Avg. loss: 75.816719\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 9.16, NNZs: 44, Bias: -19.338538, T: 7680, Avg. loss: 82.091663\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 6.28, NNZs: 44, Bias: -19.866070, T: 8320, Avg. loss: 80.338302\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 8.67, NNZs: 44, Bias: -20.249927, T: 8960, Avg. loss: 77.763763\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 6.72, NNZs: 44, Bias: -20.783372, T: 9600, Avg. loss: 84.528284\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 2.60, NNZs: 44, Bias: -20.831906, T: 10240, Avg. loss: 21.081200\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 2.52, NNZs: 44, Bias: -20.915984, T: 10880, Avg. loss: 13.879038\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 2.16, NNZs: 44, Bias: -20.997294, T: 11520, Avg. loss: 14.867438\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 1.96, NNZs: 44, Bias: -21.073347, T: 12160, Avg. loss: 15.247984\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.67, NNZs: 44, Bias: -21.147747, T: 12800, Avg. loss: 15.697421\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.95, NNZs: 44, Bias: -21.221151, T: 13440, Avg. loss: 15.912261\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 1.86, NNZs: 44, Bias: -21.289947, T: 14080, Avg. loss: 13.323098\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 2.05, NNZs: 44, Bias: -21.355879, T: 14720, Avg. loss: 15.670591\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 2.38, NNZs: 44, Bias: -21.439276, T: 15360, Avg. loss: 14.048558\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 2.40, NNZs: 44, Bias: -21.531538, T: 16000, Avg. loss: 15.405405\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 1.73, NNZs: 44, Bias: -21.595660, T: 16640, Avg. loss: 15.098512\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 2.46, NNZs: 44, Bias: -21.656147, T: 17280, Avg. loss: 14.324409\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1.48, NNZs: 44, Bias: -21.665591, T: 17920, Avg. loss: 5.804966\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.08, NNZs: 44, Bias: -21.673279, T: 18560, Avg. loss: 2.931253\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.02, NNZs: 44, Bias: -21.683801, T: 19200, Avg. loss: 2.375622\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.99, NNZs: 44, Bias: -21.692709, T: 19840, Avg. loss: 2.414061\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.95, NNZs: 44, Bias: -21.702718, T: 20480, Avg. loss: 2.667215\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.95, NNZs: 44, Bias: -21.708766, T: 21120, Avg. loss: 2.440674\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.720001, T: 21760, Avg. loss: 2.313048\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.732348, T: 22400, Avg. loss: 2.643310\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.742019, T: 23040, Avg. loss: 2.435969\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.90, NNZs: 44, Bias: -21.752661, T: 23680, Avg. loss: 2.758176\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.90, NNZs: 44, Bias: -21.763259, T: 24320, Avg. loss: 2.249982\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.91, NNZs: 44, Bias: -21.772147, T: 24960, Avg. loss: 2.264457\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.89, NNZs: 44, Bias: -21.780717, T: 25600, Avg. loss: 2.408183\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.87, NNZs: 44, Bias: -21.788835, T: 26240, Avg. loss: 2.288684\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.86, NNZs: 44, Bias: -21.796010, T: 26880, Avg. loss: 2.150486\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.88, NNZs: 44, Bias: -21.804099, T: 27520, Avg. loss: 2.213629\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.84, NNZs: 44, Bias: -21.813593, T: 28160, Avg. loss: 2.698464\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.85, NNZs: 44, Bias: -21.824923, T: 28800, Avg. loss: 2.531753\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.86, NNZs: 44, Bias: -21.835083, T: 29440, Avg. loss: 2.314919\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.87, NNZs: 44, Bias: -21.847257, T: 30080, Avg. loss: 2.572171\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.83, NNZs: 44, Bias: -21.847102, T: 30720, Avg. loss: 0.727465\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.81, NNZs: 44, Bias: -21.847476, T: 31360, Avg. loss: 0.394332\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.81, NNZs: 44, Bias: -21.847750, T: 32000, Avg. loss: 0.347348\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.80, NNZs: 44, Bias: -21.848207, T: 32640, Avg. loss: 0.294411\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.79, NNZs: 44, Bias: -21.848611, T: 33280, Avg. loss: 0.313080\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.78, NNZs: 44, Bias: -21.849179, T: 33920, Avg. loss: 0.338814\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.78, NNZs: 44, Bias: -21.849595, T: 34560, Avg. loss: 0.311426\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.77, NNZs: 44, Bias: -21.850114, T: 35200, Avg. loss: 0.278903\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.76, NNZs: 44, Bias: -21.850544, T: 35840, Avg. loss: 0.323347\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.76, NNZs: 44, Bias: -21.850999, T: 36480, Avg. loss: 0.285556\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.75, NNZs: 44, Bias: -21.851467, T: 37120, Avg. loss: 0.311541\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.75, NNZs: 44, Bias: -21.851826, T: 37760, Avg. loss: 0.333364\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.75, NNZs: 44, Bias: -21.852213, T: 38400, Avg. loss: 0.332154\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852266, T: 39040, Avg. loss: 0.133484\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852265, T: 39680, Avg. loss: 0.124933\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852264, T: 40320, Avg. loss: 0.134122\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852245, T: 40960, Avg. loss: 0.124002\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852247, T: 41600, Avg. loss: 0.126805\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852262, T: 42240, Avg. loss: 0.126852\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852263, T: 42880, Avg. loss: 0.125756\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852229, T: 43520, Avg. loss: 0.106021\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852226, T: 44160, Avg. loss: 0.103396\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852218, T: 44800, Avg. loss: 0.104170\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852229, T: 45440, Avg. loss: 0.105322\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852224, T: 46080, Avg. loss: 0.105754\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852236, T: 46720, Avg. loss: 0.101491\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852229, T: 47360, Avg. loss: 0.104941\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852214, T: 48000, Avg. loss: 0.105051\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852213, T: 48640, Avg. loss: 0.105558\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852203, T: 49280, Avg. loss: 0.104789\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852202, T: 49920, Avg. loss: 0.104441\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 50560, Avg. loss: 0.100782\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 51200, Avg. loss: 0.100245\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852208, T: 51840, Avg. loss: 0.100183\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 52480, Avg. loss: 0.100279\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852208, T: 53120, Avg. loss: 0.099715\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852208, T: 53760, Avg. loss: 0.099310\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 54400, Avg. loss: 0.099242\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 55040, Avg. loss: 0.099155\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852206, T: 55680, Avg. loss: 0.099177\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852206, T: 56320, Avg. loss: 0.099165\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 88 epochs took 0.04 seconds\n",
      "--- training time 0.0422053337097168 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.002804, T: 640, Avg. loss: 0.530745\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.004999, T: 1280, Avg. loss: 0.473073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.007353, T: 1920, Avg. loss: 0.477698\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.009563, T: 2560, Avg. loss: 0.526879\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.012097, T: 3200, Avg. loss: 0.492399\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.014273, T: 3840, Avg. loss: 0.483501\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.016534, T: 4480, Avg. loss: 0.501115\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.007859945297241211 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.002804, T: 640, Avg. loss: 0.530745\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.004999, T: 1280, Avg. loss: 0.473073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.007353, T: 1920, Avg. loss: 0.477698\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.009563, T: 2560, Avg. loss: 0.526879\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.012097, T: 3200, Avg. loss: 0.492399\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.014273, T: 3840, Avg. loss: 0.483501\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.016534, T: 4480, Avg. loss: 0.501115\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.006455183029174805 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.002804, T: 640, Avg. loss: 0.530745\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.004999, T: 1280, Avg. loss: 0.473073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.007353, T: 1920, Avg. loss: 0.477698\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.009563, T: 2560, Avg. loss: 0.526879\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.012097, T: 3200, Avg. loss: 0.492399\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.014273, T: 3840, Avg. loss: 0.483501\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.016534, T: 4480, Avg. loss: 0.501115\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.007288217544555664 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 2495.55, NNZs: 40, Bias: -173.243886, T: 640, Avg. loss: 30801.248757\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2050.57, NNZs: 43, Bias: -287.332502, T: 1280, Avg. loss: 18969.702448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1652.84, NNZs: 43, Bias: -367.519263, T: 1920, Avg. loss: 14798.941977\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1456.19, NNZs: 43, Bias: -429.450141, T: 2560, Avg. loss: 13148.500053\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1381.34, NNZs: 43, Bias: -483.250401, T: 3200, Avg. loss: 10270.942512\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1567.17, NNZs: 43, Bias: -522.966221, T: 3840, Avg. loss: 8722.036104\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1079.76, NNZs: 43, Bias: -553.762673, T: 4480, Avg. loss: 7476.517176\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1214.10, NNZs: 43, Bias: -595.186474, T: 5120, Avg. loss: 6678.600067\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1278.12, NNZs: 44, Bias: -624.695637, T: 5760, Avg. loss: 5915.409154\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1285.32, NNZs: 44, Bias: -651.612881, T: 6400, Avg. loss: 5752.807953\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1139.73, NNZs: 44, Bias: -675.035744, T: 7040, Avg. loss: 4983.009927\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1112.20, NNZs: 44, Bias: -692.915017, T: 7680, Avg. loss: 4710.982586\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1033.57, NNZs: 44, Bias: -716.356350, T: 8320, Avg. loss: 4034.006958\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 949.86, NNZs: 44, Bias: -735.998619, T: 8960, Avg. loss: 4552.730168\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1030.75, NNZs: 44, Bias: -758.365883, T: 9600, Avg. loss: 4016.078415\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 988.92, NNZs: 44, Bias: -775.763258, T: 10240, Avg. loss: 3432.888311\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1039.65, NNZs: 44, Bias: -792.294392, T: 10880, Avg. loss: 2936.404461\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1010.74, NNZs: 44, Bias: -806.220773, T: 11520, Avg. loss: 2984.979803\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 974.24, NNZs: 44, Bias: -821.803321, T: 12160, Avg. loss: 3316.948645\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 963.70, NNZs: 44, Bias: -835.139095, T: 12800, Avg. loss: 2951.386082\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 970.55, NNZs: 44, Bias: -849.324160, T: 13440, Avg. loss: 2989.667011\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 988.25, NNZs: 44, Bias: -861.529135, T: 14080, Avg. loss: 2281.903736\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 987.73, NNZs: 44, Bias: -871.963436, T: 14720, Avg. loss: 2682.600205\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 976.90, NNZs: 44, Bias: -884.481374, T: 15360, Avg. loss: 2330.265429\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 974.74, NNZs: 44, Bias: -895.322019, T: 16000, Avg. loss: 2155.861475\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 950.52, NNZs: 44, Bias: -905.148129, T: 16640, Avg. loss: 2048.901443\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 961.11, NNZs: 44, Bias: -914.615551, T: 17280, Avg. loss: 2048.271031\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 957.22, NNZs: 44, Bias: -926.464267, T: 17920, Avg. loss: 1869.561717\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 950.08, NNZs: 44, Bias: -936.829761, T: 18560, Avg. loss: 1802.534811\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 980.53, NNZs: 44, Bias: -947.912722, T: 19200, Avg. loss: 1866.771309\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 957.39, NNZs: 44, Bias: -954.247734, T: 19840, Avg. loss: 1798.679859\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 950.76, NNZs: 44, Bias: -963.227196, T: 20480, Avg. loss: 1781.657030\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 945.74, NNZs: 44, Bias: -968.739841, T: 21120, Avg. loss: 1624.041529\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 945.61, NNZs: 44, Bias: -977.686627, T: 21760, Avg. loss: 1596.320191\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 954.60, NNZs: 44, Bias: -985.911547, T: 22400, Avg. loss: 1568.622498\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 945.79, NNZs: 44, Bias: -993.914015, T: 23040, Avg. loss: 1572.932396\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 942.78, NNZs: 44, Bias: -1001.726833, T: 23680, Avg. loss: 1601.846946\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 938.02, NNZs: 44, Bias: -1009.316532, T: 24320, Avg. loss: 1452.959411\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 934.07, NNZs: 44, Bias: -1016.737288, T: 24960, Avg. loss: 1278.891445\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 935.74, NNZs: 44, Bias: -1023.199696, T: 25600, Avg. loss: 1403.652975\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 922.73, NNZs: 44, Bias: -1028.397080, T: 26240, Avg. loss: 1359.303331\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 915.36, NNZs: 44, Bias: -1033.470784, T: 26880, Avg. loss: 1196.712144\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 916.26, NNZs: 44, Bias: -1038.435008, T: 27520, Avg. loss: 1333.135925\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 914.79, NNZs: 44, Bias: -1044.330947, T: 28160, Avg. loss: 1226.511264\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 918.79, NNZs: 44, Bias: -1051.136086, T: 28800, Avg. loss: 1205.729002\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 910.75, NNZs: 44, Bias: -1056.290764, T: 29440, Avg. loss: 1067.009941\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 926.65, NNZs: 44, Bias: -1063.128725, T: 30080, Avg. loss: 1190.628791\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 924.57, NNZs: 44, Bias: -1068.861692, T: 30720, Avg. loss: 1049.310080\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 925.09, NNZs: 44, Bias: -1074.160225, T: 31360, Avg. loss: 1110.357461\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 919.66, NNZs: 44, Bias: -1079.057770, T: 32000, Avg. loss: 1148.884431\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 916.19, NNZs: 44, Bias: -1083.860439, T: 32640, Avg. loss: 951.042110\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 904.96, NNZs: 44, Bias: -1088.282155, T: 33280, Avg. loss: 945.939081\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 902.75, NNZs: 44, Bias: -1092.744731, T: 33920, Avg. loss: 1033.170353\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 899.03, NNZs: 44, Bias: -1097.856195, T: 34560, Avg. loss: 979.107370\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 894.86, NNZs: 44, Bias: -1102.313042, T: 35200, Avg. loss: 996.605479\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 912.39, NNZs: 44, Bias: -1107.787375, T: 35840, Avg. loss: 935.173136\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 898.29, NNZs: 44, Bias: -1112.090240, T: 36480, Avg. loss: 923.409901\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 896.24, NNZs: 44, Bias: -1116.319380, T: 37120, Avg. loss: 907.743547\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 897.41, NNZs: 44, Bias: -1120.999807, T: 37760, Avg. loss: 974.755917\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 889.59, NNZs: 44, Bias: -1125.607573, T: 38400, Avg. loss: 903.230092\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 887.86, NNZs: 44, Bias: -1129.644132, T: 39040, Avg. loss: 840.587006\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 886.24, NNZs: 44, Bias: -1133.610148, T: 39680, Avg. loss: 744.851484\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 886.11, NNZs: 44, Bias: -1137.760367, T: 40320, Avg. loss: 794.789842\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 886.62, NNZs: 44, Bias: -1141.358172, T: 40960, Avg. loss: 911.947559\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 887.62, NNZs: 44, Bias: -1145.615043, T: 41600, Avg. loss: 714.642955\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 882.87, NNZs: 44, Bias: -1148.872796, T: 42240, Avg. loss: 762.570822\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 875.14, NNZs: 44, Bias: -1153.008843, T: 42880, Avg. loss: 726.207850\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 877.37, NNZs: 44, Bias: -1156.471768, T: 43520, Avg. loss: 775.719993\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 876.79, NNZs: 44, Bias: -1159.595838, T: 44160, Avg. loss: 707.479024\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 874.91, NNZs: 44, Bias: -1163.553259, T: 44800, Avg. loss: 777.630009\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 870.75, NNZs: 44, Bias: -1166.591431, T: 45440, Avg. loss: 757.268589\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 866.30, NNZs: 44, Bias: -1169.798316, T: 46080, Avg. loss: 758.242938\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 865.10, NNZs: 44, Bias: -1173.174130, T: 46720, Avg. loss: 703.222684\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 865.32, NNZs: 44, Bias: -1176.917043, T: 47360, Avg. loss: 734.025923\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 858.54, NNZs: 44, Bias: -1179.793455, T: 48000, Avg. loss: 695.823355\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 862.10, NNZs: 44, Bias: -1182.836877, T: 48640, Avg. loss: 591.220628\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 857.91, NNZs: 44, Bias: -1185.440426, T: 49280, Avg. loss: 783.068207\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 859.97, NNZs: 44, Bias: -1188.601682, T: 49920, Avg. loss: 626.584526\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 857.29, NNZs: 44, Bias: -1191.921791, T: 50560, Avg. loss: 623.839323\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 856.27, NNZs: 44, Bias: -1194.621243, T: 51200, Avg. loss: 646.226516\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 851.58, NNZs: 44, Bias: -1197.477257, T: 51840, Avg. loss: 640.572277\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 81 epochs took 0.03 seconds\n",
      "--- training time 0.0373377799987793 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 2495.55, NNZs: 40, Bias: -173.243886, T: 640, Avg. loss: 30801.248757\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2050.57, NNZs: 43, Bias: -287.332502, T: 1280, Avg. loss: 18969.702448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1652.84, NNZs: 43, Bias: -367.519263, T: 1920, Avg. loss: 14798.941977\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1456.19, NNZs: 43, Bias: -429.450141, T: 2560, Avg. loss: 13148.500053\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1381.34, NNZs: 43, Bias: -483.250401, T: 3200, Avg. loss: 10270.942512\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1567.17, NNZs: 43, Bias: -522.966221, T: 3840, Avg. loss: 8722.036104\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1079.76, NNZs: 43, Bias: -553.762673, T: 4480, Avg. loss: 7476.517176\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1214.10, NNZs: 43, Bias: -595.186474, T: 5120, Avg. loss: 6678.600067\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1278.12, NNZs: 44, Bias: -624.695637, T: 5760, Avg. loss: 5915.409154\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1285.32, NNZs: 44, Bias: -651.612881, T: 6400, Avg. loss: 5752.807953\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1139.73, NNZs: 44, Bias: -675.035744, T: 7040, Avg. loss: 4983.009927\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1112.20, NNZs: 44, Bias: -692.915017, T: 7680, Avg. loss: 4710.982586\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1033.57, NNZs: 44, Bias: -716.356350, T: 8320, Avg. loss: 4034.006958\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 949.86, NNZs: 44, Bias: -735.998619, T: 8960, Avg. loss: 4552.730168\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1030.75, NNZs: 44, Bias: -758.365883, T: 9600, Avg. loss: 4016.078415\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 988.92, NNZs: 44, Bias: -775.763258, T: 10240, Avg. loss: 3432.888311\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1039.65, NNZs: 44, Bias: -792.294392, T: 10880, Avg. loss: 2936.404461\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1010.74, NNZs: 44, Bias: -806.220773, T: 11520, Avg. loss: 2984.979803\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 974.24, NNZs: 44, Bias: -821.803321, T: 12160, Avg. loss: 3316.948645\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 963.70, NNZs: 44, Bias: -835.139095, T: 12800, Avg. loss: 2951.386082\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 970.55, NNZs: 44, Bias: -849.324160, T: 13440, Avg. loss: 2989.667011\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 988.25, NNZs: 44, Bias: -861.529135, T: 14080, Avg. loss: 2281.903736\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 987.73, NNZs: 44, Bias: -871.963436, T: 14720, Avg. loss: 2682.600205\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 976.90, NNZs: 44, Bias: -884.481374, T: 15360, Avg. loss: 2330.265429\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 974.74, NNZs: 44, Bias: -895.322019, T: 16000, Avg. loss: 2155.861475\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 950.52, NNZs: 44, Bias: -905.148129, T: 16640, Avg. loss: 2048.901443\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 961.11, NNZs: 44, Bias: -914.615551, T: 17280, Avg. loss: 2048.271031\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 957.22, NNZs: 44, Bias: -926.464267, T: 17920, Avg. loss: 1869.561717\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 950.08, NNZs: 44, Bias: -936.829761, T: 18560, Avg. loss: 1802.534811\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 980.53, NNZs: 44, Bias: -947.912722, T: 19200, Avg. loss: 1866.771309\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 957.39, NNZs: 44, Bias: -954.247734, T: 19840, Avg. loss: 1798.679859\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 950.76, NNZs: 44, Bias: -963.227196, T: 20480, Avg. loss: 1781.657030\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 945.74, NNZs: 44, Bias: -968.739841, T: 21120, Avg. loss: 1624.041529\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 945.61, NNZs: 44, Bias: -977.686627, T: 21760, Avg. loss: 1596.320191\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 954.60, NNZs: 44, Bias: -985.911547, T: 22400, Avg. loss: 1568.622498\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 945.79, NNZs: 44, Bias: -993.914015, T: 23040, Avg. loss: 1572.932396\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 942.78, NNZs: 44, Bias: -1001.726833, T: 23680, Avg. loss: 1601.846946\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 938.02, NNZs: 44, Bias: -1009.316532, T: 24320, Avg. loss: 1452.959411\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 934.07, NNZs: 44, Bias: -1016.737288, T: 24960, Avg. loss: 1278.891445\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 935.74, NNZs: 44, Bias: -1023.199696, T: 25600, Avg. loss: 1403.652975\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 922.73, NNZs: 44, Bias: -1028.397080, T: 26240, Avg. loss: 1359.303331\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 915.36, NNZs: 44, Bias: -1033.470784, T: 26880, Avg. loss: 1196.712144\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 916.26, NNZs: 44, Bias: -1038.435008, T: 27520, Avg. loss: 1333.135925\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 914.79, NNZs: 44, Bias: -1044.330947, T: 28160, Avg. loss: 1226.511264\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 918.79, NNZs: 44, Bias: -1051.136086, T: 28800, Avg. loss: 1205.729002\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 910.75, NNZs: 44, Bias: -1056.290764, T: 29440, Avg. loss: 1067.009941\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 926.65, NNZs: 44, Bias: -1063.128725, T: 30080, Avg. loss: 1190.628791\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 924.57, NNZs: 44, Bias: -1068.861692, T: 30720, Avg. loss: 1049.310080\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 925.09, NNZs: 44, Bias: -1074.160225, T: 31360, Avg. loss: 1110.357461\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 919.66, NNZs: 44, Bias: -1079.057770, T: 32000, Avg. loss: 1148.884431\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 916.19, NNZs: 44, Bias: -1083.860439, T: 32640, Avg. loss: 951.042110\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 904.96, NNZs: 44, Bias: -1088.282155, T: 33280, Avg. loss: 945.939081\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 902.75, NNZs: 44, Bias: -1092.744731, T: 33920, Avg. loss: 1033.170353\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 899.03, NNZs: 44, Bias: -1097.856195, T: 34560, Avg. loss: 979.107370\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 894.86, NNZs: 44, Bias: -1102.313042, T: 35200, Avg. loss: 996.605479\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 912.39, NNZs: 44, Bias: -1107.787375, T: 35840, Avg. loss: 935.173136\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 898.29, NNZs: 44, Bias: -1112.090240, T: 36480, Avg. loss: 923.409901\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 896.24, NNZs: 44, Bias: -1116.319380, T: 37120, Avg. loss: 907.743547\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 897.41, NNZs: 44, Bias: -1120.999807, T: 37760, Avg. loss: 974.755917\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 889.59, NNZs: 44, Bias: -1125.607573, T: 38400, Avg. loss: 903.230092\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 887.86, NNZs: 44, Bias: -1129.644132, T: 39040, Avg. loss: 840.587006\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 886.24, NNZs: 44, Bias: -1133.610148, T: 39680, Avg. loss: 744.851484\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 886.11, NNZs: 44, Bias: -1137.760367, T: 40320, Avg. loss: 794.789842\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 886.62, NNZs: 44, Bias: -1141.358172, T: 40960, Avg. loss: 911.947559\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 887.62, NNZs: 44, Bias: -1145.615043, T: 41600, Avg. loss: 714.642955\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 882.87, NNZs: 44, Bias: -1148.872796, T: 42240, Avg. loss: 762.570822\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 875.14, NNZs: 44, Bias: -1153.008843, T: 42880, Avg. loss: 726.207850\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 877.37, NNZs: 44, Bias: -1156.471768, T: 43520, Avg. loss: 775.719993\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 876.79, NNZs: 44, Bias: -1159.595838, T: 44160, Avg. loss: 707.479024\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 874.91, NNZs: 44, Bias: -1163.553259, T: 44800, Avg. loss: 777.630009\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 870.75, NNZs: 44, Bias: -1166.591431, T: 45440, Avg. loss: 757.268589\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 866.30, NNZs: 44, Bias: -1169.798316, T: 46080, Avg. loss: 758.242938\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 865.10, NNZs: 44, Bias: -1173.174130, T: 46720, Avg. loss: 703.222684\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 865.32, NNZs: 44, Bias: -1176.917043, T: 47360, Avg. loss: 734.025923\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 858.54, NNZs: 44, Bias: -1179.793455, T: 48000, Avg. loss: 695.823355\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 862.10, NNZs: 44, Bias: -1182.836877, T: 48640, Avg. loss: 591.220628\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 857.91, NNZs: 44, Bias: -1185.440426, T: 49280, Avg. loss: 783.068207\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 859.97, NNZs: 44, Bias: -1188.601682, T: 49920, Avg. loss: 626.584526\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 857.29, NNZs: 44, Bias: -1191.921791, T: 50560, Avg. loss: 623.839323\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 856.27, NNZs: 44, Bias: -1194.621243, T: 51200, Avg. loss: 646.226516\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 851.58, NNZs: 44, Bias: -1197.477257, T: 51840, Avg. loss: 640.572277\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 81 epochs took 0.04 seconds\n",
      "--- training time 0.040376901626586914 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 2495.55, NNZs: 40, Bias: -173.243886, T: 640, Avg. loss: 30801.248757\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2050.57, NNZs: 43, Bias: -287.332502, T: 1280, Avg. loss: 18969.702448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1652.84, NNZs: 43, Bias: -367.519263, T: 1920, Avg. loss: 14798.941977\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1456.19, NNZs: 43, Bias: -429.450141, T: 2560, Avg. loss: 13148.500053\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1381.34, NNZs: 43, Bias: -483.250401, T: 3200, Avg. loss: 10270.942512\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1567.17, NNZs: 43, Bias: -522.966221, T: 3840, Avg. loss: 8722.036104\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1079.76, NNZs: 43, Bias: -553.762673, T: 4480, Avg. loss: 7476.517176\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1214.10, NNZs: 43, Bias: -595.186474, T: 5120, Avg. loss: 6678.600067\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1278.12, NNZs: 44, Bias: -624.695637, T: 5760, Avg. loss: 5915.409154\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1285.32, NNZs: 44, Bias: -651.612881, T: 6400, Avg. loss: 5752.807953\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1139.73, NNZs: 44, Bias: -675.035744, T: 7040, Avg. loss: 4983.009927\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1112.20, NNZs: 44, Bias: -692.915017, T: 7680, Avg. loss: 4710.982586\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1033.57, NNZs: 44, Bias: -716.356350, T: 8320, Avg. loss: 4034.006958\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 949.86, NNZs: 44, Bias: -735.998619, T: 8960, Avg. loss: 4552.730168\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1030.75, NNZs: 44, Bias: -758.365883, T: 9600, Avg. loss: 4016.078415\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 988.92, NNZs: 44, Bias: -775.763258, T: 10240, Avg. loss: 3432.888311\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1039.65, NNZs: 44, Bias: -792.294392, T: 10880, Avg. loss: 2936.404461\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1010.74, NNZs: 44, Bias: -806.220773, T: 11520, Avg. loss: 2984.979803\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 974.24, NNZs: 44, Bias: -821.803321, T: 12160, Avg. loss: 3316.948645\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 963.70, NNZs: 44, Bias: -835.139095, T: 12800, Avg. loss: 2951.386082\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 970.55, NNZs: 44, Bias: -849.324160, T: 13440, Avg. loss: 2989.667011\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 988.25, NNZs: 44, Bias: -861.529135, T: 14080, Avg. loss: 2281.903736\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 987.73, NNZs: 44, Bias: -871.963436, T: 14720, Avg. loss: 2682.600205\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 976.90, NNZs: 44, Bias: -884.481374, T: 15360, Avg. loss: 2330.265429\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 974.74, NNZs: 44, Bias: -895.322019, T: 16000, Avg. loss: 2155.861475\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 950.52, NNZs: 44, Bias: -905.148129, T: 16640, Avg. loss: 2048.901443\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 961.11, NNZs: 44, Bias: -914.615551, T: 17280, Avg. loss: 2048.271031\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 957.22, NNZs: 44, Bias: -926.464267, T: 17920, Avg. loss: 1869.561717\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 950.08, NNZs: 44, Bias: -936.829761, T: 18560, Avg. loss: 1802.534811\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 980.53, NNZs: 44, Bias: -947.912722, T: 19200, Avg. loss: 1866.771309\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 957.39, NNZs: 44, Bias: -954.247734, T: 19840, Avg. loss: 1798.679859\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 950.76, NNZs: 44, Bias: -963.227196, T: 20480, Avg. loss: 1781.657030\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 945.74, NNZs: 44, Bias: -968.739841, T: 21120, Avg. loss: 1624.041529\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 945.61, NNZs: 44, Bias: -977.686627, T: 21760, Avg. loss: 1596.320191\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 954.60, NNZs: 44, Bias: -985.911547, T: 22400, Avg. loss: 1568.622498\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 945.79, NNZs: 44, Bias: -993.914015, T: 23040, Avg. loss: 1572.932396\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 942.78, NNZs: 44, Bias: -1001.726833, T: 23680, Avg. loss: 1601.846946\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 938.02, NNZs: 44, Bias: -1009.316532, T: 24320, Avg. loss: 1452.959411\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 934.07, NNZs: 44, Bias: -1016.737288, T: 24960, Avg. loss: 1278.891445\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 935.74, NNZs: 44, Bias: -1023.199696, T: 25600, Avg. loss: 1403.652975\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 922.73, NNZs: 44, Bias: -1028.397080, T: 26240, Avg. loss: 1359.303331\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 915.36, NNZs: 44, Bias: -1033.470784, T: 26880, Avg. loss: 1196.712144\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 916.26, NNZs: 44, Bias: -1038.435008, T: 27520, Avg. loss: 1333.135925\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 914.79, NNZs: 44, Bias: -1044.330947, T: 28160, Avg. loss: 1226.511264\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 918.79, NNZs: 44, Bias: -1051.136086, T: 28800, Avg. loss: 1205.729002\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 910.75, NNZs: 44, Bias: -1056.290764, T: 29440, Avg. loss: 1067.009941\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 926.65, NNZs: 44, Bias: -1063.128725, T: 30080, Avg. loss: 1190.628791\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 924.57, NNZs: 44, Bias: -1068.861692, T: 30720, Avg. loss: 1049.310080\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 925.09, NNZs: 44, Bias: -1074.160225, T: 31360, Avg. loss: 1110.357461\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 919.66, NNZs: 44, Bias: -1079.057770, T: 32000, Avg. loss: 1148.884431\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 916.19, NNZs: 44, Bias: -1083.860439, T: 32640, Avg. loss: 951.042110\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 904.96, NNZs: 44, Bias: -1088.282155, T: 33280, Avg. loss: 945.939081\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 902.75, NNZs: 44, Bias: -1092.744731, T: 33920, Avg. loss: 1033.170353\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 899.03, NNZs: 44, Bias: -1097.856195, T: 34560, Avg. loss: 979.107370\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 894.86, NNZs: 44, Bias: -1102.313042, T: 35200, Avg. loss: 996.605479\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 912.39, NNZs: 44, Bias: -1107.787375, T: 35840, Avg. loss: 935.173136\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 898.29, NNZs: 44, Bias: -1112.090240, T: 36480, Avg. loss: 923.409901\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 896.24, NNZs: 44, Bias: -1116.319380, T: 37120, Avg. loss: 907.743547\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 897.41, NNZs: 44, Bias: -1120.999807, T: 37760, Avg. loss: 974.755917\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 889.59, NNZs: 44, Bias: -1125.607573, T: 38400, Avg. loss: 903.230092\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 887.86, NNZs: 44, Bias: -1129.644132, T: 39040, Avg. loss: 840.587006\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 886.24, NNZs: 44, Bias: -1133.610148, T: 39680, Avg. loss: 744.851484\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 886.11, NNZs: 44, Bias: -1137.760367, T: 40320, Avg. loss: 794.789842\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 886.62, NNZs: 44, Bias: -1141.358172, T: 40960, Avg. loss: 911.947559\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 887.62, NNZs: 44, Bias: -1145.615043, T: 41600, Avg. loss: 714.642955\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 882.87, NNZs: 44, Bias: -1148.872796, T: 42240, Avg. loss: 762.570822\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 875.14, NNZs: 44, Bias: -1153.008843, T: 42880, Avg. loss: 726.207850\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 877.37, NNZs: 44, Bias: -1156.471768, T: 43520, Avg. loss: 775.719993\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 876.79, NNZs: 44, Bias: -1159.595838, T: 44160, Avg. loss: 707.479024\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 874.91, NNZs: 44, Bias: -1163.553259, T: 44800, Avg. loss: 777.630009\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 870.75, NNZs: 44, Bias: -1166.591431, T: 45440, Avg. loss: 757.268589\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 866.30, NNZs: 44, Bias: -1169.798316, T: 46080, Avg. loss: 758.242938\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 865.10, NNZs: 44, Bias: -1173.174130, T: 46720, Avg. loss: 703.222684\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 865.32, NNZs: 44, Bias: -1176.917043, T: 47360, Avg. loss: 734.025923\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 858.54, NNZs: 44, Bias: -1179.793455, T: 48000, Avg. loss: 695.823355\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 862.10, NNZs: 44, Bias: -1182.836877, T: 48640, Avg. loss: 591.220628\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 857.91, NNZs: 44, Bias: -1185.440426, T: 49280, Avg. loss: 783.068207\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 859.97, NNZs: 44, Bias: -1188.601682, T: 49920, Avg. loss: 626.584526\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 857.29, NNZs: 44, Bias: -1191.921791, T: 50560, Avg. loss: 623.839323\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 856.27, NNZs: 44, Bias: -1194.621243, T: 51200, Avg. loss: 646.226516\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 851.58, NNZs: 44, Bias: -1197.477257, T: 51840, Avg. loss: 640.572277\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 81 epochs took 0.04 seconds\n",
      "--- training time 0.04102683067321777 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000268, T: 640, Avg. loss: 0.365764\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000371, T: 1280, Avg. loss: 0.356616\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000440, T: 1920, Avg. loss: 0.351156\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000512, T: 2560, Avg. loss: 0.349170\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000571, T: 3200, Avg. loss: 0.344668\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000626, T: 3840, Avg. loss: 0.344730\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000670, T: 4480, Avg. loss: 0.341486\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000723, T: 5120, Avg. loss: 0.340767\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000765, T: 5760, Avg. loss: 0.340707\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000802, T: 6400, Avg. loss: 0.339845\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000839, T: 7040, Avg. loss: 0.338683\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000873, T: 7680, Avg. loss: 0.337827\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000916, T: 8320, Avg. loss: 0.336225\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000941, T: 8960, Avg. loss: 0.336617\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000975, T: 9600, Avg. loss: 0.336643\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001005, T: 10240, Avg. loss: 0.336029\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001040, T: 10880, Avg. loss: 0.334355\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001068, T: 11520, Avg. loss: 0.335234\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001097, T: 12160, Avg. loss: 0.334441\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001120, T: 12800, Avg. loss: 0.334514\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001147, T: 13440, Avg. loss: 0.334017\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001171, T: 14080, Avg. loss: 0.333580\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 22 epochs took 0.01 seconds\n",
      "--- training time 0.015640735626220703 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000268, T: 640, Avg. loss: 0.365764\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000371, T: 1280, Avg. loss: 0.356616\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000440, T: 1920, Avg. loss: 0.351156\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000512, T: 2560, Avg. loss: 0.349170\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000571, T: 3200, Avg. loss: 0.344668\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000626, T: 3840, Avg. loss: 0.344730\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000670, T: 4480, Avg. loss: 0.341486\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000723, T: 5120, Avg. loss: 0.340767\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000765, T: 5760, Avg. loss: 0.340707\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000802, T: 6400, Avg. loss: 0.339845\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000839, T: 7040, Avg. loss: 0.338683\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000873, T: 7680, Avg. loss: 0.337827\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000916, T: 8320, Avg. loss: 0.336225\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000941, T: 8960, Avg. loss: 0.336617\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000975, T: 9600, Avg. loss: 0.336643\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001005, T: 10240, Avg. loss: 0.336029\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001040, T: 10880, Avg. loss: 0.334355\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001068, T: 11520, Avg. loss: 0.335234\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001097, T: 12160, Avg. loss: 0.334441\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001120, T: 12800, Avg. loss: 0.334514\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001147, T: 13440, Avg. loss: 0.334017\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001171, T: 14080, Avg. loss: 0.333580\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 22 epochs took 0.01 seconds\n",
      "--- training time 0.01576995849609375 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000268, T: 640, Avg. loss: 0.365764\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000371, T: 1280, Avg. loss: 0.356616\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000440, T: 1920, Avg. loss: 0.351156\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000512, T: 2560, Avg. loss: 0.349170\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000571, T: 3200, Avg. loss: 0.344668\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000626, T: 3840, Avg. loss: 0.344730\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000670, T: 4480, Avg. loss: 0.341486\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000723, T: 5120, Avg. loss: 0.340767\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000765, T: 5760, Avg. loss: 0.340707\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000802, T: 6400, Avg. loss: 0.339845\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000839, T: 7040, Avg. loss: 0.338683\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.02, NNZs: 44, Bias: -0.000873, T: 7680, Avg. loss: 0.337827\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000916, T: 8320, Avg. loss: 0.336225\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000941, T: 8960, Avg. loss: 0.336617\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.000975, T: 9600, Avg. loss: 0.336643\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001005, T: 10240, Avg. loss: 0.336029\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001040, T: 10880, Avg. loss: 0.334355\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001068, T: 11520, Avg. loss: 0.335234\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001097, T: 12160, Avg. loss: 0.334441\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001120, T: 12800, Avg. loss: 0.334514\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001147, T: 13440, Avg. loss: 0.334017\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.03, NNZs: 44, Bias: -0.001171, T: 14080, Avg. loss: 0.333580\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 22 epochs took 0.01 seconds\n",
      "--- training time 0.014236927032470703 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.002804, T: 640, Avg. loss: 0.530745\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.004999, T: 1280, Avg. loss: 0.473073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.007353, T: 1920, Avg. loss: 0.477698\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.009563, T: 2560, Avg. loss: 0.526879\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.012097, T: 3200, Avg. loss: 0.492399\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.014273, T: 3840, Avg. loss: 0.483501\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.016534, T: 4480, Avg. loss: 0.501115\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.016942, T: 5120, Avg. loss: 0.367130\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.017476, T: 5760, Avg. loss: 0.352643\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.017962, T: 6400, Avg. loss: 0.350942\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.018492, T: 7040, Avg. loss: 0.344682\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.018956, T: 7680, Avg. loss: 0.348603\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.019531, T: 8320, Avg. loss: 0.343703\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.019971, T: 8960, Avg. loss: 0.350367\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.020559, T: 9600, Avg. loss: 0.348111\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021010, T: 10240, Avg. loss: 0.348495\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021158, T: 10880, Avg. loss: 0.317506\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021251, T: 11520, Avg. loss: 0.324189\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021362, T: 12160, Avg. loss: 0.320888\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021453, T: 12800, Avg. loss: 0.324178\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021557, T: 13440, Avg. loss: 0.322479\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021656, T: 14080, Avg. loss: 0.321282\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021682, T: 14720, Avg. loss: 0.318814\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021707, T: 15360, Avg. loss: 0.317611\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021731, T: 16000, Avg. loss: 0.317027\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021748, T: 16640, Avg. loss: 0.318004\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021771, T: 17280, Avg. loss: 0.317610\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 27 epochs took 0.01 seconds\n",
      "--- training time 0.016734838485717773 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.002804, T: 640, Avg. loss: 0.530745\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.004999, T: 1280, Avg. loss: 0.473073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.007353, T: 1920, Avg. loss: 0.477698\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.009563, T: 2560, Avg. loss: 0.526879\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.012097, T: 3200, Avg. loss: 0.492399\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.014273, T: 3840, Avg. loss: 0.483501\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.016534, T: 4480, Avg. loss: 0.501115\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.016942, T: 5120, Avg. loss: 0.367130\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.017476, T: 5760, Avg. loss: 0.352643\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.017962, T: 6400, Avg. loss: 0.350942\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.018492, T: 7040, Avg. loss: 0.344682\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.018956, T: 7680, Avg. loss: 0.348603\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.019531, T: 8320, Avg. loss: 0.343703\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.019971, T: 8960, Avg. loss: 0.350367\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.020559, T: 9600, Avg. loss: 0.348111\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021010, T: 10240, Avg. loss: 0.348495\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021158, T: 10880, Avg. loss: 0.317506\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021251, T: 11520, Avg. loss: 0.324189\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021362, T: 12160, Avg. loss: 0.320888\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021453, T: 12800, Avg. loss: 0.324178\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021557, T: 13440, Avg. loss: 0.322479\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021656, T: 14080, Avg. loss: 0.321282\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021682, T: 14720, Avg. loss: 0.318814\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021707, T: 15360, Avg. loss: 0.317611\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021731, T: 16000, Avg. loss: 0.317027\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021748, T: 16640, Avg. loss: 0.318004\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021771, T: 17280, Avg. loss: 0.317610\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 27 epochs took 0.01 seconds\n",
      "--- training time 0.01575613021850586 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.002804, T: 640, Avg. loss: 0.530745\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.004999, T: 1280, Avg. loss: 0.473073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.007353, T: 1920, Avg. loss: 0.477698\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.06, NNZs: 44, Bias: -0.009563, T: 2560, Avg. loss: 0.526879\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.07, NNZs: 44, Bias: -0.012097, T: 3200, Avg. loss: 0.492399\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.014273, T: 3840, Avg. loss: 0.483501\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.016534, T: 4480, Avg. loss: 0.501115\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.016942, T: 5120, Avg. loss: 0.367130\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.017476, T: 5760, Avg. loss: 0.352643\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.017962, T: 6400, Avg. loss: 0.350942\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.018492, T: 7040, Avg. loss: 0.344682\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.018956, T: 7680, Avg. loss: 0.348603\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.019531, T: 8320, Avg. loss: 0.343703\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.019971, T: 8960, Avg. loss: 0.350367\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.020559, T: 9600, Avg. loss: 0.348111\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021010, T: 10240, Avg. loss: 0.348495\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021158, T: 10880, Avg. loss: 0.317506\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021251, T: 11520, Avg. loss: 0.324189\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021362, T: 12160, Avg. loss: 0.320888\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021453, T: 12800, Avg. loss: 0.324178\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021557, T: 13440, Avg. loss: 0.322479\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.08, NNZs: 44, Bias: -0.021656, T: 14080, Avg. loss: 0.321282\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021682, T: 14720, Avg. loss: 0.318814\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021707, T: 15360, Avg. loss: 0.317611\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021731, T: 16000, Avg. loss: 0.317027\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021748, T: 16640, Avg. loss: 0.318004\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.09, NNZs: 44, Bias: -0.021771, T: 17280, Avg. loss: 0.317610\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 27 epochs took 0.01 seconds\n",
      "--- training time 0.01702713966369629 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.021067, T: 640, Avg. loss: 3.984145\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.48, NNZs: 44, Bias: -0.040317, T: 1280, Avg. loss: 3.222851\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.059537, T: 1920, Avg. loss: 3.644051\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.50, NNZs: 44, Bias: -0.078804, T: 2560, Avg. loss: 4.137911\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.45, NNZs: 44, Bias: -0.098773, T: 3200, Avg. loss: 3.813206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.74, NNZs: 44, Bias: -0.116994, T: 3840, Avg. loss: 3.862541\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.70, NNZs: 44, Bias: -0.135162, T: 4480, Avg. loss: 3.740942\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.008761167526245117 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.021067, T: 640, Avg. loss: 3.984145\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.48, NNZs: 44, Bias: -0.040317, T: 1280, Avg. loss: 3.222851\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.059537, T: 1920, Avg. loss: 3.644051\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.50, NNZs: 44, Bias: -0.078804, T: 2560, Avg. loss: 4.137911\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.45, NNZs: 44, Bias: -0.098773, T: 3200, Avg. loss: 3.813206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.74, NNZs: 44, Bias: -0.116994, T: 3840, Avg. loss: 3.862541\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.70, NNZs: 44, Bias: -0.135162, T: 4480, Avg. loss: 3.740942\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.008816957473754883 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.021067, T: 640, Avg. loss: 3.984145\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.48, NNZs: 44, Bias: -0.040317, T: 1280, Avg. loss: 3.222851\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.059537, T: 1920, Avg. loss: 3.644051\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.50, NNZs: 44, Bias: -0.078804, T: 2560, Avg. loss: 4.137911\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.45, NNZs: 44, Bias: -0.098773, T: 3200, Avg. loss: 3.813206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.74, NNZs: 44, Bias: -0.116994, T: 3840, Avg. loss: 3.862541\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.70, NNZs: 44, Bias: -0.135162, T: 4480, Avg. loss: 3.740942\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.008114099502563477 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 500.74, NNZs: 40, Bias: -52.512065, T: 640, Avg. loss: 8966.903966\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 320.78, NNZs: 43, Bias: -72.608925, T: 1280, Avg. loss: 3357.209314\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 230.09, NNZs: 43, Bias: -84.340473, T: 1920, Avg. loss: 2166.524856\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 189.36, NNZs: 43, Bias: -92.661941, T: 2560, Avg. loss: 1764.310331\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 168.40, NNZs: 44, Bias: -99.779847, T: 3200, Avg. loss: 1306.004672\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 202.15, NNZs: 44, Bias: -104.232835, T: 3840, Avg. loss: 995.721480\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 137.92, NNZs: 44, Bias: -108.116835, T: 4480, Avg. loss: 926.979040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 151.23, NNZs: 44, Bias: -112.749757, T: 5120, Avg. loss: 746.909156\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 148.27, NNZs: 44, Bias: -116.665804, T: 5760, Avg. loss: 699.113288\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 153.32, NNZs: 44, Bias: -119.708379, T: 6400, Avg. loss: 599.858419\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 133.29, NNZs: 44, Bias: -122.480550, T: 7040, Avg. loss: 555.386621\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 126.49, NNZs: 44, Bias: -124.739493, T: 7680, Avg. loss: 528.065646\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 117.66, NNZs: 44, Bias: -127.544830, T: 8320, Avg. loss: 475.009744\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 109.57, NNZs: 44, Bias: -129.587971, T: 8960, Avg. loss: 491.862829\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 106.81, NNZs: 44, Bias: -131.703656, T: 9600, Avg. loss: 446.339582\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 112.49, NNZs: 44, Bias: -133.685142, T: 10240, Avg. loss: 363.660773\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 115.80, NNZs: 44, Bias: -135.462435, T: 10880, Avg. loss: 317.797125\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 114.90, NNZs: 44, Bias: -137.127378, T: 11520, Avg. loss: 313.789935\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 105.54, NNZs: 44, Bias: -138.791050, T: 12160, Avg. loss: 348.313547\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 104.84, NNZs: 44, Bias: -140.210565, T: 12800, Avg. loss: 334.727113\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 107.89, NNZs: 44, Bias: -141.560703, T: 13440, Avg. loss: 298.511347\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 100.53, NNZs: 44, Bias: -142.568970, T: 14080, Avg. loss: 257.251948\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 104.61, NNZs: 44, Bias: -143.586413, T: 14720, Avg. loss: 250.219567\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 105.06, NNZs: 44, Bias: -144.970692, T: 15360, Avg. loss: 247.542619\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 100.92, NNZs: 44, Bias: -146.237201, T: 16000, Avg. loss: 248.501058\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 100.15, NNZs: 44, Bias: -147.451414, T: 16640, Avg. loss: 225.751338\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 103.35, NNZs: 44, Bias: -148.561394, T: 17280, Avg. loss: 212.981286\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 100.88, NNZs: 44, Bias: -149.463165, T: 17920, Avg. loss: 191.596918\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 101.96, NNZs: 44, Bias: -150.548571, T: 18560, Avg. loss: 189.725798\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 103.52, NNZs: 44, Bias: -151.611007, T: 19200, Avg. loss: 183.233201\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 102.28, NNZs: 44, Bias: -152.380246, T: 19840, Avg. loss: 201.349287\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 101.43, NNZs: 44, Bias: -153.315040, T: 20480, Avg. loss: 194.863840\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 98.98, NNZs: 44, Bias: -153.983702, T: 21120, Avg. loss: 169.953737\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 98.06, NNZs: 44, Bias: -154.831632, T: 21760, Avg. loss: 173.155293\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 99.43, NNZs: 44, Bias: -155.729074, T: 22400, Avg. loss: 155.416821\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 100.79, NNZs: 44, Bias: -156.597047, T: 23040, Avg. loss: 153.429602\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 97.84, NNZs: 44, Bias: -157.191383, T: 23680, Avg. loss: 159.924902\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 97.13, NNZs: 44, Bias: -157.891737, T: 24320, Avg. loss: 148.308670\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 97.03, NNZs: 44, Bias: -158.613327, T: 24960, Avg. loss: 133.659802\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 96.85, NNZs: 44, Bias: -159.227607, T: 25600, Avg. loss: 145.577644\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 95.71, NNZs: 44, Bias: -159.751561, T: 26240, Avg. loss: 132.080117\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 95.59, NNZs: 44, Bias: -160.375331, T: 26880, Avg. loss: 117.890443\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 96.42, NNZs: 44, Bias: -160.953157, T: 27520, Avg. loss: 134.577507\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 95.09, NNZs: 44, Bias: -161.520962, T: 28160, Avg. loss: 136.019925\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 94.90, NNZs: 44, Bias: -162.150253, T: 28800, Avg. loss: 127.672971\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 94.33, NNZs: 44, Bias: -162.662278, T: 29440, Avg. loss: 127.475931\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 95.54, NNZs: 44, Bias: -163.365363, T: 30080, Avg. loss: 123.089532\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 47 epochs took 0.02 seconds\n",
      "--- training time 0.029799222946166992 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 500.74, NNZs: 40, Bias: -52.512065, T: 640, Avg. loss: 8966.903966\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 320.78, NNZs: 43, Bias: -72.608925, T: 1280, Avg. loss: 3357.209314\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 230.09, NNZs: 43, Bias: -84.340473, T: 1920, Avg. loss: 2166.524856\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 189.36, NNZs: 43, Bias: -92.661941, T: 2560, Avg. loss: 1764.310331\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 168.40, NNZs: 44, Bias: -99.779847, T: 3200, Avg. loss: 1306.004672\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 202.15, NNZs: 44, Bias: -104.232835, T: 3840, Avg. loss: 995.721480\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 137.92, NNZs: 44, Bias: -108.116835, T: 4480, Avg. loss: 926.979040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 151.23, NNZs: 44, Bias: -112.749757, T: 5120, Avg. loss: 746.909156\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 148.27, NNZs: 44, Bias: -116.665804, T: 5760, Avg. loss: 699.113288\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 153.32, NNZs: 44, Bias: -119.708379, T: 6400, Avg. loss: 599.858419\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 133.29, NNZs: 44, Bias: -122.480550, T: 7040, Avg. loss: 555.386621\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 126.49, NNZs: 44, Bias: -124.739493, T: 7680, Avg. loss: 528.065646\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 117.66, NNZs: 44, Bias: -127.544830, T: 8320, Avg. loss: 475.009744\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 109.57, NNZs: 44, Bias: -129.587971, T: 8960, Avg. loss: 491.862829\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 106.81, NNZs: 44, Bias: -131.703656, T: 9600, Avg. loss: 446.339582\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 112.49, NNZs: 44, Bias: -133.685142, T: 10240, Avg. loss: 363.660773\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 115.80, NNZs: 44, Bias: -135.462435, T: 10880, Avg. loss: 317.797125\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 114.90, NNZs: 44, Bias: -137.127378, T: 11520, Avg. loss: 313.789935\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 105.54, NNZs: 44, Bias: -138.791050, T: 12160, Avg. loss: 348.313547\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 104.84, NNZs: 44, Bias: -140.210565, T: 12800, Avg. loss: 334.727113\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 107.89, NNZs: 44, Bias: -141.560703, T: 13440, Avg. loss: 298.511347\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 100.53, NNZs: 44, Bias: -142.568970, T: 14080, Avg. loss: 257.251948\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 104.61, NNZs: 44, Bias: -143.586413, T: 14720, Avg. loss: 250.219567\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 105.06, NNZs: 44, Bias: -144.970692, T: 15360, Avg. loss: 247.542619\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 100.92, NNZs: 44, Bias: -146.237201, T: 16000, Avg. loss: 248.501058\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 100.15, NNZs: 44, Bias: -147.451414, T: 16640, Avg. loss: 225.751338\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 103.35, NNZs: 44, Bias: -148.561394, T: 17280, Avg. loss: 212.981286\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 100.88, NNZs: 44, Bias: -149.463165, T: 17920, Avg. loss: 191.596918\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 101.96, NNZs: 44, Bias: -150.548571, T: 18560, Avg. loss: 189.725798\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 103.52, NNZs: 44, Bias: -151.611007, T: 19200, Avg. loss: 183.233201\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 102.28, NNZs: 44, Bias: -152.380246, T: 19840, Avg. loss: 201.349287\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 101.43, NNZs: 44, Bias: -153.315040, T: 20480, Avg. loss: 194.863840\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 98.98, NNZs: 44, Bias: -153.983702, T: 21120, Avg. loss: 169.953737\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 98.06, NNZs: 44, Bias: -154.831632, T: 21760, Avg. loss: 173.155293\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 99.43, NNZs: 44, Bias: -155.729074, T: 22400, Avg. loss: 155.416821\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 100.79, NNZs: 44, Bias: -156.597047, T: 23040, Avg. loss: 153.429602\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 97.84, NNZs: 44, Bias: -157.191383, T: 23680, Avg. loss: 159.924902\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 97.13, NNZs: 44, Bias: -157.891737, T: 24320, Avg. loss: 148.308670\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 97.03, NNZs: 44, Bias: -158.613327, T: 24960, Avg. loss: 133.659802\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 96.85, NNZs: 44, Bias: -159.227607, T: 25600, Avg. loss: 145.577644\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 95.71, NNZs: 44, Bias: -159.751561, T: 26240, Avg. loss: 132.080117\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 95.59, NNZs: 44, Bias: -160.375331, T: 26880, Avg. loss: 117.890443\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 96.42, NNZs: 44, Bias: -160.953157, T: 27520, Avg. loss: 134.577507\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 95.09, NNZs: 44, Bias: -161.520962, T: 28160, Avg. loss: 136.019925\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 94.90, NNZs: 44, Bias: -162.150253, T: 28800, Avg. loss: 127.672971\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 94.33, NNZs: 44, Bias: -162.662278, T: 29440, Avg. loss: 127.475931\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 95.54, NNZs: 44, Bias: -163.365363, T: 30080, Avg. loss: 123.089532\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 47 epochs took 0.02 seconds\n",
      "--- training time 0.028528928756713867 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 500.74, NNZs: 40, Bias: -52.512065, T: 640, Avg. loss: 8966.903966\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 320.78, NNZs: 43, Bias: -72.608925, T: 1280, Avg. loss: 3357.209314\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 230.09, NNZs: 43, Bias: -84.340473, T: 1920, Avg. loss: 2166.524856\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 189.36, NNZs: 43, Bias: -92.661941, T: 2560, Avg. loss: 1764.310331\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 168.40, NNZs: 44, Bias: -99.779847, T: 3200, Avg. loss: 1306.004672\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 202.15, NNZs: 44, Bias: -104.232835, T: 3840, Avg. loss: 995.721480\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 137.92, NNZs: 44, Bias: -108.116835, T: 4480, Avg. loss: 926.979040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 151.23, NNZs: 44, Bias: -112.749757, T: 5120, Avg. loss: 746.909156\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 148.27, NNZs: 44, Bias: -116.665804, T: 5760, Avg. loss: 699.113288\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 153.32, NNZs: 44, Bias: -119.708379, T: 6400, Avg. loss: 599.858419\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 133.29, NNZs: 44, Bias: -122.480550, T: 7040, Avg. loss: 555.386621\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 126.49, NNZs: 44, Bias: -124.739493, T: 7680, Avg. loss: 528.065646\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 117.66, NNZs: 44, Bias: -127.544830, T: 8320, Avg. loss: 475.009744\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 109.57, NNZs: 44, Bias: -129.587971, T: 8960, Avg. loss: 491.862829\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 106.81, NNZs: 44, Bias: -131.703656, T: 9600, Avg. loss: 446.339582\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 112.49, NNZs: 44, Bias: -133.685142, T: 10240, Avg. loss: 363.660773\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 115.80, NNZs: 44, Bias: -135.462435, T: 10880, Avg. loss: 317.797125\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 114.90, NNZs: 44, Bias: -137.127378, T: 11520, Avg. loss: 313.789935\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 105.54, NNZs: 44, Bias: -138.791050, T: 12160, Avg. loss: 348.313547\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 104.84, NNZs: 44, Bias: -140.210565, T: 12800, Avg. loss: 334.727113\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 107.89, NNZs: 44, Bias: -141.560703, T: 13440, Avg. loss: 298.511347\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 100.53, NNZs: 44, Bias: -142.568970, T: 14080, Avg. loss: 257.251948\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 104.61, NNZs: 44, Bias: -143.586413, T: 14720, Avg. loss: 250.219567\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 105.06, NNZs: 44, Bias: -144.970692, T: 15360, Avg. loss: 247.542619\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 100.92, NNZs: 44, Bias: -146.237201, T: 16000, Avg. loss: 248.501058\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 100.15, NNZs: 44, Bias: -147.451414, T: 16640, Avg. loss: 225.751338\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 103.35, NNZs: 44, Bias: -148.561394, T: 17280, Avg. loss: 212.981286\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 100.88, NNZs: 44, Bias: -149.463165, T: 17920, Avg. loss: 191.596918\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 101.96, NNZs: 44, Bias: -150.548571, T: 18560, Avg. loss: 189.725798\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 103.52, NNZs: 44, Bias: -151.611007, T: 19200, Avg. loss: 183.233201\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 102.28, NNZs: 44, Bias: -152.380246, T: 19840, Avg. loss: 201.349287\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 101.43, NNZs: 44, Bias: -153.315040, T: 20480, Avg. loss: 194.863840\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 98.98, NNZs: 44, Bias: -153.983702, T: 21120, Avg. loss: 169.953737\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 98.06, NNZs: 44, Bias: -154.831632, T: 21760, Avg. loss: 173.155293\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 99.43, NNZs: 44, Bias: -155.729074, T: 22400, Avg. loss: 155.416821\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 100.79, NNZs: 44, Bias: -156.597047, T: 23040, Avg. loss: 153.429602\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 97.84, NNZs: 44, Bias: -157.191383, T: 23680, Avg. loss: 159.924902\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 97.13, NNZs: 44, Bias: -157.891737, T: 24320, Avg. loss: 148.308670\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 97.03, NNZs: 44, Bias: -158.613327, T: 24960, Avg. loss: 133.659802\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 96.85, NNZs: 44, Bias: -159.227607, T: 25600, Avg. loss: 145.577644\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 95.71, NNZs: 44, Bias: -159.751561, T: 26240, Avg. loss: 132.080117\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 95.59, NNZs: 44, Bias: -160.375331, T: 26880, Avg. loss: 117.890443\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 96.42, NNZs: 44, Bias: -160.953157, T: 27520, Avg. loss: 134.577507\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 95.09, NNZs: 44, Bias: -161.520962, T: 28160, Avg. loss: 136.019925\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 94.90, NNZs: 44, Bias: -162.150253, T: 28800, Avg. loss: 127.672971\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 94.33, NNZs: 44, Bias: -162.662278, T: 29440, Avg. loss: 127.475931\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 95.54, NNZs: 44, Bias: -163.365363, T: 30080, Avg. loss: 123.089532\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 47 epochs took 0.02 seconds\n",
      "--- training time 0.02968883514404297 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.04, NNZs: 44, Bias: -0.001716, T: 640, Avg. loss: 0.494289\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.04, NNZs: 44, Bias: -0.002572, T: 1280, Avg. loss: 0.364677\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.003237, T: 1920, Avg. loss: 0.349521\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.003750, T: 2560, Avg. loss: 0.365191\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.004277, T: 3200, Avg. loss: 0.343723\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.004730, T: 3840, Avg. loss: 0.350922\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005132, T: 4480, Avg. loss: 0.338571\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005522, T: 5120, Avg. loss: 0.343426\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005915, T: 5760, Avg. loss: 0.344485\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006246, T: 6400, Avg. loss: 0.344850\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006582, T: 7040, Avg. loss: 0.339307\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006865, T: 7680, Avg. loss: 0.340507\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 12 epochs took 0.01 seconds\n",
      "--- training time 0.012262105941772461 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.04, NNZs: 44, Bias: -0.001716, T: 640, Avg. loss: 0.494289\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.04, NNZs: 44, Bias: -0.002572, T: 1280, Avg. loss: 0.364677\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.003237, T: 1920, Avg. loss: 0.349521\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.003750, T: 2560, Avg. loss: 0.365191\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.004277, T: 3200, Avg. loss: 0.343723\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.004730, T: 3840, Avg. loss: 0.350922\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005132, T: 4480, Avg. loss: 0.338571\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005522, T: 5120, Avg. loss: 0.343426\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005915, T: 5760, Avg. loss: 0.344485\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006246, T: 6400, Avg. loss: 0.344850\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006582, T: 7040, Avg. loss: 0.339307\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006865, T: 7680, Avg. loss: 0.340507\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 12 epochs took 0.00 seconds\n",
      "--- training time 0.007154941558837891 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.04, NNZs: 44, Bias: -0.001716, T: 640, Avg. loss: 0.494289\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.04, NNZs: 44, Bias: -0.002572, T: 1280, Avg. loss: 0.364677\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.003237, T: 1920, Avg. loss: 0.349521\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.003750, T: 2560, Avg. loss: 0.365191\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.004277, T: 3200, Avg. loss: 0.343723\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.004730, T: 3840, Avg. loss: 0.350922\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005132, T: 4480, Avg. loss: 0.338571\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005522, T: 5120, Avg. loss: 0.343426\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.005915, T: 5760, Avg. loss: 0.344485\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006246, T: 6400, Avg. loss: 0.344850\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006582, T: 7040, Avg. loss: 0.339307\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.05, NNZs: 44, Bias: -0.006865, T: 7680, Avg. loss: 0.340507\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 12 epochs took 0.00 seconds\n",
      "--- training time 0.006494045257568359 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.021067, T: 640, Avg. loss: 3.984145\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.48, NNZs: 44, Bias: -0.040317, T: 1280, Avg. loss: 3.222851\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.059537, T: 1920, Avg. loss: 3.644051\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.50, NNZs: 44, Bias: -0.078804, T: 2560, Avg. loss: 4.137911\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.45, NNZs: 44, Bias: -0.098773, T: 3200, Avg. loss: 3.813206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.74, NNZs: 44, Bias: -0.116994, T: 3840, Avg. loss: 3.862541\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.70, NNZs: 44, Bias: -0.135162, T: 4480, Avg. loss: 3.740942\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.138026, T: 5120, Avg. loss: 1.398175\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.51, NNZs: 44, Bias: -0.141678, T: 5760, Avg. loss: 0.953206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.52, NNZs: 44, Bias: -0.145249, T: 6400, Avg. loss: 0.784679\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.52, NNZs: 44, Bias: -0.149089, T: 7040, Avg. loss: 0.727688\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.53, NNZs: 44, Bias: -0.152845, T: 7680, Avg. loss: 0.727317\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.54, NNZs: 44, Bias: -0.156963, T: 8320, Avg. loss: 0.685719\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.55, NNZs: 44, Bias: -0.160600, T: 8960, Avg. loss: 0.805217\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.165141, T: 9600, Avg. loss: 0.780246\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.57, NNZs: 44, Bias: -0.168779, T: 10240, Avg. loss: 0.745140\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.59, NNZs: 44, Bias: -0.173353, T: 10880, Avg. loss: 0.668678\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.60, NNZs: 44, Bias: -0.177487, T: 11520, Avg. loss: 0.741204\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.61, NNZs: 44, Bias: -0.181503, T: 12160, Avg. loss: 0.770187\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.62, NNZs: 44, Bias: -0.185364, T: 12800, Avg. loss: 0.800654\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.63, NNZs: 44, Bias: -0.189288, T: 13440, Avg. loss: 0.788337\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.193096, T: 14080, Avg. loss: 0.677807\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.193678, T: 14720, Avg. loss: 0.353993\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.194425, T: 15360, Avg. loss: 0.313918\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.195239, T: 16000, Avg. loss: 0.305386\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.195940, T: 16640, Avg. loss: 0.306292\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.196674, T: 17280, Avg. loss: 0.298847\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.197423, T: 17920, Avg. loss: 0.304501\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.198198, T: 18560, Avg. loss: 0.304672\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.199014, T: 19200, Avg. loss: 0.298193\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.199779, T: 19840, Avg. loss: 0.313134\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200556, T: 20480, Avg. loss: 0.311360\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200677, T: 21120, Avg. loss: 0.266225\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200840, T: 21760, Avg. loss: 0.258514\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200990, T: 22400, Avg. loss: 0.262786\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.201148, T: 23040, Avg. loss: 0.263645\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.201312, T: 23680, Avg. loss: 0.266481\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201486, T: 24320, Avg. loss: 0.261895\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201651, T: 24960, Avg. loss: 0.259777\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201667, T: 25600, Avg. loss: 0.260109\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201695, T: 26240, Avg. loss: 0.254555\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201730, T: 26880, Avg. loss: 0.254708\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201758, T: 27520, Avg. loss: 0.254875\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201796, T: 28160, Avg. loss: 0.254540\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201830, T: 28800, Avg. loss: 0.254008\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201855, T: 29440, Avg. loss: 0.255364\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201862, T: 30080, Avg. loss: 0.252925\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201869, T: 30720, Avg. loss: 0.252909\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201875, T: 31360, Avg. loss: 0.252805\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201882, T: 32000, Avg. loss: 0.252968\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201888, T: 32640, Avg. loss: 0.252887\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201895, T: 33280, Avg. loss: 0.252886\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 52 epochs took 0.01 seconds\n",
      "--- training time 0.014230012893676758 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.021067, T: 640, Avg. loss: 3.984145\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.48, NNZs: 44, Bias: -0.040317, T: 1280, Avg. loss: 3.222851\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.059537, T: 1920, Avg. loss: 3.644051\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.50, NNZs: 44, Bias: -0.078804, T: 2560, Avg. loss: 4.137911\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.45, NNZs: 44, Bias: -0.098773, T: 3200, Avg. loss: 3.813206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.74, NNZs: 44, Bias: -0.116994, T: 3840, Avg. loss: 3.862541\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.70, NNZs: 44, Bias: -0.135162, T: 4480, Avg. loss: 3.740942\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.138026, T: 5120, Avg. loss: 1.398175\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.51, NNZs: 44, Bias: -0.141678, T: 5760, Avg. loss: 0.953206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.52, NNZs: 44, Bias: -0.145249, T: 6400, Avg. loss: 0.784679\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.52, NNZs: 44, Bias: -0.149089, T: 7040, Avg. loss: 0.727688\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.53, NNZs: 44, Bias: -0.152845, T: 7680, Avg. loss: 0.727317\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.54, NNZs: 44, Bias: -0.156963, T: 8320, Avg. loss: 0.685719\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.55, NNZs: 44, Bias: -0.160600, T: 8960, Avg. loss: 0.805217\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.165141, T: 9600, Avg. loss: 0.780246\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.57, NNZs: 44, Bias: -0.168779, T: 10240, Avg. loss: 0.745140\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.59, NNZs: 44, Bias: -0.173353, T: 10880, Avg. loss: 0.668678\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.60, NNZs: 44, Bias: -0.177487, T: 11520, Avg. loss: 0.741204\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.61, NNZs: 44, Bias: -0.181503, T: 12160, Avg. loss: 0.770187\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.62, NNZs: 44, Bias: -0.185364, T: 12800, Avg. loss: 0.800654\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.63, NNZs: 44, Bias: -0.189288, T: 13440, Avg. loss: 0.788337\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.193096, T: 14080, Avg. loss: 0.677807\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.193678, T: 14720, Avg. loss: 0.353993\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.194425, T: 15360, Avg. loss: 0.313918\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.195239, T: 16000, Avg. loss: 0.305386\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.195940, T: 16640, Avg. loss: 0.306292\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.196674, T: 17280, Avg. loss: 0.298847\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.197423, T: 17920, Avg. loss: 0.304501\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.198198, T: 18560, Avg. loss: 0.304672\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.199014, T: 19200, Avg. loss: 0.298193\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.199779, T: 19840, Avg. loss: 0.313134\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200556, T: 20480, Avg. loss: 0.311360\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200677, T: 21120, Avg. loss: 0.266225\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200840, T: 21760, Avg. loss: 0.258514\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200990, T: 22400, Avg. loss: 0.262786\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.201148, T: 23040, Avg. loss: 0.263645\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.201312, T: 23680, Avg. loss: 0.266481\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201486, T: 24320, Avg. loss: 0.261895\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201651, T: 24960, Avg. loss: 0.259777\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201667, T: 25600, Avg. loss: 0.260109\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201695, T: 26240, Avg. loss: 0.254555\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201730, T: 26880, Avg. loss: 0.254708\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201758, T: 27520, Avg. loss: 0.254875\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201796, T: 28160, Avg. loss: 0.254540\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201830, T: 28800, Avg. loss: 0.254008\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201855, T: 29440, Avg. loss: 0.255364\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201862, T: 30080, Avg. loss: 0.252925\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201869, T: 30720, Avg. loss: 0.252909\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201875, T: 31360, Avg. loss: 0.252805\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201882, T: 32000, Avg. loss: 0.252968\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201888, T: 32640, Avg. loss: 0.252887\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201895, T: 33280, Avg. loss: 0.252886\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 52 epochs took 0.01 seconds\n",
      "--- training time 0.01511240005493164 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.021067, T: 640, Avg. loss: 3.984145\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.48, NNZs: 44, Bias: -0.040317, T: 1280, Avg. loss: 3.222851\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.059537, T: 1920, Avg. loss: 3.644051\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.50, NNZs: 44, Bias: -0.078804, T: 2560, Avg. loss: 4.137911\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.45, NNZs: 44, Bias: -0.098773, T: 3200, Avg. loss: 3.813206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.74, NNZs: 44, Bias: -0.116994, T: 3840, Avg. loss: 3.862541\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.70, NNZs: 44, Bias: -0.135162, T: 4480, Avg. loss: 3.740942\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.138026, T: 5120, Avg. loss: 1.398175\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.51, NNZs: 44, Bias: -0.141678, T: 5760, Avg. loss: 0.953206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.52, NNZs: 44, Bias: -0.145249, T: 6400, Avg. loss: 0.784679\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.52, NNZs: 44, Bias: -0.149089, T: 7040, Avg. loss: 0.727688\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.53, NNZs: 44, Bias: -0.152845, T: 7680, Avg. loss: 0.727317\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.54, NNZs: 44, Bias: -0.156963, T: 8320, Avg. loss: 0.685719\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.55, NNZs: 44, Bias: -0.160600, T: 8960, Avg. loss: 0.805217\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.56, NNZs: 44, Bias: -0.165141, T: 9600, Avg. loss: 0.780246\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.57, NNZs: 44, Bias: -0.168779, T: 10240, Avg. loss: 0.745140\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.59, NNZs: 44, Bias: -0.173353, T: 10880, Avg. loss: 0.668678\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.60, NNZs: 44, Bias: -0.177487, T: 11520, Avg. loss: 0.741204\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.61, NNZs: 44, Bias: -0.181503, T: 12160, Avg. loss: 0.770187\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.62, NNZs: 44, Bias: -0.185364, T: 12800, Avg. loss: 0.800654\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.63, NNZs: 44, Bias: -0.189288, T: 13440, Avg. loss: 0.788337\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.193096, T: 14080, Avg. loss: 0.677807\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.193678, T: 14720, Avg. loss: 0.353993\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.194425, T: 15360, Avg. loss: 0.313918\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.195239, T: 16000, Avg. loss: 0.305386\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.195940, T: 16640, Avg. loss: 0.306292\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.64, NNZs: 44, Bias: -0.196674, T: 17280, Avg. loss: 0.298847\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.197423, T: 17920, Avg. loss: 0.304501\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.198198, T: 18560, Avg. loss: 0.304672\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.199014, T: 19200, Avg. loss: 0.298193\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.199779, T: 19840, Avg. loss: 0.313134\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200556, T: 20480, Avg. loss: 0.311360\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200677, T: 21120, Avg. loss: 0.266225\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200840, T: 21760, Avg. loss: 0.258514\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.200990, T: 22400, Avg. loss: 0.262786\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.201148, T: 23040, Avg. loss: 0.263645\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.65, NNZs: 44, Bias: -0.201312, T: 23680, Avg. loss: 0.266481\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201486, T: 24320, Avg. loss: 0.261895\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201651, T: 24960, Avg. loss: 0.259777\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201667, T: 25600, Avg. loss: 0.260109\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201695, T: 26240, Avg. loss: 0.254555\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201730, T: 26880, Avg. loss: 0.254708\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201758, T: 27520, Avg. loss: 0.254875\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201796, T: 28160, Avg. loss: 0.254540\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201830, T: 28800, Avg. loss: 0.254008\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201855, T: 29440, Avg. loss: 0.255364\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201862, T: 30080, Avg. loss: 0.252925\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201869, T: 30720, Avg. loss: 0.252909\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201875, T: 31360, Avg. loss: 0.252805\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201882, T: 32000, Avg. loss: 0.252968\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201888, T: 32640, Avg. loss: 0.252887\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.66, NNZs: 44, Bias: -0.201895, T: 33280, Avg. loss: 0.252886\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 52 epochs took 0.01 seconds\n",
      "--- training time 0.014155149459838867 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 3.92, NNZs: 44, Bias: -0.229017, T: 640, Avg. loss: 39.588520\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.22, NNZs: 44, Bias: -0.412678, T: 1280, Avg. loss: 36.358448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.77, NNZs: 44, Bias: -0.608724, T: 1920, Avg. loss: 37.326056\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.16, NNZs: 44, Bias: -0.820996, T: 2560, Avg. loss: 41.772040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.046754, T: 3200, Avg. loss: 40.525607\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.70, NNZs: 44, Bias: -1.233228, T: 3840, Avg. loss: 39.758304\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 6.79, NNZs: 44, Bias: -1.422213, T: 4480, Avg. loss: 39.742680\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.004954814910888672 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 3.92, NNZs: 44, Bias: -0.229017, T: 640, Avg. loss: 39.588520\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.22, NNZs: 44, Bias: -0.412678, T: 1280, Avg. loss: 36.358448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.77, NNZs: 44, Bias: -0.608724, T: 1920, Avg. loss: 37.326056\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.16, NNZs: 44, Bias: -0.820996, T: 2560, Avg. loss: 41.772040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.046754, T: 3200, Avg. loss: 40.525607\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.70, NNZs: 44, Bias: -1.233228, T: 3840, Avg. loss: 39.758304\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 6.79, NNZs: 44, Bias: -1.422213, T: 4480, Avg. loss: 39.742680\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.00505375862121582 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 3.92, NNZs: 44, Bias: -0.229017, T: 640, Avg. loss: 39.588520\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.22, NNZs: 44, Bias: -0.412678, T: 1280, Avg. loss: 36.358448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.77, NNZs: 44, Bias: -0.608724, T: 1920, Avg. loss: 37.326056\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.16, NNZs: 44, Bias: -0.820996, T: 2560, Avg. loss: 41.772040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.046754, T: 3200, Avg. loss: 40.525607\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.70, NNZs: 44, Bias: -1.233228, T: 3840, Avg. loss: 39.758304\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 6.79, NNZs: 44, Bias: -1.422213, T: 4480, Avg. loss: 39.742680\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.004970073699951172 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 60.99, NNZs: 42, Bias: -10.453885, T: 640, Avg. loss: 1552.509515\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 35.66, NNZs: 43, Bias: -12.783554, T: 1280, Avg. loss: 389.856725\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24.73, NNZs: 43, Bias: -14.062543, T: 1920, Avg. loss: 236.101649\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 20.01, NNZs: 44, Bias: -14.948544, T: 2560, Avg. loss: 187.732636\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 18.39, NNZs: 44, Bias: -15.671130, T: 3200, Avg. loss: 136.399263\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.70, NNZs: 44, Bias: -16.116936, T: 3840, Avg. loss: 111.364907\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 15.98, NNZs: 44, Bias: -16.589929, T: 4480, Avg. loss: 97.613050\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 14.31, NNZs: 44, Bias: -16.987956, T: 5120, Avg. loss: 74.871437\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 15.61, NNZs: 44, Bias: -17.388014, T: 5760, Avg. loss: 67.966306\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 13.92, NNZs: 44, Bias: -17.682240, T: 6400, Avg. loss: 61.636073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 11.86, NNZs: 44, Bias: -17.950590, T: 7040, Avg. loss: 55.904815\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 12.77, NNZs: 44, Bias: -18.208976, T: 7680, Avg. loss: 46.708359\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 11.33, NNZs: 44, Bias: -18.482606, T: 8320, Avg. loss: 45.033947\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 11.24, NNZs: 44, Bias: -18.677592, T: 8960, Avg. loss: 44.011195\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 11.42, NNZs: 44, Bias: -18.902786, T: 9600, Avg. loss: 43.701096\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 11.15, NNZs: 44, Bias: -19.059339, T: 10240, Avg. loss: 36.234746\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 11.28, NNZs: 44, Bias: -19.274144, T: 10880, Avg. loss: 33.412584\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 11.10, NNZs: 44, Bias: -19.442793, T: 11520, Avg. loss: 33.555258\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 10.71, NNZs: 44, Bias: -19.610984, T: 12160, Avg. loss: 34.817090\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 10.65, NNZs: 44, Bias: -19.756785, T: 12800, Avg. loss: 33.258951\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 11.12, NNZs: 44, Bias: -19.904638, T: 13440, Avg. loss: 30.816617\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 10.41, NNZs: 44, Bias: -20.032428, T: 14080, Avg. loss: 25.012433\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 10.57, NNZs: 44, Bias: -20.137965, T: 14720, Avg. loss: 28.452017\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 10.37, NNZs: 44, Bias: -20.251578, T: 15360, Avg. loss: 21.674290\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 10.47, NNZs: 44, Bias: -20.372988, T: 16000, Avg. loss: 22.736932\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 10.00, NNZs: 44, Bias: -20.472535, T: 16640, Avg. loss: 22.318439\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 10.02, NNZs: 44, Bias: -20.558950, T: 17280, Avg. loss: 20.445041\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 9.96, NNZs: 44, Bias: -20.664347, T: 17920, Avg. loss: 19.539886\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 9.83, NNZs: 44, Bias: -20.762185, T: 18560, Avg. loss: 19.285078\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 10.04, NNZs: 44, Bias: -20.861298, T: 19200, Avg. loss: 18.476698\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 10.05, NNZs: 44, Bias: -20.937798, T: 19840, Avg. loss: 19.100710\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 9.78, NNZs: 44, Bias: -21.031560, T: 20480, Avg. loss: 19.932161\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 9.73, NNZs: 44, Bias: -21.091787, T: 21120, Avg. loss: 16.569235\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 9.61, NNZs: 44, Bias: -21.180585, T: 21760, Avg. loss: 17.286220\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 9.71, NNZs: 44, Bias: -21.269395, T: 22400, Avg. loss: 16.595709\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 9.69, NNZs: 44, Bias: -21.341714, T: 23040, Avg. loss: 15.801840\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 9.62, NNZs: 44, Bias: -21.409972, T: 23680, Avg. loss: 15.241195\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 9.56, NNZs: 44, Bias: -21.492169, T: 24320, Avg. loss: 14.953152\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 9.59, NNZs: 44, Bias: -21.566195, T: 24960, Avg. loss: 13.076712\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 9.55, NNZs: 44, Bias: -21.629678, T: 25600, Avg. loss: 14.345237\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 9.57, NNZs: 44, Bias: -21.692393, T: 26240, Avg. loss: 13.411980\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 9.47, NNZs: 44, Bias: -21.744887, T: 26880, Avg. loss: 12.224874\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 9.46, NNZs: 44, Bias: -21.804454, T: 27520, Avg. loss: 12.965197\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 9.36, NNZs: 44, Bias: -21.862684, T: 28160, Avg. loss: 13.809267\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 9.37, NNZs: 44, Bias: -21.925840, T: 28800, Avg. loss: 11.215663\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 9.29, NNZs: 44, Bias: -21.977134, T: 29440, Avg. loss: 10.919410\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 9.44, NNZs: 44, Bias: -22.046628, T: 30080, Avg. loss: 11.670287\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 9.33, NNZs: 44, Bias: -22.098766, T: 30720, Avg. loss: 10.678681\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 9.37, NNZs: 44, Bias: -22.149601, T: 31360, Avg. loss: 11.416260\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 9.30, NNZs: 44, Bias: -22.196523, T: 32000, Avg. loss: 11.358393\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 9.26, NNZs: 44, Bias: -22.242260, T: 32640, Avg. loss: 9.731031\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 9.12, NNZs: 44, Bias: -22.280656, T: 33280, Avg. loss: 9.006451\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 9.22, NNZs: 44, Bias: -22.328328, T: 33920, Avg. loss: 9.207657\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 9.12, NNZs: 44, Bias: -22.374595, T: 34560, Avg. loss: 9.882925\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 9.09, NNZs: 44, Bias: -22.421797, T: 35200, Avg. loss: 9.979394\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 9.11, NNZs: 44, Bias: -22.466248, T: 35840, Avg. loss: 8.893490\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 9.06, NNZs: 44, Bias: -22.513793, T: 36480, Avg. loss: 8.991318\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 9.03, NNZs: 44, Bias: -22.553100, T: 37120, Avg. loss: 8.224942\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 9.07, NNZs: 44, Bias: -22.589988, T: 37760, Avg. loss: 8.861412\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 9.01, NNZs: 44, Bias: -22.640601, T: 38400, Avg. loss: 8.698771\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 9.01, NNZs: 44, Bias: -22.685427, T: 39040, Avg. loss: 8.509588\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 8.98, NNZs: 44, Bias: -22.722693, T: 39680, Avg. loss: 7.738338\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 8.93, NNZs: 44, Bias: -22.760115, T: 40320, Avg. loss: 8.054029\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 8.93, NNZs: 44, Bias: -22.797019, T: 40960, Avg. loss: 8.500504\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 8.93, NNZs: 44, Bias: -22.838322, T: 41600, Avg. loss: 6.743084\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 8.90, NNZs: 44, Bias: -22.869848, T: 42240, Avg. loss: 7.161529\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 8.83, NNZs: 44, Bias: -22.908464, T: 42880, Avg. loss: 6.941667\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 8.84, NNZs: 44, Bias: -22.948904, T: 43520, Avg. loss: 9.023189\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 8.83, NNZs: 44, Bias: -22.979528, T: 44160, Avg. loss: 6.340707\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 8.79, NNZs: 44, Bias: -23.009289, T: 44800, Avg. loss: 7.420992\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 8.77, NNZs: 44, Bias: -23.043158, T: 45440, Avg. loss: 6.921390\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 8.71, NNZs: 44, Bias: -23.073129, T: 46080, Avg. loss: 7.010272\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 8.69, NNZs: 44, Bias: -23.106556, T: 46720, Avg. loss: 6.390169\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 8.68, NNZs: 44, Bias: -23.137707, T: 47360, Avg. loss: 6.870737\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 74 epochs took 0.02 seconds\n",
      "--- training time 0.019649028778076172 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 60.99, NNZs: 42, Bias: -10.453885, T: 640, Avg. loss: 1552.509515\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 35.66, NNZs: 43, Bias: -12.783554, T: 1280, Avg. loss: 389.856725\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24.73, NNZs: 43, Bias: -14.062543, T: 1920, Avg. loss: 236.101649\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 20.01, NNZs: 44, Bias: -14.948544, T: 2560, Avg. loss: 187.732636\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 18.39, NNZs: 44, Bias: -15.671130, T: 3200, Avg. loss: 136.399263\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.70, NNZs: 44, Bias: -16.116936, T: 3840, Avg. loss: 111.364907\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 15.98, NNZs: 44, Bias: -16.589929, T: 4480, Avg. loss: 97.613050\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 14.31, NNZs: 44, Bias: -16.987956, T: 5120, Avg. loss: 74.871437\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 15.61, NNZs: 44, Bias: -17.388014, T: 5760, Avg. loss: 67.966306\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 13.92, NNZs: 44, Bias: -17.682240, T: 6400, Avg. loss: 61.636073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 11.86, NNZs: 44, Bias: -17.950590, T: 7040, Avg. loss: 55.904815\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 12.77, NNZs: 44, Bias: -18.208976, T: 7680, Avg. loss: 46.708359\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 11.33, NNZs: 44, Bias: -18.482606, T: 8320, Avg. loss: 45.033947\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 11.24, NNZs: 44, Bias: -18.677592, T: 8960, Avg. loss: 44.011195\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 11.42, NNZs: 44, Bias: -18.902786, T: 9600, Avg. loss: 43.701096\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 11.15, NNZs: 44, Bias: -19.059339, T: 10240, Avg. loss: 36.234746\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 11.28, NNZs: 44, Bias: -19.274144, T: 10880, Avg. loss: 33.412584\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 11.10, NNZs: 44, Bias: -19.442793, T: 11520, Avg. loss: 33.555258\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 10.71, NNZs: 44, Bias: -19.610984, T: 12160, Avg. loss: 34.817090\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 10.65, NNZs: 44, Bias: -19.756785, T: 12800, Avg. loss: 33.258951\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 11.12, NNZs: 44, Bias: -19.904638, T: 13440, Avg. loss: 30.816617\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 10.41, NNZs: 44, Bias: -20.032428, T: 14080, Avg. loss: 25.012433\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 10.57, NNZs: 44, Bias: -20.137965, T: 14720, Avg. loss: 28.452017\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 10.37, NNZs: 44, Bias: -20.251578, T: 15360, Avg. loss: 21.674290\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 10.47, NNZs: 44, Bias: -20.372988, T: 16000, Avg. loss: 22.736932\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 10.00, NNZs: 44, Bias: -20.472535, T: 16640, Avg. loss: 22.318439\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 10.02, NNZs: 44, Bias: -20.558950, T: 17280, Avg. loss: 20.445041\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 9.96, NNZs: 44, Bias: -20.664347, T: 17920, Avg. loss: 19.539886\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 9.83, NNZs: 44, Bias: -20.762185, T: 18560, Avg. loss: 19.285078\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 10.04, NNZs: 44, Bias: -20.861298, T: 19200, Avg. loss: 18.476698\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 10.05, NNZs: 44, Bias: -20.937798, T: 19840, Avg. loss: 19.100710\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 9.78, NNZs: 44, Bias: -21.031560, T: 20480, Avg. loss: 19.932161\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 9.73, NNZs: 44, Bias: -21.091787, T: 21120, Avg. loss: 16.569235\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 9.61, NNZs: 44, Bias: -21.180585, T: 21760, Avg. loss: 17.286220\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 9.71, NNZs: 44, Bias: -21.269395, T: 22400, Avg. loss: 16.595709\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 9.69, NNZs: 44, Bias: -21.341714, T: 23040, Avg. loss: 15.801840\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 9.62, NNZs: 44, Bias: -21.409972, T: 23680, Avg. loss: 15.241195\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 9.56, NNZs: 44, Bias: -21.492169, T: 24320, Avg. loss: 14.953152\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 9.59, NNZs: 44, Bias: -21.566195, T: 24960, Avg. loss: 13.076712\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 9.55, NNZs: 44, Bias: -21.629678, T: 25600, Avg. loss: 14.345237\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 9.57, NNZs: 44, Bias: -21.692393, T: 26240, Avg. loss: 13.411980\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 9.47, NNZs: 44, Bias: -21.744887, T: 26880, Avg. loss: 12.224874\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 9.46, NNZs: 44, Bias: -21.804454, T: 27520, Avg. loss: 12.965197\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 9.36, NNZs: 44, Bias: -21.862684, T: 28160, Avg. loss: 13.809267\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 9.37, NNZs: 44, Bias: -21.925840, T: 28800, Avg. loss: 11.215663\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 9.29, NNZs: 44, Bias: -21.977134, T: 29440, Avg. loss: 10.919410\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 9.44, NNZs: 44, Bias: -22.046628, T: 30080, Avg. loss: 11.670287\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 9.33, NNZs: 44, Bias: -22.098766, T: 30720, Avg. loss: 10.678681\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 9.37, NNZs: 44, Bias: -22.149601, T: 31360, Avg. loss: 11.416260\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 9.30, NNZs: 44, Bias: -22.196523, T: 32000, Avg. loss: 11.358393\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 9.26, NNZs: 44, Bias: -22.242260, T: 32640, Avg. loss: 9.731031\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 9.12, NNZs: 44, Bias: -22.280656, T: 33280, Avg. loss: 9.006451\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 9.22, NNZs: 44, Bias: -22.328328, T: 33920, Avg. loss: 9.207657\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 9.12, NNZs: 44, Bias: -22.374595, T: 34560, Avg. loss: 9.882925\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 9.09, NNZs: 44, Bias: -22.421797, T: 35200, Avg. loss: 9.979394\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 9.11, NNZs: 44, Bias: -22.466248, T: 35840, Avg. loss: 8.893490\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 9.06, NNZs: 44, Bias: -22.513793, T: 36480, Avg. loss: 8.991318\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 9.03, NNZs: 44, Bias: -22.553100, T: 37120, Avg. loss: 8.224942\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 9.07, NNZs: 44, Bias: -22.589988, T: 37760, Avg. loss: 8.861412\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 9.01, NNZs: 44, Bias: -22.640601, T: 38400, Avg. loss: 8.698771\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 9.01, NNZs: 44, Bias: -22.685427, T: 39040, Avg. loss: 8.509588\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 8.98, NNZs: 44, Bias: -22.722693, T: 39680, Avg. loss: 7.738338\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 8.93, NNZs: 44, Bias: -22.760115, T: 40320, Avg. loss: 8.054029\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 8.93, NNZs: 44, Bias: -22.797019, T: 40960, Avg. loss: 8.500504\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 8.93, NNZs: 44, Bias: -22.838322, T: 41600, Avg. loss: 6.743084\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 8.90, NNZs: 44, Bias: -22.869848, T: 42240, Avg. loss: 7.161529\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 8.83, NNZs: 44, Bias: -22.908464, T: 42880, Avg. loss: 6.941667\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 8.84, NNZs: 44, Bias: -22.948904, T: 43520, Avg. loss: 9.023189\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 8.83, NNZs: 44, Bias: -22.979528, T: 44160, Avg. loss: 6.340707\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 8.79, NNZs: 44, Bias: -23.009289, T: 44800, Avg. loss: 7.420992\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 8.77, NNZs: 44, Bias: -23.043158, T: 45440, Avg. loss: 6.921390\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 8.71, NNZs: 44, Bias: -23.073129, T: 46080, Avg. loss: 7.010272\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 8.69, NNZs: 44, Bias: -23.106556, T: 46720, Avg. loss: 6.390169\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 8.68, NNZs: 44, Bias: -23.137707, T: 47360, Avg. loss: 6.870737\n",
      "Total training time: 0.03 seconds.\n",
      "Convergence after 74 epochs took 0.03 seconds\n",
      "--- training time 0.03374886512756348 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 60.99, NNZs: 42, Bias: -10.453885, T: 640, Avg. loss: 1552.509515\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 35.66, NNZs: 43, Bias: -12.783554, T: 1280, Avg. loss: 389.856725\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24.73, NNZs: 43, Bias: -14.062543, T: 1920, Avg. loss: 236.101649\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 20.01, NNZs: 44, Bias: -14.948544, T: 2560, Avg. loss: 187.732636\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 18.39, NNZs: 44, Bias: -15.671130, T: 3200, Avg. loss: 136.399263\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.70, NNZs: 44, Bias: -16.116936, T: 3840, Avg. loss: 111.364907\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 15.98, NNZs: 44, Bias: -16.589929, T: 4480, Avg. loss: 97.613050\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 14.31, NNZs: 44, Bias: -16.987956, T: 5120, Avg. loss: 74.871437\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 15.61, NNZs: 44, Bias: -17.388014, T: 5760, Avg. loss: 67.966306\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 13.92, NNZs: 44, Bias: -17.682240, T: 6400, Avg. loss: 61.636073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 11.86, NNZs: 44, Bias: -17.950590, T: 7040, Avg. loss: 55.904815\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 12.77, NNZs: 44, Bias: -18.208976, T: 7680, Avg. loss: 46.708359\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 11.33, NNZs: 44, Bias: -18.482606, T: 8320, Avg. loss: 45.033947\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 11.24, NNZs: 44, Bias: -18.677592, T: 8960, Avg. loss: 44.011195\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 11.42, NNZs: 44, Bias: -18.902786, T: 9600, Avg. loss: 43.701096\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 11.15, NNZs: 44, Bias: -19.059339, T: 10240, Avg. loss: 36.234746\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 11.28, NNZs: 44, Bias: -19.274144, T: 10880, Avg. loss: 33.412584\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 11.10, NNZs: 44, Bias: -19.442793, T: 11520, Avg. loss: 33.555258\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 10.71, NNZs: 44, Bias: -19.610984, T: 12160, Avg. loss: 34.817090\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 10.65, NNZs: 44, Bias: -19.756785, T: 12800, Avg. loss: 33.258951\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 11.12, NNZs: 44, Bias: -19.904638, T: 13440, Avg. loss: 30.816617\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 10.41, NNZs: 44, Bias: -20.032428, T: 14080, Avg. loss: 25.012433\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 10.57, NNZs: 44, Bias: -20.137965, T: 14720, Avg. loss: 28.452017\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 10.37, NNZs: 44, Bias: -20.251578, T: 15360, Avg. loss: 21.674290\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 10.47, NNZs: 44, Bias: -20.372988, T: 16000, Avg. loss: 22.736932\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 10.00, NNZs: 44, Bias: -20.472535, T: 16640, Avg. loss: 22.318439\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 10.02, NNZs: 44, Bias: -20.558950, T: 17280, Avg. loss: 20.445041\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 9.96, NNZs: 44, Bias: -20.664347, T: 17920, Avg. loss: 19.539886\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 9.83, NNZs: 44, Bias: -20.762185, T: 18560, Avg. loss: 19.285078\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 10.04, NNZs: 44, Bias: -20.861298, T: 19200, Avg. loss: 18.476698\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 10.05, NNZs: 44, Bias: -20.937798, T: 19840, Avg. loss: 19.100710\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 9.78, NNZs: 44, Bias: -21.031560, T: 20480, Avg. loss: 19.932161\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 9.73, NNZs: 44, Bias: -21.091787, T: 21120, Avg. loss: 16.569235\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 9.61, NNZs: 44, Bias: -21.180585, T: 21760, Avg. loss: 17.286220\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 9.71, NNZs: 44, Bias: -21.269395, T: 22400, Avg. loss: 16.595709\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 9.69, NNZs: 44, Bias: -21.341714, T: 23040, Avg. loss: 15.801840\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 9.62, NNZs: 44, Bias: -21.409972, T: 23680, Avg. loss: 15.241195\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 9.56, NNZs: 44, Bias: -21.492169, T: 24320, Avg. loss: 14.953152\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 9.59, NNZs: 44, Bias: -21.566195, T: 24960, Avg. loss: 13.076712\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 9.55, NNZs: 44, Bias: -21.629678, T: 25600, Avg. loss: 14.345237\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 9.57, NNZs: 44, Bias: -21.692393, T: 26240, Avg. loss: 13.411980\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 9.47, NNZs: 44, Bias: -21.744887, T: 26880, Avg. loss: 12.224874\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 9.46, NNZs: 44, Bias: -21.804454, T: 27520, Avg. loss: 12.965197\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 9.36, NNZs: 44, Bias: -21.862684, T: 28160, Avg. loss: 13.809267\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 9.37, NNZs: 44, Bias: -21.925840, T: 28800, Avg. loss: 11.215663\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 9.29, NNZs: 44, Bias: -21.977134, T: 29440, Avg. loss: 10.919410\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 9.44, NNZs: 44, Bias: -22.046628, T: 30080, Avg. loss: 11.670287\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 9.33, NNZs: 44, Bias: -22.098766, T: 30720, Avg. loss: 10.678681\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 9.37, NNZs: 44, Bias: -22.149601, T: 31360, Avg. loss: 11.416260\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 9.30, NNZs: 44, Bias: -22.196523, T: 32000, Avg. loss: 11.358393\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 9.26, NNZs: 44, Bias: -22.242260, T: 32640, Avg. loss: 9.731031\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 9.12, NNZs: 44, Bias: -22.280656, T: 33280, Avg. loss: 9.006451\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 9.22, NNZs: 44, Bias: -22.328328, T: 33920, Avg. loss: 9.207657\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 9.12, NNZs: 44, Bias: -22.374595, T: 34560, Avg. loss: 9.882925\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 9.09, NNZs: 44, Bias: -22.421797, T: 35200, Avg. loss: 9.979394\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 9.11, NNZs: 44, Bias: -22.466248, T: 35840, Avg. loss: 8.893490\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 9.06, NNZs: 44, Bias: -22.513793, T: 36480, Avg. loss: 8.991318\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 9.03, NNZs: 44, Bias: -22.553100, T: 37120, Avg. loss: 8.224942\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 9.07, NNZs: 44, Bias: -22.589988, T: 37760, Avg. loss: 8.861412\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 9.01, NNZs: 44, Bias: -22.640601, T: 38400, Avg. loss: 8.698771\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 9.01, NNZs: 44, Bias: -22.685427, T: 39040, Avg. loss: 8.509588\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 8.98, NNZs: 44, Bias: -22.722693, T: 39680, Avg. loss: 7.738338\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 8.93, NNZs: 44, Bias: -22.760115, T: 40320, Avg. loss: 8.054029\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 8.93, NNZs: 44, Bias: -22.797019, T: 40960, Avg. loss: 8.500504\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 8.93, NNZs: 44, Bias: -22.838322, T: 41600, Avg. loss: 6.743084\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 8.90, NNZs: 44, Bias: -22.869848, T: 42240, Avg. loss: 7.161529\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 8.83, NNZs: 44, Bias: -22.908464, T: 42880, Avg. loss: 6.941667\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 8.84, NNZs: 44, Bias: -22.948904, T: 43520, Avg. loss: 9.023189\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 8.83, NNZs: 44, Bias: -22.979528, T: 44160, Avg. loss: 6.340707\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 8.79, NNZs: 44, Bias: -23.009289, T: 44800, Avg. loss: 7.420992\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 8.77, NNZs: 44, Bias: -23.043158, T: 45440, Avg. loss: 6.921390\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 8.71, NNZs: 44, Bias: -23.073129, T: 46080, Avg. loss: 7.010272\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 8.69, NNZs: 44, Bias: -23.106556, T: 46720, Avg. loss: 6.390169\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 8.68, NNZs: 44, Bias: -23.137707, T: 47360, Avg. loss: 6.870737\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 74 epochs took 0.02 seconds\n",
      "--- training time 0.02050471305847168 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.28, NNZs: 44, Bias: -0.013512, T: 640, Avg. loss: 3.020409\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.018760, T: 1280, Avg. loss: 1.296850\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.023565, T: 1920, Avg. loss: 0.963469\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.15, NNZs: 44, Bias: -0.027589, T: 2560, Avg. loss: 0.921900\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.14, NNZs: 44, Bias: -0.031779, T: 3200, Avg. loss: 0.737516\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.034975, T: 3840, Avg. loss: 0.649676\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.038168, T: 4480, Avg. loss: 0.654734\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.041333, T: 5120, Avg. loss: 0.612543\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.044426, T: 5760, Avg. loss: 0.567650\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.047042, T: 6400, Avg. loss: 0.558362\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.19, NNZs: 44, Bias: -0.049740, T: 7040, Avg. loss: 0.546509\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.19, NNZs: 44, Bias: -0.052214, T: 7680, Avg. loss: 0.536491\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.20, NNZs: 44, Bias: -0.054853, T: 8320, Avg. loss: 0.494764\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.20, NNZs: 44, Bias: -0.056945, T: 8960, Avg. loss: 0.522660\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.21, NNZs: 44, Bias: -0.059607, T: 9600, Avg. loss: 0.512106\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.21, NNZs: 44, Bias: -0.061642, T: 10240, Avg. loss: 0.487472\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.22, NNZs: 44, Bias: -0.064052, T: 10880, Avg. loss: 0.448072\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.066284, T: 11520, Avg. loss: 0.466046\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.068396, T: 12160, Avg. loss: 0.460946\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.070376, T: 12800, Avg. loss: 0.473061\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.24, NNZs: 44, Bias: -0.072256, T: 13440, Avg. loss: 0.466358\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.24, NNZs: 44, Bias: -0.074107, T: 14080, Avg. loss: 0.420802\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.25, NNZs: 44, Bias: -0.075874, T: 14720, Avg. loss: 0.437950\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.077713, T: 15360, Avg. loss: 0.414708\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.079615, T: 16000, Avg. loss: 0.419000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.081175, T: 16640, Avg. loss: 0.416462\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.27, NNZs: 44, Bias: -0.082705, T: 17280, Avg. loss: 0.399610\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.27, NNZs: 44, Bias: -0.084400, T: 17920, Avg. loss: 0.406214\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.28, NNZs: 44, Bias: -0.086092, T: 18560, Avg. loss: 0.404670\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.087828, T: 19200, Avg. loss: 0.393779\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.089294, T: 19840, Avg. loss: 0.408178\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.090851, T: 20480, Avg. loss: 0.415089\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.092223, T: 21120, Avg. loss: 0.385259\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.30, NNZs: 44, Bias: -0.093777, T: 21760, Avg. loss: 0.389855\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.30, NNZs: 44, Bias: -0.095357, T: 22400, Avg. loss: 0.395306\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.31, NNZs: 44, Bias: -0.096812, T: 23040, Avg. loss: 0.398555\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.31, NNZs: 44, Bias: -0.098326, T: 23680, Avg. loss: 0.403534\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.099797, T: 24320, Avg. loss: 0.395906\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 38 epochs took 0.01 seconds\n",
      "--- training time 0.012681961059570312 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.28, NNZs: 44, Bias: -0.013512, T: 640, Avg. loss: 3.020409\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.018760, T: 1280, Avg. loss: 1.296850\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.023565, T: 1920, Avg. loss: 0.963469\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.15, NNZs: 44, Bias: -0.027589, T: 2560, Avg. loss: 0.921900\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.14, NNZs: 44, Bias: -0.031779, T: 3200, Avg. loss: 0.737516\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.034975, T: 3840, Avg. loss: 0.649676\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.038168, T: 4480, Avg. loss: 0.654734\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.041333, T: 5120, Avg. loss: 0.612543\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.044426, T: 5760, Avg. loss: 0.567650\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.047042, T: 6400, Avg. loss: 0.558362\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.19, NNZs: 44, Bias: -0.049740, T: 7040, Avg. loss: 0.546509\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.19, NNZs: 44, Bias: -0.052214, T: 7680, Avg. loss: 0.536491\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.20, NNZs: 44, Bias: -0.054853, T: 8320, Avg. loss: 0.494764\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.20, NNZs: 44, Bias: -0.056945, T: 8960, Avg. loss: 0.522660\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.21, NNZs: 44, Bias: -0.059607, T: 9600, Avg. loss: 0.512106\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.21, NNZs: 44, Bias: -0.061642, T: 10240, Avg. loss: 0.487472\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.22, NNZs: 44, Bias: -0.064052, T: 10880, Avg. loss: 0.448072\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.066284, T: 11520, Avg. loss: 0.466046\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.068396, T: 12160, Avg. loss: 0.460946\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.070376, T: 12800, Avg. loss: 0.473061\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.24, NNZs: 44, Bias: -0.072256, T: 13440, Avg. loss: 0.466358\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.24, NNZs: 44, Bias: -0.074107, T: 14080, Avg. loss: 0.420802\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.25, NNZs: 44, Bias: -0.075874, T: 14720, Avg. loss: 0.437950\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.077713, T: 15360, Avg. loss: 0.414708\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.079615, T: 16000, Avg. loss: 0.419000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.081175, T: 16640, Avg. loss: 0.416462\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.27, NNZs: 44, Bias: -0.082705, T: 17280, Avg. loss: 0.399610\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.27, NNZs: 44, Bias: -0.084400, T: 17920, Avg. loss: 0.406214\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.28, NNZs: 44, Bias: -0.086092, T: 18560, Avg. loss: 0.404670\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.087828, T: 19200, Avg. loss: 0.393779\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.089294, T: 19840, Avg. loss: 0.408178\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.090851, T: 20480, Avg. loss: 0.415089\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.092223, T: 21120, Avg. loss: 0.385259\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.30, NNZs: 44, Bias: -0.093777, T: 21760, Avg. loss: 0.389855\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.30, NNZs: 44, Bias: -0.095357, T: 22400, Avg. loss: 0.395306\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.31, NNZs: 44, Bias: -0.096812, T: 23040, Avg. loss: 0.398555\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.31, NNZs: 44, Bias: -0.098326, T: 23680, Avg. loss: 0.403534\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.099797, T: 24320, Avg. loss: 0.395906\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 38 epochs took 0.04 seconds\n",
      "--- training time 0.04838895797729492 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 0.28, NNZs: 44, Bias: -0.013512, T: 640, Avg. loss: 3.020409\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.018760, T: 1280, Avg. loss: 1.296850\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.023565, T: 1920, Avg. loss: 0.963469\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.15, NNZs: 44, Bias: -0.027589, T: 2560, Avg. loss: 0.921900\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.14, NNZs: 44, Bias: -0.031779, T: 3200, Avg. loss: 0.737516\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.034975, T: 3840, Avg. loss: 0.649676\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.038168, T: 4480, Avg. loss: 0.654734\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.16, NNZs: 44, Bias: -0.041333, T: 5120, Avg. loss: 0.612543\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.044426, T: 5760, Avg. loss: 0.567650\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.18, NNZs: 44, Bias: -0.047042, T: 6400, Avg. loss: 0.558362\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.19, NNZs: 44, Bias: -0.049740, T: 7040, Avg. loss: 0.546509\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.19, NNZs: 44, Bias: -0.052214, T: 7680, Avg. loss: 0.536491\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.20, NNZs: 44, Bias: -0.054853, T: 8320, Avg. loss: 0.494764\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.20, NNZs: 44, Bias: -0.056945, T: 8960, Avg. loss: 0.522660\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.21, NNZs: 44, Bias: -0.059607, T: 9600, Avg. loss: 0.512106\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.21, NNZs: 44, Bias: -0.061642, T: 10240, Avg. loss: 0.487472\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.22, NNZs: 44, Bias: -0.064052, T: 10880, Avg. loss: 0.448072\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.066284, T: 11520, Avg. loss: 0.466046\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.068396, T: 12160, Avg. loss: 0.460946\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.23, NNZs: 44, Bias: -0.070376, T: 12800, Avg. loss: 0.473061\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.24, NNZs: 44, Bias: -0.072256, T: 13440, Avg. loss: 0.466358\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.24, NNZs: 44, Bias: -0.074107, T: 14080, Avg. loss: 0.420802\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.25, NNZs: 44, Bias: -0.075874, T: 14720, Avg. loss: 0.437950\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.077713, T: 15360, Avg. loss: 0.414708\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.079615, T: 16000, Avg. loss: 0.419000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.26, NNZs: 44, Bias: -0.081175, T: 16640, Avg. loss: 0.416462\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.27, NNZs: 44, Bias: -0.082705, T: 17280, Avg. loss: 0.399610\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.27, NNZs: 44, Bias: -0.084400, T: 17920, Avg. loss: 0.406214\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.28, NNZs: 44, Bias: -0.086092, T: 18560, Avg. loss: 0.404670\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.087828, T: 19200, Avg. loss: 0.393779\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.089294, T: 19840, Avg. loss: 0.408178\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.090851, T: 20480, Avg. loss: 0.415089\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.29, NNZs: 44, Bias: -0.092223, T: 21120, Avg. loss: 0.385259\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.30, NNZs: 44, Bias: -0.093777, T: 21760, Avg. loss: 0.389855\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.30, NNZs: 44, Bias: -0.095357, T: 22400, Avg. loss: 0.395306\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.31, NNZs: 44, Bias: -0.096812, T: 23040, Avg. loss: 0.398555\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.31, NNZs: 44, Bias: -0.098326, T: 23680, Avg. loss: 0.403534\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.32, NNZs: 44, Bias: -0.099797, T: 24320, Avg. loss: 0.395906\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 38 epochs took 0.01 seconds\n",
      "--- training time 0.013960838317871094 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 3.92, NNZs: 44, Bias: -0.229017, T: 640, Avg. loss: 39.588520\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.22, NNZs: 44, Bias: -0.412678, T: 1280, Avg. loss: 36.358448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.77, NNZs: 44, Bias: -0.608724, T: 1920, Avg. loss: 37.326056\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.16, NNZs: 44, Bias: -0.820996, T: 2560, Avg. loss: 41.772040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.046754, T: 3200, Avg. loss: 40.525607\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.70, NNZs: 44, Bias: -1.233228, T: 3840, Avg. loss: 39.758304\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 6.79, NNZs: 44, Bias: -1.422213, T: 4480, Avg. loss: 39.742680\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 4.53, NNZs: 44, Bias: -1.450692, T: 5120, Avg. loss: 16.560021\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 4.10, NNZs: 44, Bias: -1.488961, T: 5760, Avg. loss: 9.079159\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 4.12, NNZs: 44, Bias: -1.526367, T: 6400, Avg. loss: 7.795266\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 4.13, NNZs: 44, Bias: -1.563871, T: 7040, Avg. loss: 7.278739\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 4.18, NNZs: 44, Bias: -1.597494, T: 7680, Avg. loss: 7.476793\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 4.20, NNZs: 44, Bias: -1.635171, T: 8320, Avg. loss: 6.880366\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 4.23, NNZs: 44, Bias: -1.670875, T: 8960, Avg. loss: 8.182257\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 4.29, NNZs: 44, Bias: -1.708758, T: 9600, Avg. loss: 7.790961\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 4.42, NNZs: 44, Bias: -1.745993, T: 10240, Avg. loss: 6.813259\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 4.53, NNZs: 44, Bias: -1.787712, T: 10880, Avg. loss: 6.377116\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 4.54, NNZs: 44, Bias: -1.826082, T: 11520, Avg. loss: 7.133107\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 4.61, NNZs: 44, Bias: -1.865045, T: 12160, Avg. loss: 7.854998\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 4.62, NNZs: 44, Bias: -1.900519, T: 12800, Avg. loss: 8.339434\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 4.69, NNZs: 44, Bias: -1.938469, T: 13440, Avg. loss: 7.971242\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 4.70, NNZs: 44, Bias: -1.971390, T: 14080, Avg. loss: 6.846766\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.975878, T: 14720, Avg. loss: 1.909502\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 4.65, NNZs: 44, Bias: -1.981030, T: 15360, Avg. loss: 1.337327\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 4.64, NNZs: 44, Bias: -1.986973, T: 16000, Avg. loss: 1.095216\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 4.64, NNZs: 44, Bias: -1.991376, T: 16640, Avg. loss: 1.240920\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 4.63, NNZs: 44, Bias: -1.995282, T: 17280, Avg. loss: 1.152731\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.000016, T: 17920, Avg. loss: 1.129366\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.005264, T: 18560, Avg. loss: 1.114322\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.010318, T: 19200, Avg. loss: 1.112498\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 4.62, NNZs: 44, Bias: -2.010732, T: 19840, Avg. loss: 0.529010\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 4.62, NNZs: 44, Bias: -2.011248, T: 20480, Avg. loss: 0.383808\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.011636, T: 21120, Avg. loss: 0.347171\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.012246, T: 21760, Avg. loss: 0.332399\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.012706, T: 22400, Avg. loss: 0.351599\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.013156, T: 23040, Avg. loss: 0.337051\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.013751, T: 23680, Avg. loss: 0.323753\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.014291, T: 24320, Avg. loss: 0.316370\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.014850, T: 24960, Avg. loss: 0.306305\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.015305, T: 25600, Avg. loss: 0.349897\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.015810, T: 26240, Avg. loss: 0.322652\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.016303, T: 26880, Avg. loss: 0.284620\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.016802, T: 27520, Avg. loss: 0.341514\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.017296, T: 28160, Avg. loss: 0.334507\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.017880, T: 28800, Avg. loss: 0.307931\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.018483, T: 29440, Avg. loss: 0.334228\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019125, T: 30080, Avg. loss: 0.296572\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019163, T: 30720, Avg. loss: 0.224531\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019239, T: 31360, Avg. loss: 0.215501\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019339, T: 32000, Avg. loss: 0.227935\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019387, T: 32640, Avg. loss: 0.213606\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019489, T: 33280, Avg. loss: 0.218986\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019590, T: 33920, Avg. loss: 0.228519\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019696, T: 34560, Avg. loss: 0.219427\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019733, T: 35200, Avg. loss: 0.221081\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019877, T: 35840, Avg. loss: 0.221838\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019869, T: 36480, Avg. loss: 0.214944\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019888, T: 37120, Avg. loss: 0.209974\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019906, T: 37760, Avg. loss: 0.209764\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019922, T: 38400, Avg. loss: 0.207634\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019936, T: 39040, Avg. loss: 0.209592\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019947, T: 39680, Avg. loss: 0.208848\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019974, T: 40320, Avg. loss: 0.210157\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019986, T: 40960, Avg. loss: 0.208959\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020005, T: 41600, Avg. loss: 0.209884\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020008, T: 42240, Avg. loss: 0.205329\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020012, T: 42880, Avg. loss: 0.205593\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020015, T: 43520, Avg. loss: 0.205441\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020019, T: 44160, Avg. loss: 0.205546\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020022, T: 44800, Avg. loss: 0.205484\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020026, T: 45440, Avg. loss: 0.205467\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 71 epochs took 0.02 seconds\n",
      "--- training time 0.0230410099029541 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 3.92, NNZs: 44, Bias: -0.229017, T: 640, Avg. loss: 39.588520\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.22, NNZs: 44, Bias: -0.412678, T: 1280, Avg. loss: 36.358448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.77, NNZs: 44, Bias: -0.608724, T: 1920, Avg. loss: 37.326056\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.16, NNZs: 44, Bias: -0.820996, T: 2560, Avg. loss: 41.772040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.046754, T: 3200, Avg. loss: 40.525607\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.70, NNZs: 44, Bias: -1.233228, T: 3840, Avg. loss: 39.758304\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 6.79, NNZs: 44, Bias: -1.422213, T: 4480, Avg. loss: 39.742680\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 4.53, NNZs: 44, Bias: -1.450692, T: 5120, Avg. loss: 16.560021\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 4.10, NNZs: 44, Bias: -1.488961, T: 5760, Avg. loss: 9.079159\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 4.12, NNZs: 44, Bias: -1.526367, T: 6400, Avg. loss: 7.795266\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 4.13, NNZs: 44, Bias: -1.563871, T: 7040, Avg. loss: 7.278739\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 4.18, NNZs: 44, Bias: -1.597494, T: 7680, Avg. loss: 7.476793\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 4.20, NNZs: 44, Bias: -1.635171, T: 8320, Avg. loss: 6.880366\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 4.23, NNZs: 44, Bias: -1.670875, T: 8960, Avg. loss: 8.182257\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 4.29, NNZs: 44, Bias: -1.708758, T: 9600, Avg. loss: 7.790961\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 4.42, NNZs: 44, Bias: -1.745993, T: 10240, Avg. loss: 6.813259\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 4.53, NNZs: 44, Bias: -1.787712, T: 10880, Avg. loss: 6.377116\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 4.54, NNZs: 44, Bias: -1.826082, T: 11520, Avg. loss: 7.133107\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 4.61, NNZs: 44, Bias: -1.865045, T: 12160, Avg. loss: 7.854998\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 4.62, NNZs: 44, Bias: -1.900519, T: 12800, Avg. loss: 8.339434\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 4.69, NNZs: 44, Bias: -1.938469, T: 13440, Avg. loss: 7.971242\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 4.70, NNZs: 44, Bias: -1.971390, T: 14080, Avg. loss: 6.846766\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.975878, T: 14720, Avg. loss: 1.909502\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 4.65, NNZs: 44, Bias: -1.981030, T: 15360, Avg. loss: 1.337327\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 4.64, NNZs: 44, Bias: -1.986973, T: 16000, Avg. loss: 1.095216\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 4.64, NNZs: 44, Bias: -1.991376, T: 16640, Avg. loss: 1.240920\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 4.63, NNZs: 44, Bias: -1.995282, T: 17280, Avg. loss: 1.152731\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.000016, T: 17920, Avg. loss: 1.129366\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.005264, T: 18560, Avg. loss: 1.114322\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.010318, T: 19200, Avg. loss: 1.112498\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 4.62, NNZs: 44, Bias: -2.010732, T: 19840, Avg. loss: 0.529010\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 4.62, NNZs: 44, Bias: -2.011248, T: 20480, Avg. loss: 0.383808\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.011636, T: 21120, Avg. loss: 0.347171\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.012246, T: 21760, Avg. loss: 0.332399\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.012706, T: 22400, Avg. loss: 0.351599\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.013156, T: 23040, Avg. loss: 0.337051\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.013751, T: 23680, Avg. loss: 0.323753\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.014291, T: 24320, Avg. loss: 0.316370\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.014850, T: 24960, Avg. loss: 0.306305\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.015305, T: 25600, Avg. loss: 0.349897\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.015810, T: 26240, Avg. loss: 0.322652\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.016303, T: 26880, Avg. loss: 0.284620\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.016802, T: 27520, Avg. loss: 0.341514\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.017296, T: 28160, Avg. loss: 0.334507\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.017880, T: 28800, Avg. loss: 0.307931\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.018483, T: 29440, Avg. loss: 0.334228\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019125, T: 30080, Avg. loss: 0.296572\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019163, T: 30720, Avg. loss: 0.224531\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019239, T: 31360, Avg. loss: 0.215501\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019339, T: 32000, Avg. loss: 0.227935\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019387, T: 32640, Avg. loss: 0.213606\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019489, T: 33280, Avg. loss: 0.218986\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019590, T: 33920, Avg. loss: 0.228519\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019696, T: 34560, Avg. loss: 0.219427\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019733, T: 35200, Avg. loss: 0.221081\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019877, T: 35840, Avg. loss: 0.221838\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019869, T: 36480, Avg. loss: 0.214944\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019888, T: 37120, Avg. loss: 0.209974\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019906, T: 37760, Avg. loss: 0.209764\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019922, T: 38400, Avg. loss: 0.207634\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019936, T: 39040, Avg. loss: 0.209592\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019947, T: 39680, Avg. loss: 0.208848\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019974, T: 40320, Avg. loss: 0.210157\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019986, T: 40960, Avg. loss: 0.208959\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020005, T: 41600, Avg. loss: 0.209884\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020008, T: 42240, Avg. loss: 0.205329\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020012, T: 42880, Avg. loss: 0.205593\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020015, T: 43520, Avg. loss: 0.205441\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020019, T: 44160, Avg. loss: 0.205546\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020022, T: 44800, Avg. loss: 0.205484\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020026, T: 45440, Avg. loss: 0.205467\n",
      "Total training time: 0.10 seconds.\n",
      "Convergence after 71 epochs took 0.10 seconds\n",
      "--- training time 0.10201597213745117 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 3.92, NNZs: 44, Bias: -0.229017, T: 640, Avg. loss: 39.588520\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.22, NNZs: 44, Bias: -0.412678, T: 1280, Avg. loss: 36.358448\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.77, NNZs: 44, Bias: -0.608724, T: 1920, Avg. loss: 37.326056\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.16, NNZs: 44, Bias: -0.820996, T: 2560, Avg. loss: 41.772040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.046754, T: 3200, Avg. loss: 40.525607\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.70, NNZs: 44, Bias: -1.233228, T: 3840, Avg. loss: 39.758304\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 6.79, NNZs: 44, Bias: -1.422213, T: 4480, Avg. loss: 39.742680\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 4.53, NNZs: 44, Bias: -1.450692, T: 5120, Avg. loss: 16.560021\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 4.10, NNZs: 44, Bias: -1.488961, T: 5760, Avg. loss: 9.079159\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 4.12, NNZs: 44, Bias: -1.526367, T: 6400, Avg. loss: 7.795266\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 4.13, NNZs: 44, Bias: -1.563871, T: 7040, Avg. loss: 7.278739\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 4.18, NNZs: 44, Bias: -1.597494, T: 7680, Avg. loss: 7.476793\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 4.20, NNZs: 44, Bias: -1.635171, T: 8320, Avg. loss: 6.880366\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 4.23, NNZs: 44, Bias: -1.670875, T: 8960, Avg. loss: 8.182257\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 4.29, NNZs: 44, Bias: -1.708758, T: 9600, Avg. loss: 7.790961\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 4.42, NNZs: 44, Bias: -1.745993, T: 10240, Avg. loss: 6.813259\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 4.53, NNZs: 44, Bias: -1.787712, T: 10880, Avg. loss: 6.377116\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 4.54, NNZs: 44, Bias: -1.826082, T: 11520, Avg. loss: 7.133107\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 4.61, NNZs: 44, Bias: -1.865045, T: 12160, Avg. loss: 7.854998\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 4.62, NNZs: 44, Bias: -1.900519, T: 12800, Avg. loss: 8.339434\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 4.69, NNZs: 44, Bias: -1.938469, T: 13440, Avg. loss: 7.971242\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 4.70, NNZs: 44, Bias: -1.971390, T: 14080, Avg. loss: 6.846766\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 4.66, NNZs: 44, Bias: -1.975878, T: 14720, Avg. loss: 1.909502\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 4.65, NNZs: 44, Bias: -1.981030, T: 15360, Avg. loss: 1.337327\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 4.64, NNZs: 44, Bias: -1.986973, T: 16000, Avg. loss: 1.095216\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 4.64, NNZs: 44, Bias: -1.991376, T: 16640, Avg. loss: 1.240920\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 4.63, NNZs: 44, Bias: -1.995282, T: 17280, Avg. loss: 1.152731\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.000016, T: 17920, Avg. loss: 1.129366\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.005264, T: 18560, Avg. loss: 1.114322\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 4.63, NNZs: 44, Bias: -2.010318, T: 19200, Avg. loss: 1.112498\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 4.62, NNZs: 44, Bias: -2.010732, T: 19840, Avg. loss: 0.529010\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 4.62, NNZs: 44, Bias: -2.011248, T: 20480, Avg. loss: 0.383808\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.011636, T: 21120, Avg. loss: 0.347171\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.012246, T: 21760, Avg. loss: 0.332399\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 4.61, NNZs: 44, Bias: -2.012706, T: 22400, Avg. loss: 0.351599\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.013156, T: 23040, Avg. loss: 0.337051\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.013751, T: 23680, Avg. loss: 0.323753\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.014291, T: 24320, Avg. loss: 0.316370\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 4.60, NNZs: 44, Bias: -2.014850, T: 24960, Avg. loss: 0.306305\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.015305, T: 25600, Avg. loss: 0.349897\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.015810, T: 26240, Avg. loss: 0.322652\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 4.59, NNZs: 44, Bias: -2.016303, T: 26880, Avg. loss: 0.284620\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.016802, T: 27520, Avg. loss: 0.341514\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.017296, T: 28160, Avg. loss: 0.334507\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 4.58, NNZs: 44, Bias: -2.017880, T: 28800, Avg. loss: 0.307931\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.018483, T: 29440, Avg. loss: 0.334228\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019125, T: 30080, Avg. loss: 0.296572\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019163, T: 30720, Avg. loss: 0.224531\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019239, T: 31360, Avg. loss: 0.215501\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019339, T: 32000, Avg. loss: 0.227935\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019387, T: 32640, Avg. loss: 0.213606\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019489, T: 33280, Avg. loss: 0.218986\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019590, T: 33920, Avg. loss: 0.228519\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019696, T: 34560, Avg. loss: 0.219427\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019733, T: 35200, Avg. loss: 0.221081\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019877, T: 35840, Avg. loss: 0.221838\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019869, T: 36480, Avg. loss: 0.214944\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019888, T: 37120, Avg. loss: 0.209974\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 4.57, NNZs: 44, Bias: -2.019906, T: 37760, Avg. loss: 0.209764\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019922, T: 38400, Avg. loss: 0.207634\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019936, T: 39040, Avg. loss: 0.209592\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019947, T: 39680, Avg. loss: 0.208848\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019974, T: 40320, Avg. loss: 0.210157\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.019986, T: 40960, Avg. loss: 0.208959\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020005, T: 41600, Avg. loss: 0.209884\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020008, T: 42240, Avg. loss: 0.205329\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020012, T: 42880, Avg. loss: 0.205593\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020015, T: 43520, Avg. loss: 0.205441\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020019, T: 44160, Avg. loss: 0.205546\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020022, T: 44800, Avg. loss: 0.205484\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 4.56, NNZs: 44, Bias: -2.020026, T: 45440, Avg. loss: 0.205467\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 71 epochs took 0.04 seconds\n",
      "--- training time 0.04170393943786621 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 10.91, NNZs: 43, Bias: -2.550009, T: 640, Avg. loss: 402.389039\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.71, NNZs: 44, Bias: -5.050009, T: 1280, Avg. loss: 323.294791\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.46, NNZs: 44, Bias: -7.512515, T: 1920, Avg. loss: 359.311537\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.05, NNZs: 44, Bias: -10.201947, T: 2560, Avg. loss: 399.918189\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.69, NNZs: 44, Bias: -12.720222, T: 3200, Avg. loss: 361.718888\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.91, NNZs: 44, Bias: -14.880795, T: 3840, Avg. loss: 377.351976\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 19.10, NNZs: 44, Bias: -17.180424, T: 4480, Avg. loss: 376.820507\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.008644819259643555 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 10.91, NNZs: 43, Bias: -2.550009, T: 640, Avg. loss: 402.389039\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.71, NNZs: 44, Bias: -5.050009, T: 1280, Avg. loss: 323.294791\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.46, NNZs: 44, Bias: -7.512515, T: 1920, Avg. loss: 359.311537\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.05, NNZs: 44, Bias: -10.201947, T: 2560, Avg. loss: 399.918189\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.69, NNZs: 44, Bias: -12.720222, T: 3200, Avg. loss: 361.718888\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.91, NNZs: 44, Bias: -14.880795, T: 3840, Avg. loss: 377.351976\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 19.10, NNZs: 44, Bias: -17.180424, T: 4480, Avg. loss: 376.820507\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.012438058853149414 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 10.91, NNZs: 43, Bias: -2.550009, T: 640, Avg. loss: 402.389039\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.71, NNZs: 44, Bias: -5.050009, T: 1280, Avg. loss: 323.294791\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.46, NNZs: 44, Bias: -7.512515, T: 1920, Avg. loss: 359.311537\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.05, NNZs: 44, Bias: -10.201947, T: 2560, Avg. loss: 399.918189\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.69, NNZs: 44, Bias: -12.720222, T: 3200, Avg. loss: 361.718888\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.91, NNZs: 44, Bias: -14.880795, T: 3840, Avg. loss: 377.351976\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 19.10, NNZs: 44, Bias: -17.180424, T: 4480, Avg. loss: 376.820507\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "--- training time 0.008802175521850586 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 6.35, NNZs: 44, Bias: -1.994673, T: 640, Avg. loss: 189.614785\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.05, NNZs: 44, Bias: -2.217508, T: 1280, Avg. loss: 40.077763\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3.12, NNZs: 44, Bias: -2.340662, T: 1920, Avg. loss: 23.614151\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.03, NNZs: 44, Bias: -2.422736, T: 2560, Avg. loss: 19.441969\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.59, NNZs: 44, Bias: -2.496541, T: 3200, Avg. loss: 13.700437\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.98, NNZs: 44, Bias: -2.541821, T: 3840, Avg. loss: 10.579633\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.45, NNZs: 44, Bias: -2.583415, T: 4480, Avg. loss: 9.411084\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.40, NNZs: 44, Bias: -2.630032, T: 5120, Avg. loss: 8.216800\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.50, NNZs: 44, Bias: -2.663326, T: 5760, Avg. loss: 7.242535\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.36, NNZs: 44, Bias: -2.692023, T: 6400, Avg. loss: 5.980278\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.29, NNZs: 44, Bias: -2.721187, T: 7040, Avg. loss: 5.348994\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.22, NNZs: 44, Bias: -2.743549, T: 7680, Avg. loss: 4.803177\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1.12, NNZs: 44, Bias: -2.768479, T: 8320, Avg. loss: 4.859873\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1.13, NNZs: 44, Bias: -2.788927, T: 8960, Avg. loss: 4.464438\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1.08, NNZs: 44, Bias: -2.811251, T: 9600, Avg. loss: 4.280645\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1.15, NNZs: 44, Bias: -2.830171, T: 10240, Avg. loss: 3.587939\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1.08, NNZs: 44, Bias: -2.848824, T: 10880, Avg. loss: 2.990107\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1.10, NNZs: 44, Bias: -2.867765, T: 11520, Avg. loss: 3.350379\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 1.05, NNZs: 44, Bias: -2.884974, T: 12160, Avg. loss: 3.444854\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.04, NNZs: 44, Bias: -2.900045, T: 12800, Avg. loss: 2.998987\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.10, NNZs: 44, Bias: -2.915230, T: 13440, Avg. loss: 2.910877\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 1.03, NNZs: 44, Bias: -2.927017, T: 14080, Avg. loss: 2.422828\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 1.07, NNZs: 44, Bias: -2.937955, T: 14720, Avg. loss: 2.621666\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 1.04, NNZs: 44, Bias: -2.950331, T: 15360, Avg. loss: 2.301741\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 1.05, NNZs: 44, Bias: -2.963537, T: 16000, Avg. loss: 2.276732\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 1.01, NNZs: 44, Bias: -2.972981, T: 16640, Avg. loss: 1.978905\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 1.03, NNZs: 44, Bias: -2.980866, T: 17280, Avg. loss: 2.065030\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.99, NNZs: 44, Bias: -2.991051, T: 17920, Avg. loss: 1.902420\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.00, NNZs: 44, Bias: -3.000799, T: 18560, Avg. loss: 1.688780\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.00, NNZs: 44, Bias: -3.010344, T: 19200, Avg. loss: 1.746155\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1.01, NNZs: 44, Bias: -3.018024, T: 19840, Avg. loss: 1.738377\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.026440, T: 20480, Avg. loss: 1.826953\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.032298, T: 21120, Avg. loss: 1.469212\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.041144, T: 21760, Avg. loss: 1.603329\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.049891, T: 22400, Avg. loss: 1.556712\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.99, NNZs: 44, Bias: -3.057867, T: 23040, Avg. loss: 1.499409\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.065866, T: 23680, Avg. loss: 1.552223\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.073255, T: 24320, Avg. loss: 1.350029\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.079636, T: 24960, Avg. loss: 1.202499\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.96, NNZs: 44, Bias: -3.085880, T: 25600, Avg. loss: 1.325216\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.96, NNZs: 44, Bias: -3.091427, T: 26240, Avg. loss: 1.228914\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.096794, T: 26880, Avg. loss: 1.123186\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.102410, T: 27520, Avg. loss: 1.207042\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.108396, T: 28160, Avg. loss: 1.183111\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.115113, T: 28800, Avg. loss: 1.183820\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.120594, T: 29440, Avg. loss: 1.158029\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.127762, T: 30080, Avg. loss: 1.112647\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.132704, T: 30720, Avg. loss: 0.996212\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.137911, T: 31360, Avg. loss: 0.994590\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.93, NNZs: 44, Bias: -3.142994, T: 32000, Avg. loss: 1.090287\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.93, NNZs: 44, Bias: -3.147777, T: 32640, Avg. loss: 0.860229\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.151914, T: 33280, Avg. loss: 0.912170\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.93, NNZs: 44, Bias: -3.157041, T: 33920, Avg. loss: 0.980728\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.161423, T: 34560, Avg. loss: 0.904690\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.165488, T: 35200, Avg. loss: 0.944352\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.170430, T: 35840, Avg. loss: 0.842694\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.174331, T: 36480, Avg. loss: 0.944322\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.178124, T: 37120, Avg. loss: 0.781941\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.181930, T: 37760, Avg. loss: 0.884373\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.187088, T: 38400, Avg. loss: 0.870619\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.90, NNZs: 44, Bias: -3.190889, T: 39040, Avg. loss: 0.779619\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.90, NNZs: 44, Bias: -3.194808, T: 39680, Avg. loss: 0.654711\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.90, NNZs: 44, Bias: -3.198546, T: 40320, Avg. loss: 0.780250\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.89, NNZs: 44, Bias: -3.201925, T: 40960, Avg. loss: 0.800828\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.89, NNZs: 44, Bias: -3.205871, T: 41600, Avg. loss: 0.675419\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.89, NNZs: 44, Bias: -3.209167, T: 42240, Avg. loss: 0.707917\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.213082, T: 42880, Avg. loss: 0.645659\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.216838, T: 43520, Avg. loss: 0.806701\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.219861, T: 44160, Avg. loss: 0.591332\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.223250, T: 44800, Avg. loss: 0.737523\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.226684, T: 45440, Avg. loss: 0.697447\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.87, NNZs: 44, Bias: -3.229653, T: 46080, Avg. loss: 0.670614\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.87, NNZs: 44, Bias: -3.232981, T: 46720, Avg. loss: 0.653457\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.87, NNZs: 44, Bias: -3.236241, T: 47360, Avg. loss: 0.691059\n",
      "Total training time: 0.06 seconds.\n",
      "Convergence after 74 epochs took 0.06 seconds\n",
      "--- training time 0.06803393363952637 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 6.35, NNZs: 44, Bias: -1.994673, T: 640, Avg. loss: 189.614785\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.05, NNZs: 44, Bias: -2.217508, T: 1280, Avg. loss: 40.077763\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3.12, NNZs: 44, Bias: -2.340662, T: 1920, Avg. loss: 23.614151\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.03, NNZs: 44, Bias: -2.422736, T: 2560, Avg. loss: 19.441969\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.59, NNZs: 44, Bias: -2.496541, T: 3200, Avg. loss: 13.700437\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.98, NNZs: 44, Bias: -2.541821, T: 3840, Avg. loss: 10.579633\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.45, NNZs: 44, Bias: -2.583415, T: 4480, Avg. loss: 9.411084\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.40, NNZs: 44, Bias: -2.630032, T: 5120, Avg. loss: 8.216800\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.50, NNZs: 44, Bias: -2.663326, T: 5760, Avg. loss: 7.242535\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.36, NNZs: 44, Bias: -2.692023, T: 6400, Avg. loss: 5.980278\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.29, NNZs: 44, Bias: -2.721187, T: 7040, Avg. loss: 5.348994\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.22, NNZs: 44, Bias: -2.743549, T: 7680, Avg. loss: 4.803177\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1.12, NNZs: 44, Bias: -2.768479, T: 8320, Avg. loss: 4.859873\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1.13, NNZs: 44, Bias: -2.788927, T: 8960, Avg. loss: 4.464438\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1.08, NNZs: 44, Bias: -2.811251, T: 9600, Avg. loss: 4.280645\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1.15, NNZs: 44, Bias: -2.830171, T: 10240, Avg. loss: 3.587939\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1.08, NNZs: 44, Bias: -2.848824, T: 10880, Avg. loss: 2.990107\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1.10, NNZs: 44, Bias: -2.867765, T: 11520, Avg. loss: 3.350379\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 1.05, NNZs: 44, Bias: -2.884974, T: 12160, Avg. loss: 3.444854\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.04, NNZs: 44, Bias: -2.900045, T: 12800, Avg. loss: 2.998987\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.10, NNZs: 44, Bias: -2.915230, T: 13440, Avg. loss: 2.910877\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 1.03, NNZs: 44, Bias: -2.927017, T: 14080, Avg. loss: 2.422828\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 1.07, NNZs: 44, Bias: -2.937955, T: 14720, Avg. loss: 2.621666\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 1.04, NNZs: 44, Bias: -2.950331, T: 15360, Avg. loss: 2.301741\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 1.05, NNZs: 44, Bias: -2.963537, T: 16000, Avg. loss: 2.276732\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 1.01, NNZs: 44, Bias: -2.972981, T: 16640, Avg. loss: 1.978905\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 1.03, NNZs: 44, Bias: -2.980866, T: 17280, Avg. loss: 2.065030\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.99, NNZs: 44, Bias: -2.991051, T: 17920, Avg. loss: 1.902420\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.00, NNZs: 44, Bias: -3.000799, T: 18560, Avg. loss: 1.688780\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.00, NNZs: 44, Bias: -3.010344, T: 19200, Avg. loss: 1.746155\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1.01, NNZs: 44, Bias: -3.018024, T: 19840, Avg. loss: 1.738377\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.026440, T: 20480, Avg. loss: 1.826953\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.032298, T: 21120, Avg. loss: 1.469212\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.041144, T: 21760, Avg. loss: 1.603329\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.049891, T: 22400, Avg. loss: 1.556712\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.99, NNZs: 44, Bias: -3.057867, T: 23040, Avg. loss: 1.499409\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.065866, T: 23680, Avg. loss: 1.552223\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.073255, T: 24320, Avg. loss: 1.350029\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.079636, T: 24960, Avg. loss: 1.202499\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.96, NNZs: 44, Bias: -3.085880, T: 25600, Avg. loss: 1.325216\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.96, NNZs: 44, Bias: -3.091427, T: 26240, Avg. loss: 1.228914\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.096794, T: 26880, Avg. loss: 1.123186\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.102410, T: 27520, Avg. loss: 1.207042\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.108396, T: 28160, Avg. loss: 1.183111\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.115113, T: 28800, Avg. loss: 1.183820\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.120594, T: 29440, Avg. loss: 1.158029\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.127762, T: 30080, Avg. loss: 1.112647\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.132704, T: 30720, Avg. loss: 0.996212\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.137911, T: 31360, Avg. loss: 0.994590\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.93, NNZs: 44, Bias: -3.142994, T: 32000, Avg. loss: 1.090287\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.93, NNZs: 44, Bias: -3.147777, T: 32640, Avg. loss: 0.860229\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.151914, T: 33280, Avg. loss: 0.912170\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.93, NNZs: 44, Bias: -3.157041, T: 33920, Avg. loss: 0.980728\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.161423, T: 34560, Avg. loss: 0.904690\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.165488, T: 35200, Avg. loss: 0.944352\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.170430, T: 35840, Avg. loss: 0.842694\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.174331, T: 36480, Avg. loss: 0.944322\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.178124, T: 37120, Avg. loss: 0.781941\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.181930, T: 37760, Avg. loss: 0.884373\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.187088, T: 38400, Avg. loss: 0.870619\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.90, NNZs: 44, Bias: -3.190889, T: 39040, Avg. loss: 0.779619\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.90, NNZs: 44, Bias: -3.194808, T: 39680, Avg. loss: 0.654711\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.90, NNZs: 44, Bias: -3.198546, T: 40320, Avg. loss: 0.780250\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.89, NNZs: 44, Bias: -3.201925, T: 40960, Avg. loss: 0.800828\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.89, NNZs: 44, Bias: -3.205871, T: 41600, Avg. loss: 0.675419\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.89, NNZs: 44, Bias: -3.209167, T: 42240, Avg. loss: 0.707917\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.213082, T: 42880, Avg. loss: 0.645659\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.216838, T: 43520, Avg. loss: 0.806701\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.219861, T: 44160, Avg. loss: 0.591332\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.223250, T: 44800, Avg. loss: 0.737523\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.226684, T: 45440, Avg. loss: 0.697447\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.87, NNZs: 44, Bias: -3.229653, T: 46080, Avg. loss: 0.670614\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.87, NNZs: 44, Bias: -3.232981, T: 46720, Avg. loss: 0.653457\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.87, NNZs: 44, Bias: -3.236241, T: 47360, Avg. loss: 0.691059\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 74 epochs took 0.04 seconds\n",
      "--- training time 0.04436683654785156 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 6.35, NNZs: 44, Bias: -1.994673, T: 640, Avg. loss: 189.614785\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.05, NNZs: 44, Bias: -2.217508, T: 1280, Avg. loss: 40.077763\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3.12, NNZs: 44, Bias: -2.340662, T: 1920, Avg. loss: 23.614151\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.03, NNZs: 44, Bias: -2.422736, T: 2560, Avg. loss: 19.441969\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.59, NNZs: 44, Bias: -2.496541, T: 3200, Avg. loss: 13.700437\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.98, NNZs: 44, Bias: -2.541821, T: 3840, Avg. loss: 10.579633\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.45, NNZs: 44, Bias: -2.583415, T: 4480, Avg. loss: 9.411084\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.40, NNZs: 44, Bias: -2.630032, T: 5120, Avg. loss: 8.216800\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.50, NNZs: 44, Bias: -2.663326, T: 5760, Avg. loss: 7.242535\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.36, NNZs: 44, Bias: -2.692023, T: 6400, Avg. loss: 5.980278\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.29, NNZs: 44, Bias: -2.721187, T: 7040, Avg. loss: 5.348994\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.22, NNZs: 44, Bias: -2.743549, T: 7680, Avg. loss: 4.803177\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1.12, NNZs: 44, Bias: -2.768479, T: 8320, Avg. loss: 4.859873\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1.13, NNZs: 44, Bias: -2.788927, T: 8960, Avg. loss: 4.464438\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1.08, NNZs: 44, Bias: -2.811251, T: 9600, Avg. loss: 4.280645\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1.15, NNZs: 44, Bias: -2.830171, T: 10240, Avg. loss: 3.587939\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1.08, NNZs: 44, Bias: -2.848824, T: 10880, Avg. loss: 2.990107\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1.10, NNZs: 44, Bias: -2.867765, T: 11520, Avg. loss: 3.350379\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 1.05, NNZs: 44, Bias: -2.884974, T: 12160, Avg. loss: 3.444854\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.04, NNZs: 44, Bias: -2.900045, T: 12800, Avg. loss: 2.998987\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.10, NNZs: 44, Bias: -2.915230, T: 13440, Avg. loss: 2.910877\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 1.03, NNZs: 44, Bias: -2.927017, T: 14080, Avg. loss: 2.422828\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 1.07, NNZs: 44, Bias: -2.937955, T: 14720, Avg. loss: 2.621666\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 1.04, NNZs: 44, Bias: -2.950331, T: 15360, Avg. loss: 2.301741\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 1.05, NNZs: 44, Bias: -2.963537, T: 16000, Avg. loss: 2.276732\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 1.01, NNZs: 44, Bias: -2.972981, T: 16640, Avg. loss: 1.978905\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 1.03, NNZs: 44, Bias: -2.980866, T: 17280, Avg. loss: 2.065030\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.99, NNZs: 44, Bias: -2.991051, T: 17920, Avg. loss: 1.902420\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.00, NNZs: 44, Bias: -3.000799, T: 18560, Avg. loss: 1.688780\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.00, NNZs: 44, Bias: -3.010344, T: 19200, Avg. loss: 1.746155\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1.01, NNZs: 44, Bias: -3.018024, T: 19840, Avg. loss: 1.738377\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.026440, T: 20480, Avg. loss: 1.826953\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.032298, T: 21120, Avg. loss: 1.469212\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.041144, T: 21760, Avg. loss: 1.603329\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.049891, T: 22400, Avg. loss: 1.556712\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.99, NNZs: 44, Bias: -3.057867, T: 23040, Avg. loss: 1.499409\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.98, NNZs: 44, Bias: -3.065866, T: 23680, Avg. loss: 1.552223\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.073255, T: 24320, Avg. loss: 1.350029\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.97, NNZs: 44, Bias: -3.079636, T: 24960, Avg. loss: 1.202499\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.96, NNZs: 44, Bias: -3.085880, T: 25600, Avg. loss: 1.325216\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.96, NNZs: 44, Bias: -3.091427, T: 26240, Avg. loss: 1.228914\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.096794, T: 26880, Avg. loss: 1.123186\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.102410, T: 27520, Avg. loss: 1.207042\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.108396, T: 28160, Avg. loss: 1.183111\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.115113, T: 28800, Avg. loss: 1.183820\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.120594, T: 29440, Avg. loss: 1.158029\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.95, NNZs: 44, Bias: -3.127762, T: 30080, Avg. loss: 1.112647\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.132704, T: 30720, Avg. loss: 0.996212\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.94, NNZs: 44, Bias: -3.137911, T: 31360, Avg. loss: 0.994590\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.93, NNZs: 44, Bias: -3.142994, T: 32000, Avg. loss: 1.090287\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.93, NNZs: 44, Bias: -3.147777, T: 32640, Avg. loss: 0.860229\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.151914, T: 33280, Avg. loss: 0.912170\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.93, NNZs: 44, Bias: -3.157041, T: 33920, Avg. loss: 0.980728\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.161423, T: 34560, Avg. loss: 0.904690\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.165488, T: 35200, Avg. loss: 0.944352\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.92, NNZs: 44, Bias: -3.170430, T: 35840, Avg. loss: 0.842694\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.174331, T: 36480, Avg. loss: 0.944322\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.178124, T: 37120, Avg. loss: 0.781941\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.181930, T: 37760, Avg. loss: 0.884373\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.91, NNZs: 44, Bias: -3.187088, T: 38400, Avg. loss: 0.870619\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.90, NNZs: 44, Bias: -3.190889, T: 39040, Avg. loss: 0.779619\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.90, NNZs: 44, Bias: -3.194808, T: 39680, Avg. loss: 0.654711\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.90, NNZs: 44, Bias: -3.198546, T: 40320, Avg. loss: 0.780250\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.89, NNZs: 44, Bias: -3.201925, T: 40960, Avg. loss: 0.800828\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.89, NNZs: 44, Bias: -3.205871, T: 41600, Avg. loss: 0.675419\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.89, NNZs: 44, Bias: -3.209167, T: 42240, Avg. loss: 0.707917\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.213082, T: 42880, Avg. loss: 0.645659\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.216838, T: 43520, Avg. loss: 0.806701\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.219861, T: 44160, Avg. loss: 0.591332\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.223250, T: 44800, Avg. loss: 0.737523\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.88, NNZs: 44, Bias: -3.226684, T: 45440, Avg. loss: 0.697447\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.87, NNZs: 44, Bias: -3.229653, T: 46080, Avg. loss: 0.670614\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.87, NNZs: 44, Bias: -3.232981, T: 46720, Avg. loss: 0.653457\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.87, NNZs: 44, Bias: -3.236241, T: 47360, Avg. loss: 0.691059\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 74 epochs took 0.04 seconds\n",
      "--- training time 0.048024892807006836 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 1.81, NNZs: 44, Bias: -0.132429, T: 640, Avg. loss: 30.907784\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.39, NNZs: 44, Bias: -0.188078, T: 1280, Avg. loss: 10.660232\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.25, NNZs: 44, Bias: -0.238202, T: 1920, Avg. loss: 9.212930\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.276557, T: 2560, Avg. loss: 9.238287\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.316699, T: 3200, Avg. loss: 7.258781\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.20, NNZs: 44, Bias: -0.346927, T: 3840, Avg. loss: 6.083062\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.05, NNZs: 44, Bias: -0.377001, T: 4480, Avg. loss: 6.074865\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.405743, T: 5120, Avg. loss: 5.408817\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.05, NNZs: 44, Bias: -0.434407, T: 5760, Avg. loss: 5.172337\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.07, NNZs: 44, Bias: -0.459415, T: 6400, Avg. loss: 4.729603\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.08, NNZs: 44, Bias: -0.484385, T: 7040, Avg. loss: 4.626073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.505227, T: 7680, Avg. loss: 4.504605\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.529476, T: 8320, Avg. loss: 3.886199\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.548966, T: 8960, Avg. loss: 4.488182\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.574013, T: 9600, Avg. loss: 4.301054\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1.06, NNZs: 44, Bias: -0.594354, T: 10240, Avg. loss: 3.785013\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.616599, T: 10880, Avg. loss: 3.399852\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.636243, T: 11520, Avg. loss: 3.280211\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.96, NNZs: 44, Bias: -0.654038, T: 12160, Avg. loss: 3.690596\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.671599, T: 12800, Avg. loss: 3.693993\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.689654, T: 13440, Avg. loss: 3.407431\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.705857, T: 14080, Avg. loss: 2.926440\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.720351, T: 14720, Avg. loss: 3.038130\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.736537, T: 15360, Avg. loss: 3.017863\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.751568, T: 16000, Avg. loss: 2.732331\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.766843, T: 16640, Avg. loss: 2.835467\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.779676, T: 17280, Avg. loss: 2.794700\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.795386, T: 17920, Avg. loss: 2.689158\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.809601, T: 18560, Avg. loss: 2.586526\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.06, NNZs: 44, Bias: -0.827178, T: 19200, Avg. loss: 2.624687\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.839258, T: 19840, Avg. loss: 2.743357\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.852483, T: 20480, Avg. loss: 2.547765\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.862580, T: 21120, Avg. loss: 2.184022\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.875723, T: 21760, Avg. loss: 2.496151\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.890938, T: 22400, Avg. loss: 2.564650\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.904156, T: 23040, Avg. loss: 2.505766\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.917612, T: 23680, Avg. loss: 2.671161\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.930996, T: 24320, Avg. loss: 2.351704\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 38 epochs took 0.01 seconds\n",
      "--- training time 0.010432958602905273 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 1.81, NNZs: 44, Bias: -0.132429, T: 640, Avg. loss: 30.907784\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.39, NNZs: 44, Bias: -0.188078, T: 1280, Avg. loss: 10.660232\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.25, NNZs: 44, Bias: -0.238202, T: 1920, Avg. loss: 9.212930\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.276557, T: 2560, Avg. loss: 9.238287\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.316699, T: 3200, Avg. loss: 7.258781\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.20, NNZs: 44, Bias: -0.346927, T: 3840, Avg. loss: 6.083062\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.05, NNZs: 44, Bias: -0.377001, T: 4480, Avg. loss: 6.074865\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.405743, T: 5120, Avg. loss: 5.408817\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.05, NNZs: 44, Bias: -0.434407, T: 5760, Avg. loss: 5.172337\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.07, NNZs: 44, Bias: -0.459415, T: 6400, Avg. loss: 4.729603\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.08, NNZs: 44, Bias: -0.484385, T: 7040, Avg. loss: 4.626073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.505227, T: 7680, Avg. loss: 4.504605\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.529476, T: 8320, Avg. loss: 3.886199\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.548966, T: 8960, Avg. loss: 4.488182\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.574013, T: 9600, Avg. loss: 4.301054\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1.06, NNZs: 44, Bias: -0.594354, T: 10240, Avg. loss: 3.785013\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.616599, T: 10880, Avg. loss: 3.399852\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.636243, T: 11520, Avg. loss: 3.280211\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.96, NNZs: 44, Bias: -0.654038, T: 12160, Avg. loss: 3.690596\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.671599, T: 12800, Avg. loss: 3.693993\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.689654, T: 13440, Avg. loss: 3.407431\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.705857, T: 14080, Avg. loss: 2.926440\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.720351, T: 14720, Avg. loss: 3.038130\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.736537, T: 15360, Avg. loss: 3.017863\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.751568, T: 16000, Avg. loss: 2.732331\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.766843, T: 16640, Avg. loss: 2.835467\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.779676, T: 17280, Avg. loss: 2.794700\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.795386, T: 17920, Avg. loss: 2.689158\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.809601, T: 18560, Avg. loss: 2.586526\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.06, NNZs: 44, Bias: -0.827178, T: 19200, Avg. loss: 2.624687\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.839258, T: 19840, Avg. loss: 2.743357\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.852483, T: 20480, Avg. loss: 2.547765\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.862580, T: 21120, Avg. loss: 2.184022\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.875723, T: 21760, Avg. loss: 2.496151\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.890938, T: 22400, Avg. loss: 2.564650\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.904156, T: 23040, Avg. loss: 2.505766\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.917612, T: 23680, Avg. loss: 2.671161\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.930996, T: 24320, Avg. loss: 2.351704\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 38 epochs took 0.01 seconds\n",
      "--- training time 0.01073312759399414 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 1.81, NNZs: 44, Bias: -0.132429, T: 640, Avg. loss: 30.907784\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.39, NNZs: 44, Bias: -0.188078, T: 1280, Avg. loss: 10.660232\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.25, NNZs: 44, Bias: -0.238202, T: 1920, Avg. loss: 9.212930\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.276557, T: 2560, Avg. loss: 9.238287\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.316699, T: 3200, Avg. loss: 7.258781\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.20, NNZs: 44, Bias: -0.346927, T: 3840, Avg. loss: 6.083062\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.05, NNZs: 44, Bias: -0.377001, T: 4480, Avg. loss: 6.074865\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.405743, T: 5120, Avg. loss: 5.408817\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.05, NNZs: 44, Bias: -0.434407, T: 5760, Avg. loss: 5.172337\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.07, NNZs: 44, Bias: -0.459415, T: 6400, Avg. loss: 4.729603\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.08, NNZs: 44, Bias: -0.484385, T: 7040, Avg. loss: 4.626073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.505227, T: 7680, Avg. loss: 4.504605\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.529476, T: 8320, Avg. loss: 3.886199\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.548966, T: 8960, Avg. loss: 4.488182\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.574013, T: 9600, Avg. loss: 4.301054\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1.06, NNZs: 44, Bias: -0.594354, T: 10240, Avg. loss: 3.785013\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.616599, T: 10880, Avg. loss: 3.399852\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.636243, T: 11520, Avg. loss: 3.280211\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.96, NNZs: 44, Bias: -0.654038, T: 12160, Avg. loss: 3.690596\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.671599, T: 12800, Avg. loss: 3.693993\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.689654, T: 13440, Avg. loss: 3.407431\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.705857, T: 14080, Avg. loss: 2.926440\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.720351, T: 14720, Avg. loss: 3.038130\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.736537, T: 15360, Avg. loss: 3.017863\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 1.01, NNZs: 44, Bias: -0.751568, T: 16000, Avg. loss: 2.732331\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.98, NNZs: 44, Bias: -0.766843, T: 16640, Avg. loss: 2.835467\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.779676, T: 17280, Avg. loss: 2.794700\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.795386, T: 17920, Avg. loss: 2.689158\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.809601, T: 18560, Avg. loss: 2.586526\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.06, NNZs: 44, Bias: -0.827178, T: 19200, Avg. loss: 2.624687\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1.02, NNZs: 44, Bias: -0.839258, T: 19840, Avg. loss: 2.743357\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 1.00, NNZs: 44, Bias: -0.852483, T: 20480, Avg. loss: 2.547765\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.862580, T: 21120, Avg. loss: 2.184022\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.99, NNZs: 44, Bias: -0.875723, T: 21760, Avg. loss: 2.496151\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.890938, T: 22400, Avg. loss: 2.564650\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.904156, T: 23040, Avg. loss: 2.505766\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1.04, NNZs: 44, Bias: -0.917612, T: 23680, Avg. loss: 2.671161\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1.03, NNZs: 44, Bias: -0.930996, T: 24320, Avg. loss: 2.351704\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 38 epochs took 0.01 seconds\n",
      "--- training time 0.01024007797241211 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 10.91, NNZs: 43, Bias: -2.550009, T: 640, Avg. loss: 402.389039\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.71, NNZs: 44, Bias: -5.050009, T: 1280, Avg. loss: 323.294791\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.46, NNZs: 44, Bias: -7.512515, T: 1920, Avg. loss: 359.311537\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.05, NNZs: 44, Bias: -10.201947, T: 2560, Avg. loss: 399.918189\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.69, NNZs: 44, Bias: -12.720222, T: 3200, Avg. loss: 361.718888\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.91, NNZs: 44, Bias: -14.880795, T: 3840, Avg. loss: 377.351976\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 19.10, NNZs: 44, Bias: -17.180424, T: 4480, Avg. loss: 376.820507\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 5.86, NNZs: 44, Bias: -17.603116, T: 5120, Avg. loss: 83.034376\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 9.02, NNZs: 44, Bias: -18.059716, T: 5760, Avg. loss: 72.589001\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 7.08, NNZs: 44, Bias: -18.459718, T: 6400, Avg. loss: 68.394544\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 7.82, NNZs: 44, Bias: -18.920503, T: 7040, Avg. loss: 75.816719\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 9.16, NNZs: 44, Bias: -19.338538, T: 7680, Avg. loss: 82.091663\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 6.28, NNZs: 44, Bias: -19.866070, T: 8320, Avg. loss: 80.338302\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 8.67, NNZs: 44, Bias: -20.249927, T: 8960, Avg. loss: 77.763763\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 6.72, NNZs: 44, Bias: -20.783372, T: 9600, Avg. loss: 84.528284\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 2.60, NNZs: 44, Bias: -20.831906, T: 10240, Avg. loss: 21.081200\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 2.52, NNZs: 44, Bias: -20.915984, T: 10880, Avg. loss: 13.879038\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 2.16, NNZs: 44, Bias: -20.997294, T: 11520, Avg. loss: 14.867438\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 1.96, NNZs: 44, Bias: -21.073347, T: 12160, Avg. loss: 15.247984\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.67, NNZs: 44, Bias: -21.147747, T: 12800, Avg. loss: 15.697421\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.95, NNZs: 44, Bias: -21.221151, T: 13440, Avg. loss: 15.912261\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 1.86, NNZs: 44, Bias: -21.289947, T: 14080, Avg. loss: 13.323098\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 2.05, NNZs: 44, Bias: -21.355879, T: 14720, Avg. loss: 15.670591\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 2.38, NNZs: 44, Bias: -21.439276, T: 15360, Avg. loss: 14.048558\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 2.40, NNZs: 44, Bias: -21.531538, T: 16000, Avg. loss: 15.405405\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 1.73, NNZs: 44, Bias: -21.595660, T: 16640, Avg. loss: 15.098512\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 2.46, NNZs: 44, Bias: -21.656147, T: 17280, Avg. loss: 14.324409\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1.48, NNZs: 44, Bias: -21.665591, T: 17920, Avg. loss: 5.804966\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.08, NNZs: 44, Bias: -21.673279, T: 18560, Avg. loss: 2.931253\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.02, NNZs: 44, Bias: -21.683801, T: 19200, Avg. loss: 2.375622\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.99, NNZs: 44, Bias: -21.692709, T: 19840, Avg. loss: 2.414061\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.95, NNZs: 44, Bias: -21.702718, T: 20480, Avg. loss: 2.667215\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.95, NNZs: 44, Bias: -21.708766, T: 21120, Avg. loss: 2.440674\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.720001, T: 21760, Avg. loss: 2.313048\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.732348, T: 22400, Avg. loss: 2.643310\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.742019, T: 23040, Avg. loss: 2.435969\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.90, NNZs: 44, Bias: -21.752661, T: 23680, Avg. loss: 2.758176\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.90, NNZs: 44, Bias: -21.763259, T: 24320, Avg. loss: 2.249982\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.91, NNZs: 44, Bias: -21.772147, T: 24960, Avg. loss: 2.264457\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.89, NNZs: 44, Bias: -21.780717, T: 25600, Avg. loss: 2.408183\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.87, NNZs: 44, Bias: -21.788835, T: 26240, Avg. loss: 2.288684\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.86, NNZs: 44, Bias: -21.796010, T: 26880, Avg. loss: 2.150486\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.88, NNZs: 44, Bias: -21.804099, T: 27520, Avg. loss: 2.213629\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.84, NNZs: 44, Bias: -21.813593, T: 28160, Avg. loss: 2.698464\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.85, NNZs: 44, Bias: -21.824923, T: 28800, Avg. loss: 2.531753\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.86, NNZs: 44, Bias: -21.835083, T: 29440, Avg. loss: 2.314919\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.87, NNZs: 44, Bias: -21.847257, T: 30080, Avg. loss: 2.572171\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.83, NNZs: 44, Bias: -21.847102, T: 30720, Avg. loss: 0.727465\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.81, NNZs: 44, Bias: -21.847476, T: 31360, Avg. loss: 0.394332\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.81, NNZs: 44, Bias: -21.847750, T: 32000, Avg. loss: 0.347348\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.80, NNZs: 44, Bias: -21.848207, T: 32640, Avg. loss: 0.294411\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.79, NNZs: 44, Bias: -21.848611, T: 33280, Avg. loss: 0.313080\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.78, NNZs: 44, Bias: -21.849179, T: 33920, Avg. loss: 0.338814\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.78, NNZs: 44, Bias: -21.849595, T: 34560, Avg. loss: 0.311426\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.77, NNZs: 44, Bias: -21.850114, T: 35200, Avg. loss: 0.278903\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.76, NNZs: 44, Bias: -21.850544, T: 35840, Avg. loss: 0.323347\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.76, NNZs: 44, Bias: -21.850999, T: 36480, Avg. loss: 0.285556\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.75, NNZs: 44, Bias: -21.851467, T: 37120, Avg. loss: 0.311541\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.75, NNZs: 44, Bias: -21.851826, T: 37760, Avg. loss: 0.333364\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.75, NNZs: 44, Bias: -21.852213, T: 38400, Avg. loss: 0.332154\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852266, T: 39040, Avg. loss: 0.133484\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852265, T: 39680, Avg. loss: 0.124933\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852264, T: 40320, Avg. loss: 0.134122\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852245, T: 40960, Avg. loss: 0.124002\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852247, T: 41600, Avg. loss: 0.126805\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852262, T: 42240, Avg. loss: 0.126852\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852263, T: 42880, Avg. loss: 0.125756\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852229, T: 43520, Avg. loss: 0.106021\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852226, T: 44160, Avg. loss: 0.103396\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852218, T: 44800, Avg. loss: 0.104170\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852229, T: 45440, Avg. loss: 0.105322\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852224, T: 46080, Avg. loss: 0.105754\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852236, T: 46720, Avg. loss: 0.101491\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852229, T: 47360, Avg. loss: 0.104941\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852214, T: 48000, Avg. loss: 0.105051\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852213, T: 48640, Avg. loss: 0.105558\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852203, T: 49280, Avg. loss: 0.104789\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852202, T: 49920, Avg. loss: 0.104441\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 50560, Avg. loss: 0.100782\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 51200, Avg. loss: 0.100245\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852208, T: 51840, Avg. loss: 0.100183\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 52480, Avg. loss: 0.100279\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852208, T: 53120, Avg. loss: 0.099715\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852208, T: 53760, Avg. loss: 0.099310\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 54400, Avg. loss: 0.099242\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 55040, Avg. loss: 0.099155\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852206, T: 55680, Avg. loss: 0.099177\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852206, T: 56320, Avg. loss: 0.099165\n",
      "Total training time: 0.09 seconds.\n",
      "Convergence after 88 epochs took 0.09 seconds\n",
      "--- training time 0.08925485610961914 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 10.91, NNZs: 43, Bias: -2.550009, T: 640, Avg. loss: 402.389039\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.71, NNZs: 44, Bias: -5.050009, T: 1280, Avg. loss: 323.294791\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.46, NNZs: 44, Bias: -7.512515, T: 1920, Avg. loss: 359.311537\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.05, NNZs: 44, Bias: -10.201947, T: 2560, Avg. loss: 399.918189\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.69, NNZs: 44, Bias: -12.720222, T: 3200, Avg. loss: 361.718888\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.91, NNZs: 44, Bias: -14.880795, T: 3840, Avg. loss: 377.351976\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 19.10, NNZs: 44, Bias: -17.180424, T: 4480, Avg. loss: 376.820507\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 5.86, NNZs: 44, Bias: -17.603116, T: 5120, Avg. loss: 83.034376\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 9.02, NNZs: 44, Bias: -18.059716, T: 5760, Avg. loss: 72.589001\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 7.08, NNZs: 44, Bias: -18.459718, T: 6400, Avg. loss: 68.394544\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 7.82, NNZs: 44, Bias: -18.920503, T: 7040, Avg. loss: 75.816719\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 9.16, NNZs: 44, Bias: -19.338538, T: 7680, Avg. loss: 82.091663\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 6.28, NNZs: 44, Bias: -19.866070, T: 8320, Avg. loss: 80.338302\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 8.67, NNZs: 44, Bias: -20.249927, T: 8960, Avg. loss: 77.763763\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 6.72, NNZs: 44, Bias: -20.783372, T: 9600, Avg. loss: 84.528284\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 2.60, NNZs: 44, Bias: -20.831906, T: 10240, Avg. loss: 21.081200\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 2.52, NNZs: 44, Bias: -20.915984, T: 10880, Avg. loss: 13.879038\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 2.16, NNZs: 44, Bias: -20.997294, T: 11520, Avg. loss: 14.867438\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 1.96, NNZs: 44, Bias: -21.073347, T: 12160, Avg. loss: 15.247984\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.67, NNZs: 44, Bias: -21.147747, T: 12800, Avg. loss: 15.697421\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.95, NNZs: 44, Bias: -21.221151, T: 13440, Avg. loss: 15.912261\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 1.86, NNZs: 44, Bias: -21.289947, T: 14080, Avg. loss: 13.323098\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 2.05, NNZs: 44, Bias: -21.355879, T: 14720, Avg. loss: 15.670591\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 2.38, NNZs: 44, Bias: -21.439276, T: 15360, Avg. loss: 14.048558\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 2.40, NNZs: 44, Bias: -21.531538, T: 16000, Avg. loss: 15.405405\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 1.73, NNZs: 44, Bias: -21.595660, T: 16640, Avg. loss: 15.098512\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 2.46, NNZs: 44, Bias: -21.656147, T: 17280, Avg. loss: 14.324409\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1.48, NNZs: 44, Bias: -21.665591, T: 17920, Avg. loss: 5.804966\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.08, NNZs: 44, Bias: -21.673279, T: 18560, Avg. loss: 2.931253\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.02, NNZs: 44, Bias: -21.683801, T: 19200, Avg. loss: 2.375622\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.99, NNZs: 44, Bias: -21.692709, T: 19840, Avg. loss: 2.414061\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.95, NNZs: 44, Bias: -21.702718, T: 20480, Avg. loss: 2.667215\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.95, NNZs: 44, Bias: -21.708766, T: 21120, Avg. loss: 2.440674\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.720001, T: 21760, Avg. loss: 2.313048\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.732348, T: 22400, Avg. loss: 2.643310\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.742019, T: 23040, Avg. loss: 2.435969\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.90, NNZs: 44, Bias: -21.752661, T: 23680, Avg. loss: 2.758176\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.90, NNZs: 44, Bias: -21.763259, T: 24320, Avg. loss: 2.249982\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.91, NNZs: 44, Bias: -21.772147, T: 24960, Avg. loss: 2.264457\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.89, NNZs: 44, Bias: -21.780717, T: 25600, Avg. loss: 2.408183\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.87, NNZs: 44, Bias: -21.788835, T: 26240, Avg. loss: 2.288684\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.86, NNZs: 44, Bias: -21.796010, T: 26880, Avg. loss: 2.150486\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.88, NNZs: 44, Bias: -21.804099, T: 27520, Avg. loss: 2.213629\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.84, NNZs: 44, Bias: -21.813593, T: 28160, Avg. loss: 2.698464\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.85, NNZs: 44, Bias: -21.824923, T: 28800, Avg. loss: 2.531753\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.86, NNZs: 44, Bias: -21.835083, T: 29440, Avg. loss: 2.314919\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.87, NNZs: 44, Bias: -21.847257, T: 30080, Avg. loss: 2.572171\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.83, NNZs: 44, Bias: -21.847102, T: 30720, Avg. loss: 0.727465\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.81, NNZs: 44, Bias: -21.847476, T: 31360, Avg. loss: 0.394332\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.81, NNZs: 44, Bias: -21.847750, T: 32000, Avg. loss: 0.347348\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.80, NNZs: 44, Bias: -21.848207, T: 32640, Avg. loss: 0.294411\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.79, NNZs: 44, Bias: -21.848611, T: 33280, Avg. loss: 0.313080\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.78, NNZs: 44, Bias: -21.849179, T: 33920, Avg. loss: 0.338814\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.78, NNZs: 44, Bias: -21.849595, T: 34560, Avg. loss: 0.311426\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.77, NNZs: 44, Bias: -21.850114, T: 35200, Avg. loss: 0.278903\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.76, NNZs: 44, Bias: -21.850544, T: 35840, Avg. loss: 0.323347\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.76, NNZs: 44, Bias: -21.850999, T: 36480, Avg. loss: 0.285556\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.75, NNZs: 44, Bias: -21.851467, T: 37120, Avg. loss: 0.311541\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.75, NNZs: 44, Bias: -21.851826, T: 37760, Avg. loss: 0.333364\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.75, NNZs: 44, Bias: -21.852213, T: 38400, Avg. loss: 0.332154\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852266, T: 39040, Avg. loss: 0.133484\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852265, T: 39680, Avg. loss: 0.124933\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852264, T: 40320, Avg. loss: 0.134122\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852245, T: 40960, Avg. loss: 0.124002\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852247, T: 41600, Avg. loss: 0.126805\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852262, T: 42240, Avg. loss: 0.126852\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852263, T: 42880, Avg. loss: 0.125756\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852229, T: 43520, Avg. loss: 0.106021\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852226, T: 44160, Avg. loss: 0.103396\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852218, T: 44800, Avg. loss: 0.104170\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852229, T: 45440, Avg. loss: 0.105322\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852224, T: 46080, Avg. loss: 0.105754\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852236, T: 46720, Avg. loss: 0.101491\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852229, T: 47360, Avg. loss: 0.104941\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852214, T: 48000, Avg. loss: 0.105051\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852213, T: 48640, Avg. loss: 0.105558\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852203, T: 49280, Avg. loss: 0.104789\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852202, T: 49920, Avg. loss: 0.104441\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 50560, Avg. loss: 0.100782\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 51200, Avg. loss: 0.100245\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852208, T: 51840, Avg. loss: 0.100183\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 52480, Avg. loss: 0.100279\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852208, T: 53120, Avg. loss: 0.099715\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852208, T: 53760, Avg. loss: 0.099310\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 54400, Avg. loss: 0.099242\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 55040, Avg. loss: 0.099155\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852206, T: 55680, Avg. loss: 0.099177\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852206, T: 56320, Avg. loss: 0.099165\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 88 epochs took 0.02 seconds\n",
      "--- training time 0.020241975784301758 seconds ---\n",
      "-- Epoch 1\n",
      "Norm: 10.91, NNZs: 43, Bias: -2.550009, T: 640, Avg. loss: 402.389039\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.71, NNZs: 44, Bias: -5.050009, T: 1280, Avg. loss: 323.294791\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.46, NNZs: 44, Bias: -7.512515, T: 1920, Avg. loss: 359.311537\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.05, NNZs: 44, Bias: -10.201947, T: 2560, Avg. loss: 399.918189\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.69, NNZs: 44, Bias: -12.720222, T: 3200, Avg. loss: 361.718888\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.91, NNZs: 44, Bias: -14.880795, T: 3840, Avg. loss: 377.351976\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 19.10, NNZs: 44, Bias: -17.180424, T: 4480, Avg. loss: 376.820507\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 5.86, NNZs: 44, Bias: -17.603116, T: 5120, Avg. loss: 83.034376\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 9.02, NNZs: 44, Bias: -18.059716, T: 5760, Avg. loss: 72.589001\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 7.08, NNZs: 44, Bias: -18.459718, T: 6400, Avg. loss: 68.394544\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 7.82, NNZs: 44, Bias: -18.920503, T: 7040, Avg. loss: 75.816719\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 9.16, NNZs: 44, Bias: -19.338538, T: 7680, Avg. loss: 82.091663\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 6.28, NNZs: 44, Bias: -19.866070, T: 8320, Avg. loss: 80.338302\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 8.67, NNZs: 44, Bias: -20.249927, T: 8960, Avg. loss: 77.763763\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 6.72, NNZs: 44, Bias: -20.783372, T: 9600, Avg. loss: 84.528284\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 2.60, NNZs: 44, Bias: -20.831906, T: 10240, Avg. loss: 21.081200\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 2.52, NNZs: 44, Bias: -20.915984, T: 10880, Avg. loss: 13.879038\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 2.16, NNZs: 44, Bias: -20.997294, T: 11520, Avg. loss: 14.867438\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 1.96, NNZs: 44, Bias: -21.073347, T: 12160, Avg. loss: 15.247984\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.67, NNZs: 44, Bias: -21.147747, T: 12800, Avg. loss: 15.697421\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.95, NNZs: 44, Bias: -21.221151, T: 13440, Avg. loss: 15.912261\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 1.86, NNZs: 44, Bias: -21.289947, T: 14080, Avg. loss: 13.323098\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 2.05, NNZs: 44, Bias: -21.355879, T: 14720, Avg. loss: 15.670591\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 2.38, NNZs: 44, Bias: -21.439276, T: 15360, Avg. loss: 14.048558\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 2.40, NNZs: 44, Bias: -21.531538, T: 16000, Avg. loss: 15.405405\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 1.73, NNZs: 44, Bias: -21.595660, T: 16640, Avg. loss: 15.098512\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 2.46, NNZs: 44, Bias: -21.656147, T: 17280, Avg. loss: 14.324409\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1.48, NNZs: 44, Bias: -21.665591, T: 17920, Avg. loss: 5.804966\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.08, NNZs: 44, Bias: -21.673279, T: 18560, Avg. loss: 2.931253\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.02, NNZs: 44, Bias: -21.683801, T: 19200, Avg. loss: 2.375622\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.99, NNZs: 44, Bias: -21.692709, T: 19840, Avg. loss: 2.414061\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.95, NNZs: 44, Bias: -21.702718, T: 20480, Avg. loss: 2.667215\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.95, NNZs: 44, Bias: -21.708766, T: 21120, Avg. loss: 2.440674\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.720001, T: 21760, Avg. loss: 2.313048\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.732348, T: 22400, Avg. loss: 2.643310\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.93, NNZs: 44, Bias: -21.742019, T: 23040, Avg. loss: 2.435969\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.90, NNZs: 44, Bias: -21.752661, T: 23680, Avg. loss: 2.758176\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.90, NNZs: 44, Bias: -21.763259, T: 24320, Avg. loss: 2.249982\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.91, NNZs: 44, Bias: -21.772147, T: 24960, Avg. loss: 2.264457\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.89, NNZs: 44, Bias: -21.780717, T: 25600, Avg. loss: 2.408183\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.87, NNZs: 44, Bias: -21.788835, T: 26240, Avg. loss: 2.288684\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.86, NNZs: 44, Bias: -21.796010, T: 26880, Avg. loss: 2.150486\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.88, NNZs: 44, Bias: -21.804099, T: 27520, Avg. loss: 2.213629\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.84, NNZs: 44, Bias: -21.813593, T: 28160, Avg. loss: 2.698464\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.85, NNZs: 44, Bias: -21.824923, T: 28800, Avg. loss: 2.531753\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.86, NNZs: 44, Bias: -21.835083, T: 29440, Avg. loss: 2.314919\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.87, NNZs: 44, Bias: -21.847257, T: 30080, Avg. loss: 2.572171\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.83, NNZs: 44, Bias: -21.847102, T: 30720, Avg. loss: 0.727465\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.81, NNZs: 44, Bias: -21.847476, T: 31360, Avg. loss: 0.394332\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.81, NNZs: 44, Bias: -21.847750, T: 32000, Avg. loss: 0.347348\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.80, NNZs: 44, Bias: -21.848207, T: 32640, Avg. loss: 0.294411\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.79, NNZs: 44, Bias: -21.848611, T: 33280, Avg. loss: 0.313080\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.78, NNZs: 44, Bias: -21.849179, T: 33920, Avg. loss: 0.338814\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.78, NNZs: 44, Bias: -21.849595, T: 34560, Avg. loss: 0.311426\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.77, NNZs: 44, Bias: -21.850114, T: 35200, Avg. loss: 0.278903\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.76, NNZs: 44, Bias: -21.850544, T: 35840, Avg. loss: 0.323347\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.76, NNZs: 44, Bias: -21.850999, T: 36480, Avg. loss: 0.285556\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.75, NNZs: 44, Bias: -21.851467, T: 37120, Avg. loss: 0.311541\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.75, NNZs: 44, Bias: -21.851826, T: 37760, Avg. loss: 0.333364\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.75, NNZs: 44, Bias: -21.852213, T: 38400, Avg. loss: 0.332154\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852266, T: 39040, Avg. loss: 0.133484\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852265, T: 39680, Avg. loss: 0.124933\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852264, T: 40320, Avg. loss: 0.134122\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852245, T: 40960, Avg. loss: 0.124002\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852247, T: 41600, Avg. loss: 0.126805\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.74, NNZs: 44, Bias: -21.852262, T: 42240, Avg. loss: 0.126852\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852263, T: 42880, Avg. loss: 0.125756\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852229, T: 43520, Avg. loss: 0.106021\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852226, T: 44160, Avg. loss: 0.103396\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852218, T: 44800, Avg. loss: 0.104170\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852229, T: 45440, Avg. loss: 0.105322\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852224, T: 46080, Avg. loss: 0.105754\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852236, T: 46720, Avg. loss: 0.101491\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852229, T: 47360, Avg. loss: 0.104941\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852214, T: 48000, Avg. loss: 0.105051\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852213, T: 48640, Avg. loss: 0.105558\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852203, T: 49280, Avg. loss: 0.104789\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852202, T: 49920, Avg. loss: 0.104441\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 50560, Avg. loss: 0.100782\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 51200, Avg. loss: 0.100245\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852208, T: 51840, Avg. loss: 0.100183\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 52480, Avg. loss: 0.100279\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852208, T: 53120, Avg. loss: 0.099715\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852208, T: 53760, Avg. loss: 0.099310\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 54400, Avg. loss: 0.099242\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852207, T: 55040, Avg. loss: 0.099155\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852206, T: 55680, Avg. loss: 0.099177\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 0.73, NNZs: 44, Bias: -21.852206, T: 56320, Avg. loss: 0.099165\n",
      "Total training time: 0.07 seconds.\n",
      "Convergence after 88 epochs took 0.07 seconds\n",
      "--- training time 0.07647204399108887 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# data pre-processing\n",
    "train, val = preprocess_data()\n",
    "\n",
    "X_train = train.drop(['#', 'Name', 'Legendary', 'WinRate'], axis=1)\n",
    "y_train = train.Legendary\n",
    "\n",
    "X_val = val.drop(['#', 'Name', 'Legendary', 'WinRate'], axis=1)\n",
    "y_val = val.Legendary\n",
    "\n",
    "# hyperparameters combinations\n",
    "learning_rates = [1e-4, 1e-3, 1e-2, 1e-1]\n",
    "learning_schedules = ['constant', 'optimal', 'invscaling', 'adaptive']\n",
    "iterations = [50, 100, 200, 500]\n",
    "\n",
    "models = []\n",
    "\n",
    "for it in iterations:\n",
    "    for lr in learning_rates:\n",
    "        for ls in learning_schedules:\n",
    "            for i in np.arange(model_sample_size): # train N times for every settings\n",
    "                model = {}\n",
    "                clf = SGDClassifier(loss='log', alpha=lr, learning_rate=ls, eta0=lr, max_iter=it, random_state=0, verbose=1)\n",
    "                start_time = time.time()\n",
    "                clf.fit(X_train, y_train)\n",
    "                model['time'] = time.time() - start_time\n",
    "                model['clf'] = clf\n",
    "                models.append(model)\n",
    "                print(\"--- training time %s seconds ---\" % (model['time']))\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Q5] Report the model setting, training time, and performance of the logistic regression model. Since the solution found may depend on the initial weight values, you are expected to repeat each setting multiple times (e.g., three times) for the same hyperparameter setting and report the mean and standard deviation of the training time, accuracy, and F1 score for each setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
      "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
      "              loss='log', max_iter=50, n_iter_no_change=5, n_jobs=None,\n",
      "              penalty='l2', power_t=0.5, random_state=0, shuffle=True,\n",
      "              tol=0.001, validation_fraction=0.1, verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.00838168462117513\n",
      "SD of Training Time:  0.0022013739901287533\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "3 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
      "              fit_intercept=True, l1_ratio=0.15, learning_rate='optimal',\n",
      "              loss='log', max_iter=50, n_iter_no_change=5, n_jobs=None,\n",
      "              penalty='l2', power_t=0.5, random_state=0, shuffle=True,\n",
      "              tol=0.001, validation_fraction=0.1, verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.01650555928548177\n",
      "SD of Training Time:  0.004766151572387254\n",
      "Mean Accuracy:  0.525\n",
      "SD of Accuracy:  0.0\n",
      "Mean F1 score:  0.2692307692307692\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "6 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
      "              fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
      "              loss='log', max_iter=50, n_iter_no_change=5, n_jobs=None,\n",
      "              penalty='l2', power_t=0.5, random_state=0, shuffle=True,\n",
      "              tol=0.001, validation_fraction=0.1, verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.011437018712361654\n",
      "SD of Training Time:  0.0004776951038715221\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "9 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
      "              fit_intercept=True, l1_ratio=0.15, learning_rate='adaptive',\n",
      "              loss='log', max_iter=50, n_iter_no_change=5, n_jobs=None,\n",
      "              penalty='l2', power_t=0.5, random_state=0, shuffle=True,\n",
      "              tol=0.001, validation_fraction=0.1, verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.015989383061726887\n",
      "SD of Training Time:  0.006321093039629646\n",
      "Mean Accuracy:  0.8874999999999998\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "12 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='constant', loss='log', max_iter=50,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.004595836003621419\n",
      "SD of Training Time:  6.985686970841632e-05\n",
      "Mean Accuracy:  0.8874999999999998\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "15 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=50,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.027983347574869793\n",
      "SD of Training Time:  0.022395338631980604\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "18 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='invscaling', loss='log',\n",
      "              max_iter=50, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=0, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.0070340633392333984\n",
      "SD of Training Time:  0.00044642977563257984\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.19047619047619047\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "21 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='adaptive', loss='log', max_iter=50,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.024966319402058918\n",
      "SD of Training Time:  0.009800946286595273\n",
      "Mean Accuracy:  0.90625\n",
      "SD of Accuracy:  0.0\n",
      "Mean F1 score:  0.21052631578947367\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "24 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.01, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='constant', loss='log', max_iter=50,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.006512006123860677\n",
      "SD of Training Time:  0.00019199840263617606\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "27 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.01, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=50,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.023686011632283527\n",
      "SD of Training Time:  0.007472130958910271\n",
      "Mean Accuracy:  0.6125\n",
      "SD of Accuracy:  0.0\n",
      "Mean F1 score:  0.3260869565217392\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "30 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.01, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='invscaling', loss='log',\n",
      "              max_iter=50, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=0, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.04048625628153483\n",
      "SD of Training Time:  0.031484056767763856\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "33 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.01, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='adaptive', loss='log', max_iter=50,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.056752681732177734\n",
      "SD of Training Time:  0.040422190323625345\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.41379310344827586\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "36 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.1, fit_intercept=True, l1_ratio=0.15,\n",
      "              learning_rate='constant', loss='log', max_iter=50,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.005063533782958984\n",
      "SD of Training Time:  0.00028965204873588864\n",
      "Mean Accuracy:  0.8874999999999998\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "39 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.1, fit_intercept=True, l1_ratio=0.15,\n",
      "              learning_rate='optimal', loss='log', max_iter=50,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.014567136764526367\n",
      "SD of Training Time:  0.0006517693602093785\n",
      "Mean Accuracy:  0.6125\n",
      "SD of Accuracy:  0.0\n",
      "Mean F1 score:  0.3404255319148936\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "42 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.1, fit_intercept=True, l1_ratio=0.15,\n",
      "              learning_rate='invscaling', loss='log', max_iter=50,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.018811941146850586\n",
      "SD of Training Time:  0.009837261602043594\n",
      "Mean Accuracy:  0.8874999999999998\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.10000000000000002\n",
      "SD of F1 score:  1.3877787807814457e-17\n",
      "\n",
      "45 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.1, fit_intercept=True, l1_ratio=0.15,\n",
      "              learning_rate='adaptive', loss='log', max_iter=50,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.034973700841267906\n",
      "SD of Training Time:  0.025386240890873265\n",
      "Mean Accuracy:  0.6\n",
      "SD of Accuracy:  0.0\n",
      "Mean F1 score:  0.346938775510204\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "48 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
      "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
      "              loss='log', max_iter=100, n_iter_no_change=5, n_jobs=None,\n",
      "              penalty='l2', power_t=0.5, random_state=0, shuffle=True,\n",
      "              tol=0.001, validation_fraction=0.1, verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.005289316177368164\n",
      "SD of Training Time:  0.00012018677182970538\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "51 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
      "              fit_intercept=True, l1_ratio=0.15, learning_rate='optimal',\n",
      "              loss='log', max_iter=100, n_iter_no_change=5, n_jobs=None,\n",
      "              penalty='l2', power_t=0.5, random_state=0, shuffle=True,\n",
      "              tol=0.001, validation_fraction=0.1, verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.04137579600016276\n",
      "SD of Training Time:  0.011662970187368487\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "54 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
      "              fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
      "              loss='log', max_iter=100, n_iter_no_change=5, n_jobs=None,\n",
      "              penalty='l2', power_t=0.5, random_state=0, shuffle=True,\n",
      "              tol=0.001, validation_fraction=0.1, verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.014210065205891928\n",
      "SD of Training Time:  0.0021932960048964573\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "57 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
      "              fit_intercept=True, l1_ratio=0.15, learning_rate='adaptive',\n",
      "              loss='log', max_iter=100, n_iter_no_change=5, n_jobs=None,\n",
      "              penalty='l2', power_t=0.5, random_state=0, shuffle=True,\n",
      "              tol=0.001, validation_fraction=0.1, verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.0221709410349528\n",
      "SD of Training Time:  0.007005727955089393\n",
      "Mean Accuracy:  0.8874999999999998\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "60 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='constant', loss='log', max_iter=100,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.007972002029418945\n",
      "SD of Training Time:  0.00033713820263777647\n",
      "Mean Accuracy:  0.8874999999999998\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "63 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=100,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.028873125712076824\n",
      "SD of Training Time:  0.004584734733088711\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "66 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='invscaling', loss='log',\n",
      "              max_iter=100, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=0, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.010399977366129557\n",
      "SD of Training Time:  0.0005066491606043154\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.19047619047619047\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "69 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='adaptive', loss='log', max_iter=100,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.031481424967447914\n",
      "SD of Training Time:  0.002511366681089879\n",
      "Mean Accuracy:  0.90625\n",
      "SD of Accuracy:  0.0\n",
      "Mean F1 score:  0.21052631578947367\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "72 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.01, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='constant', loss='log', max_iter=100,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.00917490323384603\n",
      "SD of Training Time:  0.0015433251055118813\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "75 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.01, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=100,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.031792004903157554\n",
      "SD of Training Time:  0.005719776234353286\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "78 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.01, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='invscaling', loss='log',\n",
      "              max_iter=100, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=0, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.029862483342488606\n",
      "SD of Training Time:  0.008770969597276985\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "81 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.01, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='adaptive', loss='log', max_iter=100,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.05046796798706055\n",
      "SD of Training Time:  0.023807853886229535\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.41379310344827586\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "84 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.1, fit_intercept=True, l1_ratio=0.15,\n",
      "              learning_rate='constant', loss='log', max_iter=100,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.008759498596191406\n",
      "SD of Training Time:  0.0007127802714889989\n",
      "Mean Accuracy:  0.8874999999999998\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "87 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.1, fit_intercept=True, l1_ratio=0.15,\n",
      "              learning_rate='optimal', loss='log', max_iter=100,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.06927704811096191\n",
      "SD of Training Time:  0.033690222250504324\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "90 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.1, fit_intercept=True, l1_ratio=0.15,\n",
      "              learning_rate='invscaling', loss='log', max_iter=100,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.01566004753112793\n",
      "SD of Training Time:  0.00013144210369651942\n",
      "Mean Accuracy:  0.8874999999999998\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.10000000000000002\n",
      "SD of F1 score:  1.3877787807814457e-17\n",
      "\n",
      "93 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.1, fit_intercept=True, l1_ratio=0.15,\n",
      "              learning_rate='adaptive', loss='log', max_iter=100,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.04985332489013672\n",
      "SD of Training Time:  0.010832466384789352\n",
      "Mean Accuracy:  0.9187499999999998\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.48\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "96 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
      "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
      "              loss='log', max_iter=200, n_iter_no_change=5, n_jobs=None,\n",
      "              penalty='l2', power_t=0.5, random_state=0, shuffle=True,\n",
      "              tol=0.001, validation_fraction=0.1, verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.006383498509724935\n",
      "SD of Training Time:  6.110103763602082e-05\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "99 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
      "              fit_intercept=True, l1_ratio=0.15, learning_rate='optimal',\n",
      "              loss='log', max_iter=200, n_iter_no_change=5, n_jobs=None,\n",
      "              penalty='l2', power_t=0.5, random_state=0, shuffle=True,\n",
      "              tol=0.001, validation_fraction=0.1, verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.03841861089070638\n",
      "SD of Training Time:  0.002345053845403084\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "102 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
      "              fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
      "              loss='log', max_iter=200, n_iter_no_change=5, n_jobs=None,\n",
      "              penalty='l2', power_t=0.5, random_state=0, shuffle=True,\n",
      "              tol=0.001, validation_fraction=0.1, verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.014124313990275065\n",
      "SD of Training Time:  0.00044535349681792713\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "105 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
      "              fit_intercept=True, l1_ratio=0.15, learning_rate='adaptive',\n",
      "              loss='log', max_iter=200, n_iter_no_change=5, n_jobs=None,\n",
      "              penalty='l2', power_t=0.5, random_state=0, shuffle=True,\n",
      "              tol=0.001, validation_fraction=0.1, verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.016486724217732746\n",
      "SD of Training Time:  0.0006368419647567039\n",
      "Mean Accuracy:  0.8874999999999998\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "108 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='constant', loss='log', max_iter=200,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.008303006490071615\n",
      "SD of Training Time:  0.000980155477961756\n",
      "Mean Accuracy:  0.8874999999999998\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "111 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=200,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.03082895278930664\n",
      "SD of Training Time:  0.0026431800330297623\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "114 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='invscaling', loss='log',\n",
      "              max_iter=200, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=0, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.012962977091471354\n",
      "SD of Training Time:  0.0026502964743123233\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.19047619047619047\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "117 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='adaptive', loss='log', max_iter=200,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.019216537475585938\n",
      "SD of Training Time:  0.007141453081198269\n",
      "Mean Accuracy:  0.90625\n",
      "SD of Accuracy:  0.0\n",
      "Mean F1 score:  0.21052631578947367\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "120 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.01, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='constant', loss='log', max_iter=200,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.0051000118255615234\n",
      "SD of Training Time:  0.00016753923098875893\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "123 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.01, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=200,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.019739389419555664\n",
      "SD of Training Time:  0.0010525217818703266\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "126 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.01, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='invscaling', loss='log',\n",
      "              max_iter=200, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=0, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.02401256561279297\n",
      "SD of Training Time:  0.011888930524273405\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "129 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.01, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='adaptive', loss='log', max_iter=200,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.03615633646647135\n",
      "SD of Training Time:  0.015199258218640106\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.41379310344827586\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "132 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.1, fit_intercept=True, l1_ratio=0.15,\n",
      "              learning_rate='constant', loss='log', max_iter=200,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.0066623687744140625\n",
      "SD of Training Time:  0.0002242367824513972\n",
      "Mean Accuracy:  0.8874999999999998\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "135 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.1, fit_intercept=True, l1_ratio=0.15,\n",
      "              learning_rate='optimal', loss='log', max_iter=200,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.04250105222066244\n",
      "SD of Training Time:  0.011570079601650953\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "138 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.1, fit_intercept=True, l1_ratio=0.15,\n",
      "              learning_rate='invscaling', loss='log', max_iter=200,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.01646868387858073\n",
      "SD of Training Time:  0.0018220883155223959\n",
      "Mean Accuracy:  0.8874999999999998\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.10000000000000002\n",
      "SD of F1 score:  1.3877787807814457e-17\n",
      "\n",
      "141 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.1, fit_intercept=True, l1_ratio=0.15,\n",
      "              learning_rate='adaptive', loss='log', max_iter=200,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.04474536577860514\n",
      "SD of Training Time:  0.006578115116004043\n",
      "Mean Accuracy:  0.9187499999999998\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.48\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "144 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
      "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
      "              loss='log', max_iter=500, n_iter_no_change=5, n_jobs=None,\n",
      "              penalty='l2', power_t=0.5, random_state=0, shuffle=True,\n",
      "              tol=0.001, validation_fraction=0.1, verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.0072011152903238935\n",
      "SD of Training Time:  0.0005767895973778541\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "147 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
      "              fit_intercept=True, l1_ratio=0.15, learning_rate='optimal',\n",
      "              loss='log', max_iter=500, n_iter_no_change=5, n_jobs=None,\n",
      "              penalty='l2', power_t=0.5, random_state=0, shuffle=True,\n",
      "              tol=0.001, validation_fraction=0.1, verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.03958050409952799\n",
      "SD of Training Time:  0.0016078889856937504\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "150 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
      "              fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
      "              loss='log', max_iter=500, n_iter_no_change=5, n_jobs=None,\n",
      "              penalty='l2', power_t=0.5, random_state=0, shuffle=True,\n",
      "              tol=0.001, validation_fraction=0.1, verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.015215873718261719\n",
      "SD of Training Time:  0.0006942271951556237\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "153 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
      "              fit_intercept=True, l1_ratio=0.15, learning_rate='adaptive',\n",
      "              loss='log', max_iter=500, n_iter_no_change=5, n_jobs=None,\n",
      "              penalty='l2', power_t=0.5, random_state=0, shuffle=True,\n",
      "              tol=0.001, validation_fraction=0.1, verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.016506036122639973\n",
      "SD of Training Time:  0.0005435250030760988\n",
      "Mean Accuracy:  0.8874999999999998\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "156 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='constant', loss='log', max_iter=500,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.008564074834187826\n",
      "SD of Training Time:  0.00031899475321037045\n",
      "Mean Accuracy:  0.8874999999999998\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "159 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=500,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.029338995615641277\n",
      "SD of Training Time:  0.0005745738151962909\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "162 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='invscaling', loss='log',\n",
      "              max_iter=500, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=0, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.008637030919392904\n",
      "SD of Training Time:  0.002577475854224833\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.19047619047619047\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "165 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='adaptive', loss='log', max_iter=500,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.014499187469482422\n",
      "SD of Training Time:  0.00043468255823185623\n",
      "Mean Accuracy:  0.90625\n",
      "SD of Accuracy:  0.0\n",
      "Mean F1 score:  0.21052631578947367\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "168 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.01, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='constant', loss='log', max_iter=500,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.004992882410685222\n",
      "SD of Training Time:  4.3494385977486206e-05\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "171 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.01, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=500,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.02463420232137044\n",
      "SD of Training Time:  0.0064545001071540774\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "174 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.01, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='invscaling', loss='log',\n",
      "              max_iter=500, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=0, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.02501058578491211\n",
      "SD of Training Time:  0.016539248200057\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "177 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.01, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='adaptive', loss='log', max_iter=500,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.05558697382609049\n",
      "SD of Training Time:  0.033702770883648155\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.41379310344827586\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "180 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.1, fit_intercept=True, l1_ratio=0.15,\n",
      "              learning_rate='constant', loss='log', max_iter=500,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.009961684544881185\n",
      "SD of Training Time:  0.0017522390503395275\n",
      "Mean Accuracy:  0.8874999999999998\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "183 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.1, fit_intercept=True, l1_ratio=0.15,\n",
      "              learning_rate='optimal', loss='log', max_iter=500,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.05347522099812826\n",
      "SD of Training Time:  0.010402321190641063\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "186 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.1, fit_intercept=True, l1_ratio=0.15,\n",
      "              learning_rate='invscaling', loss='log', max_iter=500,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.010468721389770508\n",
      "SD of Training Time:  0.00020286894789300504\n",
      "Mean Accuracy:  0.8874999999999998\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.10000000000000002\n",
      "SD of F1 score:  1.3877787807814457e-17\n",
      "\n",
      "189 / 192\n",
      "Model Settings:  SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.1, fit_intercept=True, l1_ratio=0.15,\n",
      "              learning_rate='adaptive', loss='log', max_iter=500,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)\n",
      "Mean Training Time:  0.06198962529500326\n",
      "SD of Training Time:  0.029977766774346753\n",
      "Mean Accuracy:  0.9187499999999998\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.48\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "Best Training Time;  0.06198962529500326\n",
      "{'time': 0.08925485610961914, 'clf': SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.1, fit_intercept=True, l1_ratio=0.15,\n",
      "              learning_rate='adaptive', loss='log', max_iter=500,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)}\n",
      "\n",
      "Best accuracy:  0.9187499999999998\n",
      "{'time': 0.08925485610961914, 'clf': SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.1, fit_intercept=True, l1_ratio=0.15,\n",
      "              learning_rate='adaptive', loss='log', max_iter=500,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)}\n",
      "\n",
      "Best f1 score:  0.48\n",
      "{'time': 0.08925485610961914, 'clf': SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.1, fit_intercept=True, l1_ratio=0.15,\n",
      "              learning_rate='adaptive', loss='log', max_iter=500,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "              verbose=1, warm_start=False)}\n"
     ]
    }
   ],
   "source": [
    "report(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "hidden = [1, 2, 4, 8, 16, 32, 64]\n",
    "iteration = 500\n",
    "\n",
    "train, val = preprocess_data()\n",
    "X_train = train.drop(['#', 'Name', 'Legendary', 'WinRate'], axis=1)\n",
    "y_train = train.Legendary\n",
    "X_val = val.drop(['#', 'Name', 'Legendary', 'WinRate'], axis=1)\n",
    "y_val = val.Legendary\n",
    "\n",
    "models = []\n",
    "\n",
    "for hu in hidden:\n",
    "    for i in np.arange(3):\n",
    "        model = {}\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(hu, ), max_iter=iteration, solver='sgd')\n",
    "        start_time = time.time()\n",
    "        mlp.fit(X_train, y_train)\n",
    "        model['time'] = time.time() - start_time\n",
    "        model['clf'] = mlp\n",
    "        models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Q6] Report the model setting, training time, and performance of the neural networks for each value of H. You are also expected to repeat each setting multiple times for the same hyperpa- rameter setting and report the mean and standard deviation of the training time, accuracy, and F1 score for each setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hidden Unit</th>\n",
       "      <th>Mean Time</th>\n",
       "      <th>Std. Time</th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Std. Accuracy</th>\n",
       "      <th>Mean F1 Score</th>\n",
       "      <th>Std. F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.294923</td>\n",
       "      <td>0.090186</td>\n",
       "      <td>0.891667</td>\n",
       "      <td>2.946278e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.256203</td>\n",
       "      <td>0.092008</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.253660</td>\n",
       "      <td>0.069851</td>\n",
       "      <td>0.891667</td>\n",
       "      <td>2.946278e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0.192969</td>\n",
       "      <td>0.136579</td>\n",
       "      <td>0.881250</td>\n",
       "      <td>1.020621e-02</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>0.040992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>0.272454</td>\n",
       "      <td>0.174739</td>\n",
       "      <td>0.891667</td>\n",
       "      <td>2.946278e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>0.313060</td>\n",
       "      <td>0.039107</td>\n",
       "      <td>0.870833</td>\n",
       "      <td>1.178511e-02</td>\n",
       "      <td>0.216055</td>\n",
       "      <td>0.069147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>0.362329</td>\n",
       "      <td>0.154806</td>\n",
       "      <td>0.902083</td>\n",
       "      <td>7.795120e-03</td>\n",
       "      <td>0.295815</td>\n",
       "      <td>0.075506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hidden Unit  Mean Time  Std. Time  Mean Accuracy  Std. Accuracy  \\\n",
       "0            1   0.294923   0.090186       0.891667   2.946278e-03   \n",
       "1            2   0.256203   0.092008       0.893750   1.110223e-16   \n",
       "2            4   0.253660   0.069851       0.891667   2.946278e-03   \n",
       "3            8   0.192969   0.136579       0.881250   1.020621e-02   \n",
       "4           16   0.272454   0.174739       0.891667   2.946278e-03   \n",
       "5           32   0.313060   0.039107       0.870833   1.178511e-02   \n",
       "6           64   0.362329   0.154806       0.902083   7.795120e-03   \n",
       "\n",
       "   Mean F1 Score  Std. F1 Score  \n",
       "0       0.000000       0.000000  \n",
       "1       0.000000       0.000000  \n",
       "2       0.000000       0.000000  \n",
       "3       0.028986       0.040992  \n",
       "4       0.000000       0.000000  \n",
       "5       0.216055       0.069147  \n",
       "6       0.295815       0.075506  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_table(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 / 21\n",
      "Model Settings:  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(1,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=None, shuffle=True, solver='sgd',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False)\n",
      "Mean Training Time:  0.2949232260386149\n",
      "SD of Training Time:  0.0901857383138779\n",
      "Mean Accuracy:  0.8916666666666666\n",
      "SD of Accuracy:  0.00294627825494399\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "3 / 21\n",
      "Model Settings:  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(2,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=None, shuffle=True, solver='sgd',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False)\n",
      "Mean Training Time:  0.25620269775390625\n",
      "SD of Training Time:  0.09200838521485394\n",
      "Mean Accuracy:  0.8937500000000002\n",
      "SD of Accuracy:  1.1102230246251565e-16\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "6 / 21\n",
      "Model Settings:  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(4,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=None, shuffle=True, solver='sgd',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False)\n",
      "Mean Training Time:  0.25365956624348956\n",
      "SD of Training Time:  0.06985107734578132\n",
      "Mean Accuracy:  0.8916666666666666\n",
      "SD of Accuracy:  0.00294627825494399\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "9 / 21\n",
      "Model Settings:  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(8,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=None, shuffle=True, solver='sgd',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False)\n",
      "Mean Training Time:  0.19296868642171225\n",
      "SD of Training Time:  0.13657872405606564\n",
      "Mean Accuracy:  0.88125\n",
      "SD of Accuracy:  0.010206207261596585\n",
      "Mean F1 score:  0.028985507246376815\n",
      "SD of F1 score:  0.04099169746008972\n",
      "\n",
      "12 / 21\n",
      "Model Settings:  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(16,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=None, shuffle=True, solver='sgd',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False)\n",
      "Mean Training Time:  0.27245426177978516\n",
      "SD of Training Time:  0.17473861019218728\n",
      "Mean Accuracy:  0.8916666666666666\n",
      "SD of Accuracy:  0.00294627825494399\n",
      "Mean F1 score:  0.0\n",
      "SD of F1 score:  0.0\n",
      "\n",
      "15 / 21\n",
      "Model Settings:  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(32,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=None, shuffle=True, solver='sgd',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False)\n",
      "Mean Training Time:  0.31306012471516925\n",
      "SD of Training Time:  0.03910716416221514\n",
      "Mean Accuracy:  0.8708333333333332\n",
      "SD of Accuracy:  0.01178511301977575\n",
      "Mean F1 score:  0.21605477855477853\n",
      "SD of F1 score:  0.06914655518983011\n",
      "\n",
      "18 / 21\n",
      "Model Settings:  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(64,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=None, shuffle=True, solver='sgd',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False)\n",
      "Mean Training Time:  0.36232900619506836\n",
      "SD of Training Time:  0.15480578070745699\n",
      "Mean Accuracy:  0.9020833333333335\n",
      "SD of Accuracy:  0.007795119555779017\n",
      "Mean F1 score:  0.29581529581529575\n",
      "SD of F1 score:  0.07550635181501372\n",
      "\n",
      "Best Training Time;  0.36232900619506836\n",
      "{'time': 0.20305705070495605, 'clf': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(64,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=None, shuffle=True, solver='sgd',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False)}\n",
      "\n",
      "Best accuracy:  0.9020833333333335\n",
      "{'time': 0.20305705070495605, 'clf': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(64,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=None, shuffle=True, solver='sgd',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False)}\n",
      "\n",
      "Best f1 score:  0.29581529581529575\n",
      "{'time': 0.20305705070495605, 'clf': MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(64,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=None, shuffle=True, solver='sgd',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False)}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "report(models, needGraph=True, xaxis=hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Q7] Compare the training time, accuracy and F1 score of the logistic regression model and the best neural network model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "source": [
    "#### Linear Regression\n",
    "    SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
    "              epsilon=0.1, eta0=0.1, fit_intercept=True, l1_ratio=0.15,\n",
    "              learning_rate='adaptive', loss='log', max_iter=500,\n",
    "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
    "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
    "              verbose=1, warm_start=False)\n",
    "    \n",
    "    Best Training Time;  0.04816102981567383\n",
    "    Best accuracy:  0.9187499999999998\n",
    "    Best f1 score:  0.48\n",
    "\n",
    "#### Neural Network\n",
    "    MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "              hidden_layer_sizes=(64,), learning_rate='constant',\n",
    "              learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
    "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
    "              power_t=0.5, random_state=4211, shuffle=True, solver='sgd',\n",
    "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
    "              warm_start=False)\n",
    "\n",
    "    Best Training Time;  0.594632069269816\n",
    "    Best accuracy:  0.86875\n",
    "    Best f1 score:  0.4615384615384615"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Q8] Plot the accuracy and the F1 score for different values of H."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./task8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Q9] Do you notice any trend when you increase the hidden layer size from 1 to 64? If so, please describe what the trend is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With increasing the hidden layer size from 1 to 64, the f1 score increase while the accuracy score remain more or less the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Q10] Referring to your experiment results, comment on the gap between accuracy and the F1 score? Suggest a reason for this observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    735\n",
       "True      65\n",
       "Name: Legendary, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pokemons['Legendary'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gap between accuracy score and f1 score is quite large (~1% - 50%), I think the main reason is the skewed dataset. Most of the data are not Legendary(8.125%), so only a few data sample are Legendary(91.875%). The value of true-positive will be small, this is the factor that will lower the f1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Predicting the Winners in the Pokemon Battles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils.fixes import loguniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 90), (40000, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process the data, we will use all the features of the pokemon\n",
    "\n",
    "def preprocess_data_task4(battles):\n",
    "    pokemons = pd.read_csv('./data/pokemon.csv', sep=',')\n",
    "\n",
    "    train = cat_to_ont_hot(pokemons)\n",
    "    \n",
    "    # link 'Second_pokemon' in battle to pokemon list\n",
    "    first_result = pd.merge(train, battles, left_on='#', right_on='Second_pokemon')\n",
    "    # Link 'First_pokemon' in battle to pokemon list\n",
    "    result = pd.merge(train, first_result, left_on='#', right_on='First_pokemon', suffixes=('_First', '_Second'))\n",
    "    # Change value of 'Winner' to 1 / 0, indicating the current pokemon win / loss\n",
    "    result['Win'] = (result['Winner'] == result['#_First']) * 1\n",
    "    # Drop all the unwanted features\n",
    "    result = result.drop(['#_First', 'Name_First',\n",
    "                          '#_Second', 'Name_Second',\n",
    "                          'First_pokemon', 'Second_pokemon', 'Winner'], axis=1)\n",
    "    \n",
    "#     print(result.columns.values)\n",
    "#     print()\n",
    "#     print(result.head())\n",
    "    return (result.iloc[:, :-1], result.iloc[:, -1:])\n",
    "\n",
    "battles = pd.read_csv('./data/battles.csv', sep=',')\n",
    "X_train, y_train = preprocess_data_task4(battles)\n",
    "\n",
    "(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 17.6min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 36.2min\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed: 69.7min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed: 86.2min finished\n",
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 5219.69 seconds for 120 candidate parameter settings.\n"
     ]
    }
   ],
   "source": [
    "#*****************************************\n",
    "#* DO NOT RUN THIS CELL AGAIN!! \n",
    "#* LOAD THE MODEL FROM THE CELLS BELOW!!\n",
    "#*****************************************\n",
    "\n",
    "random_dist = {'hidden_layer_sizes': [(20, ), (10, 10), (15, 5), (50, ), (128, ), (256, ), (512, )],\n",
    "               'solver': ['sgd', 'adam'],\n",
    "               'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "               'alpha': [0.0001, 0.05],\n",
    "               'learning_rate_init': [1e-4, 1e-3, 1e-2], \n",
    "               'activation': ['tanh', 'relu']}\n",
    "\n",
    "# run grid search\n",
    "mlp = MLPClassifier(max_iter=500)\n",
    "grid_search = GridSearchCV(mlp, random_dist, n_jobs=-1, cv=5, verbose=3)\n",
    "start = time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*****************************************\n",
    "#* DO NOT RUN THIS CELL AGAIN!! \n",
    "#* LOAD THE MODEL FROM THE CELLS BELOW!!\n",
    "#*****************************************\n",
    "\n",
    "import pickle\n",
    "\n",
    "filename = 'grid_search.sav'\n",
    "\n",
    "# save model to disk\n",
    "pickle.dump(grid_search, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.22.2.post1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.22.2.post1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator GridSearchCV from version 0.22.2.post1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "filename = './model/hidden_unit_512.sav'\n",
    "# filename = 'task4_from_win.sav'\n",
    "\n",
    "# load the model from disk\n",
    "grid_search = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Q11] Report 10 combinations of the hyperparameter setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test score: 0.938 (std: 0.015) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.941 (std: 0.010) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.937 (std: 0.016) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.941 (std: 0.013) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.933 (std: 0.016) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.935 (std: 0.014) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.589 (std: 0.188) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.944 (std: 0.011) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.823 (std: 0.090) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.932 (std: 0.008) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.936 (std: 0.014) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.937 (std: 0.019) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.938 (std: 0.015) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.944 (std: 0.011) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.941 (std: 0.014) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.942 (std: 0.009) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.941 (std: 0.016) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.930 (std: 0.018) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.937 (std: 0.017) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.944 (std: 0.013) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.936 (std: 0.018) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.944 (std: 0.014) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.914 (std: 0.026) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.930 (std: 0.029) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.697 (std: 0.162) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.944 (std: 0.011) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.850 (std: 0.055) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.943 (std: 0.013) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.917 (std: 0.069) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.927 (std: 0.012) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.938 (std: 0.016) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.943 (std: 0.010) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.942 (std: 0.017) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.942 (std: 0.014) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.942 (std: 0.019) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.928 (std: 0.017) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.939 (std: 0.017) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.943 (std: 0.008) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.942 (std: 0.013) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.943 (std: 0.011) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.921 (std: 0.030) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.931 (std: 0.021) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.695 (std: 0.104) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.943 (std: 0.013) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.817 (std: 0.049) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.943 (std: 0.011) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.932 (std: 0.025) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.935 (std: 0.012) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.938 (std: 0.016) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.945 (std: 0.013) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.943 (std: 0.013) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.945 (std: 0.007) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.943 (std: 0.016) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.929 (std: 0.010) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.941 (std: 0.013) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.943 (std: 0.011) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.943 (std: 0.010) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.944 (std: 0.013) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.925 (std: 0.031) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.926 (std: 0.019) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.708 (std: 0.050) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.943 (std: 0.015) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.841 (std: 0.048) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.943 (std: 0.011) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.930 (std: 0.019) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.932 (std: 0.014) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.943 (std: 0.014) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.944 (std: 0.012) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.947 (std: 0.011) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.943 (std: 0.012) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.948 (std: 0.010) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.927 (std: 0.019) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.945 (std: 0.012) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.938 (std: 0.011) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.946 (std: 0.016) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.945 (std: 0.010) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.907 (std: 0.094) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.931 (std: 0.024) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.773 (std: 0.015) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.937 (std: 0.010) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.870 (std: 0.007) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.943 (std: 0.010) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.932 (std: 0.015) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.931 (std: 0.020) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.944 (std: 0.014) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.939 (std: 0.014) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.948 (std: 0.010) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.943 (std: 0.014) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.949 (std: 0.012) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.930 (std: 0.025) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.945 (std: 0.008) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.934 (std: 0.013) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.944 (std: 0.013) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.946 (std: 0.010) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.933 (std: 0.011) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.934 (std: 0.020) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.809 (std: 0.022) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.934 (std: 0.012) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.887 (std: 0.027) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.944 (std: 0.010) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.933 (std: 0.014) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.935 (std: 0.019) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.946 (std: 0.012) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.935 (std: 0.012) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.947 (std: 0.012) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.942 (std: 0.010) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.949 (std: 0.010) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.927 (std: 0.020) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.945 (std: 0.011) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.936 (std: 0.013) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.942 (std: 0.007) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.943 (std: 0.006) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.911 (std: 0.052) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.921 (std: 0.039) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.842 (std: 0.019) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.936 (std: 0.012) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.893 (std: 0.016) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.940 (std: 0.010) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.933 (std: 0.014) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.935 (std: 0.015) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.945 (std: 0.012) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.935 (std: 0.010) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.944 (std: 0.012) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.945 (std: 0.006) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.949 (std: 0.011) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.934 (std: 0.020) for \n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.938 (std: 0.016) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.942 (std: 0.015) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.935 (std: 0.015) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.940 (std: 0.009) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.922 (std: 0.036) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.936 (std: 0.021) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.572 (std: 0.162) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.942 (std: 0.018) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.805 (std: 0.069) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.945 (std: 0.008) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.937 (std: 0.016) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.930 (std: 0.030) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.939 (std: 0.015) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.944 (std: 0.011) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.941 (std: 0.017) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.942 (std: 0.015) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.940 (std: 0.015) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.923 (std: 0.030) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.938 (std: 0.016) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.943 (std: 0.009) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.939 (std: 0.016) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.945 (std: 0.009) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.925 (std: 0.028) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.920 (std: 0.030) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.728 (std: 0.071) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.942 (std: 0.014) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.821 (std: 0.051) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.943 (std: 0.013) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.933 (std: 0.016) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.931 (std: 0.019) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.938 (std: 0.014) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.944 (std: 0.013) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.945 (std: 0.016) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.942 (std: 0.009) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.942 (std: 0.016) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.924 (std: 0.035) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.939 (std: 0.013) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.945 (std: 0.009) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.943 (std: 0.013) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.943 (std: 0.013) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.919 (std: 0.031) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.931 (std: 0.013) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.654 (std: 0.162) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.945 (std: 0.011) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.832 (std: 0.041) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.946 (std: 0.011) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.912 (std: 0.081) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.934 (std: 0.018) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.939 (std: 0.014) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.944 (std: 0.010) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.941 (std: 0.018) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.944 (std: 0.014) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.947 (std: 0.012) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.926 (std: 0.045) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.942 (std: 0.014) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.945 (std: 0.011) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.943 (std: 0.015) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.944 (std: 0.015) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.923 (std: 0.027) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.935 (std: 0.015) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.712 (std: 0.137) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.946 (std: 0.010) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.848 (std: 0.017) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.945 (std: 0.009) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.910 (std: 0.086) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.931 (std: 0.025) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.943 (std: 0.013) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.945 (std: 0.011) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.947 (std: 0.011) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.945 (std: 0.009) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.948 (std: 0.013) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.934 (std: 0.015) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.944 (std: 0.014) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.942 (std: 0.009) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.944 (std: 0.010) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.943 (std: 0.009) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.910 (std: 0.057) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.930 (std: 0.014) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.780 (std: 0.035) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.944 (std: 0.009) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.879 (std: 0.021) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.942 (std: 0.011) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.932 (std: 0.014) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.927 (std: 0.024) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.944 (std: 0.012) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.943 (std: 0.011) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.948 (std: 0.012) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.946 (std: 0.011) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.949 (std: 0.010) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.933 (std: 0.014) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.945 (std: 0.013) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.942 (std: 0.011) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.945 (std: 0.015) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.945 (std: 0.012) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.922 (std: 0.024) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.929 (std: 0.014) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.804 (std: 0.036) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.941 (std: 0.012) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.886 (std: 0.011) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.941 (std: 0.011) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.932 (std: 0.017) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.934 (std: 0.018) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.945 (std: 0.013) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.940 (std: 0.012) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.947 (std: 0.012) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.944 (std: 0.014) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.949 (std: 0.010) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.936 (std: 0.021) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.946 (std: 0.013) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.936 (std: 0.012) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.944 (std: 0.014) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.945 (std: 0.012) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.921 (std: 0.022) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.925 (std: 0.019) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.842 (std: 0.019) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.936 (std: 0.009) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.894 (std: 0.025) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.945 (std: 0.012) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.933 (std: 0.013) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.925 (std: 0.031) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.946 (std: 0.012) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.937 (std: 0.010) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.943 (std: 0.013) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.944 (std: 0.012) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.950 (std: 0.011) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.929 (std: 0.028) for \n",
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.909 (std: 0.049) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.916 (std: 0.046) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.916 (std: 0.050) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.925 (std: 0.041) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.528 (std: 0.000) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.921 (std: 0.028) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.827 (std: 0.056) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.924 (std: 0.029) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.892 (std: 0.033) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.905 (std: 0.050) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.751 (std: 0.363) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.925 (std: 0.028) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.910 (std: 0.039) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.941 (std: 0.009) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.922 (std: 0.038) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.910 (std: 0.055) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.831 (std: 0.306) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.910 (std: 0.037) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.925 (std: 0.042) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.910 (std: 0.049) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.941 (std: 0.013) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.924 (std: 0.043) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.747 (std: 0.357) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.932 (std: 0.012) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.837 (std: 0.066) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.926 (std: 0.034) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.890 (std: 0.016) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.940 (std: 0.008) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.755 (std: 0.371) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.935 (std: 0.017) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.925 (std: 0.046) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.932 (std: 0.029) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.942 (std: 0.010) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.929 (std: 0.030) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.679 (std: 0.371) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.931 (std: 0.024) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.942 (std: 0.006) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.922 (std: 0.043) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.935 (std: 0.016) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.938 (std: 0.004) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.750 (std: 0.362) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.934 (std: 0.021) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.858 (std: 0.041) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.900 (std: 0.039) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.888 (std: 0.013) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.927 (std: 0.064) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.904 (std: 0.016) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.930 (std: 0.020) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.939 (std: 0.013) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.935 (std: 0.012) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.944 (std: 0.012) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.939 (std: 0.009) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.673 (std: 0.356) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.939 (std: 0.015) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.941 (std: 0.012) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.939 (std: 0.009) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.936 (std: 0.017) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.935 (std: 0.008) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.890 (std: 0.027) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.941 (std: 0.004) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.864 (std: 0.023) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.938 (std: 0.006) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.894 (std: 0.018) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.940 (std: 0.009) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.900 (std: 0.027) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.934 (std: 0.015) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.941 (std: 0.012) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.940 (std: 0.010) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.945 (std: 0.009) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.935 (std: 0.020) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.824 (std: 0.298) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.935 (std: 0.019) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.940 (std: 0.008) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.934 (std: 0.010) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.940 (std: 0.007) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.929 (std: 0.010) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.798 (std: 0.303) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.928 (std: 0.034) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.855 (std: 0.013) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.932 (std: 0.012) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.890 (std: 0.021) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.931 (std: 0.010) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.911 (std: 0.029) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.936 (std: 0.014) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.943 (std: 0.010) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.933 (std: 0.011) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.944 (std: 0.010) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.930 (std: 0.014) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.919 (std: 0.035) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.932 (std: 0.020) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.941 (std: 0.013) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.925 (std: 0.022) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.938 (std: 0.015) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.926 (std: 0.018) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.901 (std: 0.049) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.937 (std: 0.016) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.868 (std: 0.015) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.928 (std: 0.010) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.894 (std: 0.014) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.925 (std: 0.032) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.911 (std: 0.030) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.918 (std: 0.035) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.942 (std: 0.011) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.930 (std: 0.014) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.944 (std: 0.011) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.929 (std: 0.021) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.917 (std: 0.029) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.931 (std: 0.018) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (256,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.942 (std: 0.010) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.924 (std: 0.016) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.939 (std: 0.015) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.924 (std: 0.027) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.886 (std: 0.011) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.935 (std: 0.024) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.876 (std: 0.025) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.921 (std: 0.018) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.897 (std: 0.013) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.920 (std: 0.035) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.905 (std: 0.012) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.937 (std: 0.016) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.942 (std: 0.010) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.926 (std: 0.016) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.940 (std: 0.013) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.925 (std: 0.023) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.939 (std: 0.017) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.929 (std: 0.031) for \n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.927 (std: 0.038) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.914 (std: 0.050) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.928 (std: 0.036) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.937 (std: 0.010) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.594 (std: 0.263) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.903 (std: 0.050) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.788 (std: 0.316) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.913 (std: 0.053) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.887 (std: 0.028) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.928 (std: 0.048) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.604 (std: 0.304) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.924 (std: 0.035) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.917 (std: 0.035) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.909 (std: 0.062) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.930 (std: 0.029) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.938 (std: 0.011) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.528 (std: 0.000) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.935 (std: 0.012) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.933 (std: 0.036) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.941 (std: 0.007) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.919 (std: 0.031) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.938 (std: 0.015) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.753 (std: 0.368) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.933 (std: 0.020) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.859 (std: 0.048) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.922 (std: 0.050) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.890 (std: 0.010) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.929 (std: 0.035) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.751 (std: 0.363) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.937 (std: 0.016) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.935 (std: 0.031) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.929 (std: 0.050) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.940 (std: 0.012) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.922 (std: 0.070) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.528 (std: 0.000) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.933 (std: 0.025) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (15,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.930 (std: 0.045) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.930 (std: 0.051) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.942 (std: 0.011) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.940 (std: 0.020) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.816 (std: 0.289) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.921 (std: 0.045) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.853 (std: 0.038) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.941 (std: 0.008) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.892 (std: 0.017) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.939 (std: 0.012) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.826 (std: 0.298) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.936 (std: 0.020) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.926 (std: 0.039) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.941 (std: 0.008) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.938 (std: 0.031) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.941 (std: 0.009) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.819 (std: 0.292) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.927 (std: 0.022) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.942 (std: 0.012) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.940 (std: 0.007) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.938 (std: 0.020) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.940 (std: 0.012) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.742 (std: 0.350) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.936 (std: 0.017) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.857 (std: 0.025) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.939 (std: 0.006) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.893 (std: 0.015) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.940 (std: 0.008) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.824 (std: 0.296) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.933 (std: 0.024) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.942 (std: 0.011) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.940 (std: 0.010) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.945 (std: 0.010) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.935 (std: 0.022) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.759 (std: 0.379) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.939 (std: 0.025) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.939 (std: 0.004) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.938 (std: 0.005) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.934 (std: 0.020) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.932 (std: 0.018) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.734 (std: 0.345) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.941 (std: 0.008) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.856 (std: 0.019) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.938 (std: 0.012) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.892 (std: 0.013) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.933 (std: 0.020) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.907 (std: 0.011) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.934 (std: 0.012) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.943 (std: 0.009) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.939 (std: 0.007) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.943 (std: 0.011) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.939 (std: 0.010) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.775 (std: 0.404) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.940 (std: 0.022) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.938 (std: 0.019) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.932 (std: 0.013) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.936 (std: 0.011) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.928 (std: 0.033) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.818 (std: 0.291) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.935 (std: 0.009) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.863 (std: 0.017) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.935 (std: 0.003) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.896 (std: 0.015) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.939 (std: 0.011) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.822 (std: 0.344) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.931 (std: 0.021) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.942 (std: 0.008) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.936 (std: 0.006) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.942 (std: 0.013) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.937 (std: 0.010) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.931 (std: 0.037) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.934 (std: 0.018) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (256,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.941 (std: 0.013) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.932 (std: 0.006) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'constant', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.937 (std: 0.018) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.938 (std: 0.003) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.877 (std: 0.051) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.941 (std: 0.009) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.877 (std: 0.014) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.935 (std: 0.010) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.897 (std: 0.010) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.934 (std: 0.019) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.910 (std: 0.012) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.938 (std: 0.021) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "mean test score: 0.942 (std: 0.009) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "mean test score: 0.934 (std: 0.015) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "mean test score: 0.938 (std: 0.011) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "mean test score: 0.921 (std: 0.038) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "mean test score: 0.932 (std: 0.051) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "mean test score: 0.938 (std: 0.014) for \n",
      "{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('./data/q4_test.csv', sep=',')\n",
    "X_test, y_test = preprocess_data_task4(test)\n",
    "\n",
    "# print('Best parameters found:\\n', grid_search.best_params_)\n",
    "\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid_search.cv_results_['params']):\n",
    "    print('mean test score: %0.3f (std: %0.03f) for \\n%r' % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Q12] Report the three best hyperparameter settings as well as the mean and standard deviation of the validation accuracy of the five random data splits for each hyperparameter setting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (512,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      " {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (512,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      " {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (128,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'solver': 'sgd'}]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.950050</td>\n",
       "      <td>0.005452</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.05, 'hidden_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.949250</td>\n",
       "      <td>0.005351</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.0001, 'hidde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0.949075</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.05, 'hidden_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_test_score  std_test_score  \\\n",
       "250         0.950050        0.005452   \n",
       "124         0.949250        0.005351   \n",
       "214         0.949075        0.005207   \n",
       "\n",
       "                                                params  \n",
       "250  {'activation': 'tanh', 'alpha': 0.05, 'hidden_...  \n",
       "124  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...  \n",
       "214  {'activation': 'tanh', 'alpha': 0.05, 'hidden_...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(grid_search.cv_results_).sort_values(by='rank_test_score').head(3)\n",
    "q12 = result.loc[:, ['mean_test_score', 'std_test_score', 'params']]\n",
    "print(q12['params'].values)\n",
    "q12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Q13] Use the best model to predict the instances in the test set (q4 test.csv). Report the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95      5282\n",
      "           1       0.94      0.96      0.95      4718\n",
      "\n",
      "    accuracy                           0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Q14] Print the confusion matrix of the predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[4972  310]\n",
      " [ 176 4542]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "disp = plot_confusion_matrix(grid_search, X_test, y_test)\n",
    "disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "plt.savefig('confusion_matrix.png')\n",
    "print(\"Confusion matrix:\\n%s\" % disp.confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

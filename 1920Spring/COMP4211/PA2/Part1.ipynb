{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'pa2_data 2/part1_data/images/'\n",
    "train_path = 'pa2_data 2/part1_data/train.csv'\n",
    "test_path = 'pa2_data 2/part1_data/test.csv'\n",
    "submission_path = 'pa2_data 2/part1_data/submission.csv'\n",
    "\n",
    "IMAGE_DIM = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomHorizontalFlip = transforms.Compose([transforms.RandomHorizontalFlip(p=0.9)]) \n",
    "RandomAffine = transforms.Compose([transforms.RandomAffine(degrees=45)]) \n",
    "RandomCrop = transforms.Compose([transforms.RandomCrop(size=30)]) \n",
    "\n",
    "transform = transforms.Compose([\n",
    "#      transforms.ToPILImage(),\n",
    "     transforms.Resize(IMAGE_DIM),\n",
    "     transforms.RandomHorizontalFlip(p=0.5), # data augmentation by fliping \n",
    "     transforms.ToTensor(),    # range [0, 255] -> [0.0,1.0]\n",
    "     transforms.Normalize((0.5, 0.5, 0.5 ), (0.5, 0.5, 0.5))])   # channel=（channel-mean）/std  -> [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PosterDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.part_csv = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        img_names = os.path.join(self.root_dir, str(self.part_csv.iloc[idx, 0]))\n",
    "#         images = plt.imread(img_names+'.jpg')\n",
    "#         normalized_image = images / 255.0\n",
    "            \n",
    "        images = Image.open(img_names+'.jpg').convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            images = self.transform(images)\n",
    "\n",
    "        labels = self.part_csv.iloc[idx, 1:]\n",
    "#         print('iange', images.shape, 'labels', torch.tensor(labels))\n",
    "      \n",
    "        return (torch.tensor(images), torch.tensor(labels))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.part_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv = pd.read_csv(train_path)\n",
    "total_train_size = train_csv.shape[0]\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_TRAIN = int(total_train_size * 0.8)\n",
    "NUM_VAL = total_train_size - NUM_TRAIN\n",
    "\n",
    "all_train_dataset = PosterDataset(train_path, image_path, transform)\n",
    "\n",
    "train_dataset, val_dataset = random_split(all_train_dataset, [NUM_TRAIN, NUM_VAL])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "test_dataset = PosterDataset(test_path, image_path)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "genres = train_csv.columns.tolist()[1:]\n",
    "len(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.size() # read in N, C, H, W\n",
    "        return x.view(N, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 30, 30]             896\n",
      "              ReLU-2           [-1, 32, 30, 30]               0\n",
      "            Conv2d-3           [-1, 32, 28, 28]           9,248\n",
      "              ReLU-4           [-1, 32, 28, 28]               0\n",
      "            Conv2d-5           [-1, 16, 26, 26]           4,624\n",
      "              ReLU-6           [-1, 16, 26, 26]               0\n",
      "       BatchNorm2d-7           [-1, 16, 26, 26]              32\n",
      "         MaxPool2d-8           [-1, 16, 13, 13]               0\n",
      "           Flatten-9                 [-1, 2704]               0\n",
      "           Linear-10                  [-1, 256]         692,480\n",
      "             ReLU-11                  [-1, 256]               0\n",
      "          Dropout-12                  [-1, 256]               0\n",
      "           Linear-13                  [-1, 128]          32,896\n",
      "             ReLU-14                  [-1, 128]               0\n",
      "          Dropout-15                  [-1, 128]               0\n",
      "           Linear-16                    [-1, 7]             903\n",
      "================================================================\n",
      "Total params: 741,079\n",
      "Trainable params: 741,079\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.12\n",
      "Params size (MB): 2.83\n",
      "Estimated Total Size (MB): 3.96\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_base = nn.Sequential(\n",
    "#     nn.Conv2d(IMAGE_DIM, 128, kernel_size=3, stride=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(128, 128, kernel_size=3, stride=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(128, 128, kernel_size=3, stride=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.BatchNorm2d(128),\n",
    "#     nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "#     nn.Conv2d(128, 64, kernel_size=3, stride=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.BatchNorm2d(64),\n",
    "#     nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "    nn.Conv2d(3, 32, kernel_size=3, stride=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(32, 32, kernel_size=3, stride=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(32, 16, kernel_size=3, stride=1),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.MaxPool2d(2, stride=2),\n",
    "    \n",
    "    Flatten(), # see above for explanation\n",
    "    nn.Linear(4160, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(),\n",
    "\n",
    "    nn.Linear(128, 7),\n",
    ")\n",
    "\n",
    "dtype = torch.FloatTensor # the CPU datatype\n",
    "gpu_dtype = torch.cuda.FloatTensor\n",
    "model = model_base#.type(dtype)\n",
    "\n",
    "summary(model, input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(save_path, model, optimizer, val_loss):\n",
    "    if save_path==None:\n",
    "        return\n",
    "    save_path = save_path \n",
    "    state_dict = {'model_state_dict': model.state_dict(),\n",
    "                  'optimizer_state_dict': optimizer.state_dict(),\n",
    "                  'val_loss': val_loss}\n",
    "\n",
    "    torch.save(state_dict, save_path)\n",
    "\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "def load_checkpoint(model, optimizer):\n",
    "    save_path = f'cifar_net.pt'\n",
    "    state_dict = torch.load(save_path)\n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
    "    val_loss = state_dict['val_loss']\n",
    "    print(f'Model loaded from <== {save_path}')\n",
    "    \n",
    "    return val_loss\n",
    "\n",
    "tmp = None\n",
    "\n",
    "def TRAIN(net, train_loader, valid_loader, threshold, num_epochs, eval_every, total_step, criterion, optimizer, val_loss, device, save_name):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    running_num = 0\n",
    "    global_step = 0\n",
    "    if val_loss==None:\n",
    "        best_val_loss = float(\"Inf\")  \n",
    "    else: \n",
    "        best_val_loss=val_loss\n",
    "    \n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            net.train()\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            '''Training of the model'''\n",
    "            # Forward pass\n",
    "            outputs = net(inputs)\n",
    "            preds = (outputs + 1) / 2             # normalise => [0, 1]\n",
    "            preds = torch.sum((preds > threshold) * 1 == labels.data, dim=1)\n",
    "            \n",
    "            loss = criterion(outputs, labels.type_as(outputs))\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            global_step += 1\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_corrects += torch.sum(preds == 7 * 1)\n",
    "            running_num += len(labels)\n",
    "\n",
    "            '''Evaluating the model every x steps'''\n",
    "            if global_step % eval_every == 0:\n",
    "                with torch.no_grad():\n",
    "                    net.eval()\n",
    "                    val_running_loss = 0.0\n",
    "                    val_running_corrects = 0\n",
    "                    for val_inputs, val_labels in valid_loader:\n",
    "                        val_outputs = net(val_inputs)\n",
    "                        val_loss = criterion(val_outputs, val_labels.type_as(val_outputs))\n",
    "                        preds = (outputs + 1) / 2             # normalise => [0, 1]\n",
    "                        preds = torch.sum((preds > threshold) * 1 == labels.data, dim=1)\n",
    "                        preds = torch.sum(preds)\n",
    "                        val_running_loss += val_loss.item()\n",
    "                        val_running_corrects += torch.sum(preds == 7 * 1)\n",
    "\n",
    "\n",
    "                    average_train_loss = running_loss / eval_every\n",
    "                    average_val_loss = val_running_loss / len(valid_loader)\n",
    "                    average_train_acc = running_corrects / float(running_num)\n",
    "                    average_val_acc = val_running_corrects / float(len(valid_loader))\n",
    "\n",
    "                    print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Train Acc: {:.4f}, Valid Loss: {:.4f},  Valid Acc: {:.4f}'\n",
    "                          .format(epoch+1, num_epochs, global_step, total_step, average_train_loss,\n",
    "                                  average_train_acc, average_val_loss, average_val_acc))\n",
    "\n",
    "                    running_loss = 0.0\n",
    "                    running_num = 0\n",
    "                    running_corrects = 0\n",
    "                    \n",
    "                    if average_val_loss < best_val_loss:\n",
    "                        best_val_loss = average_val_loss\n",
    "                        save_checkpoint(save_name, net, optimizer, best_val_loss)\n",
    "                    \n",
    "                    \n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1/260], Train Loss: 0.7234, Train Acc: 0.0000, Valid Loss: 0.6882,  Valid Acc: 0.0000\n",
      "Model saved to ==> cifar_net.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [2/260], Train Loss: 0.6731, Train Acc: 0.0312, Valid Loss: 0.6843,  Valid Acc: 0.0000\n",
      "Model saved to ==> cifar_net.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [3/260], Train Loss: 0.6466, Train Acc: 0.0312, Valid Loss: 0.6801,  Valid Acc: 0.0000\n",
      "Model saved to ==> cifar_net.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [4/260], Train Loss: 0.5983, Train Acc: 0.0625, Valid Loss: 0.6757,  Valid Acc: 0.0000\n",
      "Model saved to ==> cifar_net.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [5/260], Train Loss: 0.6090, Train Acc: 0.0625, Valid Loss: 0.6719,  Valid Acc: 0.0000\n",
      "Model saved to ==> cifar_net.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [6/260], Train Loss: 0.5715, Train Acc: 0.0938, Valid Loss: 0.6664,  Valid Acc: 0.0000\n",
      "Model saved to ==> cifar_net.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [7/260], Train Loss: 0.5558, Train Acc: 0.0625, Valid Loss: 0.6589,  Valid Acc: 0.0000\n",
      "Model saved to ==> cifar_net.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [8/260], Train Loss: 0.5261, Train Acc: 0.1250, Valid Loss: 0.6512,  Valid Acc: 0.0000\n",
      "Model saved to ==> cifar_net.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [9/260], Train Loss: 0.5039, Train Acc: 0.1250, Valid Loss: 0.6424,  Valid Acc: 0.0000\n",
      "Model saved to ==> cifar_net.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cola/anaconda3/envs/ML/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "num_epochs = 1\n",
    "eval_every = 1\n",
    "total_step = len(train_loader)*num_epochs\n",
    "best_val_loss = None\n",
    "save_path = f'cifar_net.pt'\n",
    "criterion = nn.BCEWithLogitsLoss()#.type(dtype)\n",
    "optimizer = optim.Adam(model.parameters(), 5e-4)\n",
    "model = model.to(device)\n",
    "\n",
    "TRAIN(model, train_loader, val_loader, threshold, num_epochs, eval_every, total_step, criterion, optimizer, best_val_loss, device, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
